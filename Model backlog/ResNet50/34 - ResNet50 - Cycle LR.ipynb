{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, cohen_kappa_score\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras import optimizers, applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, Callback, LearningRateScheduler\n",
    "from keras.layers import Dense, Dropout, GlobalAveragePooling2D, Input\n",
    "\n",
    "# Set seeds to make the experiment more reproducible.\n",
    "from tensorflow import set_random_seed\n",
    "def seed_everything(seed=0):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    set_random_seed(0)\n",
    "seed_everything()\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(style=\"whitegrid\")\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_kg_hide-output": true
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-input": true,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train samples:  3662\n",
      "Number of test samples:  1928\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000c1434d8d7.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001639a390f0.png</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0024cdab0c1e.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002c21358ce6.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005b95c28852.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id_code diagnosis\n",
       "0  000c1434d8d7.png         2\n",
       "1  001639a390f0.png         4\n",
       "2  0024cdab0c1e.png         1\n",
       "3  002c21358ce6.png         0\n",
       "4  005b95c28852.png         0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = pd.read_csv('../input/aptos2019-blindness-detection/train.csv')\n",
    "test = pd.read_csv('../input/aptos2019-blindness-detection/test.csv')\n",
    "print('Number of train samples: ', train.shape[0])\n",
    "print('Number of test samples: ', test.shape[0])\n",
    "\n",
    "# Preprocecss data\n",
    "train[\"id_code\"] = train[\"id_code\"].apply(lambda x: x + \".png\")\n",
    "test[\"id_code\"] = test[\"id_code\"].apply(lambda x: x + \".png\")\n",
    "train['diagnosis'] = train['diagnosis'].astype('str')\n",
    "display(train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 30\n",
    "WARMUP_EPOCHS = 2\n",
    "LEARNING_RATE = 1e-3\n",
    "WARMUP_LEARNING_RATE = 1e-3\n",
    "HEIGHT = 256\n",
    "WIDTH = 256\n",
    "CANAL = 3\n",
    "N_CLASSES = train['diagnosis'].nunique()\n",
    "ES_PATIENCE = 5\n",
    "RLROP_PATIENCE = 3\n",
    "DECAY_DROP = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": false
   },
   "outputs": [],
   "source": [
    "def kappa(y_true, y_pred, n_classes=5):\n",
    "    y_trues = K.cast(K.argmax(y_true), K.floatx())\n",
    "    y_preds = K.cast(K.argmax(y_pred), K.floatx())\n",
    "    n_samples = K.cast(K.shape(y_true)[0], K.floatx())\n",
    "    distance = K.sum(K.abs(y_trues - y_preds))\n",
    "    max_distance = n_classes - 1\n",
    "    \n",
    "    kappa_score = 1 - ((distance**2) / (n_samples * (max_distance**2)))\n",
    "\n",
    "    return kappa_score\n",
    "\n",
    "\n",
    "def step_decay(epoch):\n",
    "    lrate = 30e-5\n",
    "    if epoch > 3:\n",
    "        lrate = 15e-5\n",
    "    if epoch > 7:\n",
    "        lrate = 7.5e-5\n",
    "    if epoch > 11:\n",
    "        lrate = 3e-5\n",
    "    if epoch > 15:\n",
    "        lrate = 1e-5\n",
    "\n",
    "    return lrate\n",
    "\n",
    "\n",
    "def get_1cycle_schedule(lr_max=1e-3, n_data_points=8000, epochs=200, batch_size=40, verbose=0):          \n",
    "    \"\"\"\n",
    "    Creates a look-up table of learning rates for 1cycle schedule with cosine annealing\n",
    "    See @sgugger's & @jeremyhoward's code in fastai library: https://github.com/fastai/fastai/blob/master/fastai/train.py\n",
    "    Wrote this to use with my Keras and (non-fastai-)PyTorch codes.\n",
    "    Note that in Keras, the LearningRateScheduler callback (https://keras.io/callbacks/#learningratescheduler) only operates once per epoch, not per batch\n",
    "      So see below for Keras callback\n",
    "\n",
    "    Keyword arguments:\n",
    "    lr_max            chosen by user after lr_finder\n",
    "    n_data_points     data points per epoch (e.g. size of training set)\n",
    "    epochs            number of epochs\n",
    "    batch_size        batch size\n",
    "    Output:  \n",
    "    lrs               look-up table of LR's, with length equal to total # of iterations\n",
    "    Then you can use this in your PyTorch code by counting iteration number and setting\n",
    "          optimizer.param_groups[0]['lr'] = lrs[iter_count]\n",
    "    \"\"\"\n",
    "    if verbose > 0:\n",
    "        print(\"Setting up 1Cycle LR schedule...\")\n",
    "    pct_start, div_factor = 0.3, 25.        # @sgugger's parameters in fastai code\n",
    "    lr_start = lr_max/div_factor\n",
    "    lr_end = lr_start/1e4\n",
    "    n_iter = (n_data_points * epochs // batch_size) + 1    # number of iterations\n",
    "    a1 = int(n_iter * pct_start)\n",
    "    a2 = n_iter - a1\n",
    "\n",
    "    # make look-up table\n",
    "    lrs_first = np.linspace(lr_start, lr_max, a1)            # linear growth\n",
    "    lrs_second = (lr_max-lr_end)*(1+np.cos(np.linspace(0,np.pi,a2)))/2 + lr_end  # cosine annealing\n",
    "    lrs = np.concatenate((lrs_first, lrs_second))\n",
    "    return lrs\n",
    "\n",
    "\n",
    "class OneCycleScheduler(Callback):\n",
    "    \"\"\"My modification of Keras' Learning rate scheduler to do 1Cycle learning\n",
    "       which increments per BATCH, not per epoch\n",
    "    Keyword arguments\n",
    "        **kwargs:  keyword arguments to pass to get_1cycle_schedule()\n",
    "        Also, verbose: int. 0: quiet, 1: update messages.\n",
    "\n",
    "    Sample usage (from my train.py):\n",
    "        lrsched = OneCycleScheduler(lr_max=1e-4, n_data_points=X_train.shape[0],\n",
    "        epochs=epochs, batch_size=batch_size, verbose=1)\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(OneCycleScheduler, self).__init__()\n",
    "        self.verbose = kwargs.get('verbose', 0)\n",
    "        self.lrs = get_1cycle_schedule(**kwargs)\n",
    "        self.iteration = 0\n",
    "\n",
    "    def on_batch_begin(self, batch, logs=None):\n",
    "        lr = self.lrs[self.iteration]\n",
    "        K.set_value(self.model.optimizer.lr, lr)         # here's where the assignment takes place\n",
    "        if self.verbose > 0:\n",
    "            print('\\nIteration %06d: OneCycleScheduler setting learning '\n",
    "                  'rate to %s.' % (self.iteration, lr))\n",
    "        self.iteration += 1\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):  # this is unchanged from Keras LearningRateScheduler\n",
    "        logs = logs or {}\n",
    "        logs['lr'] = K.get_value(self.model.optimizer.lr)\n",
    "        self.iteration = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val = train_test_split(train, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2746 validated image filenames belonging to 5 classes.\n",
      "Found 916 validated image filenames belonging to 5 classes.\n",
      "Found 1928 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "train_datagen=ImageDataGenerator(rescale=1./255, \n",
    "                                 rotation_range=360,\n",
    "                                 brightness_range=[0.5, 1.5],\n",
    "                                 zoom_range=[1, 1.2],\n",
    "                                 zca_whitening=True,\n",
    "                                 horizontal_flip=True,\n",
    "                                 vertical_flip=True,\n",
    "                                 fill_mode='reflect',\n",
    "                                 cval=0.)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator=train_datagen.flow_from_dataframe(\n",
    "    dataframe=X_train,\n",
    "    directory=\"../input/aptos2019-blindness-detection/train_images/\",\n",
    "    x_col=\"id_code\",\n",
    "    y_col=\"diagnosis\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(HEIGHT, WIDTH))\n",
    "\n",
    "valid_generator=validation_datagen.flow_from_dataframe(\n",
    "    dataframe=X_val,\n",
    "    directory=\"../input/aptos2019-blindness-detection/train_images/\",\n",
    "    x_col=\"id_code\",\n",
    "    y_col=\"diagnosis\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",    \n",
    "    target_size=(HEIGHT, WIDTH))\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(  \n",
    "        dataframe=test,\n",
    "        directory = \"../input/aptos2019-blindness-detection/test_images/\",\n",
    "        x_col=\"id_code\",\n",
    "        target_size=(HEIGHT, WIDTH),\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        class_mode=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, n_out):\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "    base_model = applications.ResNet50(weights=None, \n",
    "                                       include_top=False,\n",
    "                                       input_tensor=input_tensor)\n",
    "    base_model.load_weights('../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(2048, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    final_output = Dense(n_out, activation='softmax', name='final_output')(x)\n",
    "    model = Model(input_tensor, final_output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train top layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 262, 262, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 128, 128, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 128, 128, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 128, 128, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 130, 130, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 64, 64, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 64, 64, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 64, 64, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 64, 64, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 64, 64, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 64, 64, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 64, 64, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 64, 64, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 64, 64, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 64, 64, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64, 64, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 64, 64, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 64, 64, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 64, 64, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 64, 64, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 64, 64, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 64, 64, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 64, 64, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 64, 64, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 64, 64, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 64, 64, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 64, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 64, 64, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 64, 64, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 64, 64, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 64, 64, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 64, 64, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 64, 64, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 64, 64, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 64, 64, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 64, 64, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 64, 64, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 32, 32, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 32, 32, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 32, 32, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 32, 32, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 32, 32, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 32, 32, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 32, 32, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 32, 32, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 32, 32, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 32, 32, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 32, 32, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 32, 32, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 32, 32, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 32, 32, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 32, 32, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 32, 32, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 32, 32, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 32, 32, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 32, 32, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 32, 32, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 32, 32, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 32, 32, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 32, 32, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 32, 32, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 32, 32, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 32, 32, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 32, 32, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 32, 32, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 32, 32, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 32, 32, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 32, 32, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 32, 32, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 32, 32, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 32, 32, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 32, 32, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 32, 32, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 32, 32, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 32, 32, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 32, 32, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 32, 32, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 32, 32, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 32, 32, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 16, 16, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 16, 16, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 16, 16, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 16, 16, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 16, 16, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 16, 16, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 16, 16, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 16, 16, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16, 16, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 16, 16, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 16, 16, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 16, 16, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 16, 16, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 16, 16, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 16, 16, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 16, 16, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 16, 16, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 16, 16, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 16, 16, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 16, 16, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 16, 16, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 16, 16, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 16, 16, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 16, 16, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 16, 16, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 16, 16, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 16, 16, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 16, 16, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 16, 16, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 16, 16, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 16, 16, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 16, 16, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 16, 16, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 16, 16, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 16, 16, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 16, 16, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 16, 16, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 16, 16, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 16, 16, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 16, 16, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 16, 16, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 16, 16, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 16, 16, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 16, 16, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 8, 8, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 8, 8, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 8, 8, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 8, 8, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 8, 8, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 8, 8, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 8, 8, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 8, 8, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 8, 8, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 8, 8, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 8, 8, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 8, 8, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 8, 8, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 8, 8, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 8, 8, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 8, 8, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 8, 8, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 8, 8, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 8, 8, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 8, 8, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 8, 8, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 8, 8, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 8, 8, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 8, 8, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 8, 8, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 8, 8, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 8, 8, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 8, 8, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 8, 8, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 8, 8, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 8, 8, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 8, 8, 2048)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 2048)         0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2048)         4196352     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 2048)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "final_output (Dense)            (None, 5)            10245       dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 27,794,309\n",
      "Trainable params: 4,206,597\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(input_shape=(HEIGHT, WIDTH, CANAL), n_out=N_CLASSES)\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "for i in range(-5, 0):\n",
    "    model.layers[i].trainable = True\n",
    "    \n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(train['diagnosis'].astype('int').values), train['diagnosis'].astype('int').values)\n",
    "\n",
    "metric_list = [\"accuracy\", kappa]\n",
    "optimizer = optimizers.Adam(lr=WARMUP_LEARNING_RATE)\n",
    "model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\",  metrics=metric_list)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "343/343 [==============================] - 430s 1s/step - loss: 1.3501 - acc: 0.6319 - kappa: 0.7273 - val_loss: 1.3570 - val_acc: 0.2752 - val_kappa: 0.0984\n",
      "Epoch 2/2\n",
      "343/343 [==============================] - 414s 1s/step - loss: 0.8762 - acc: 0.6709 - kappa: 0.8049 - val_loss: 1.3655 - val_acc: 0.2753 - val_kappa: 0.1169\n"
     ]
    }
   ],
   "source": [
    "STEP_SIZE_TRAIN = train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID = valid_generator.n//valid_generator.batch_size\n",
    "\n",
    "history_warmup = model.fit_generator(generator=train_generator,\n",
    "                                     steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                                     validation_data=valid_generator,\n",
    "                                     validation_steps=STEP_SIZE_VALID,\n",
    "                                     epochs=WARMUP_EPOCHS,\n",
    "                                     class_weight=class_weights,\n",
    "                                     verbose=1).history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune the complete model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up 1Cycle LR schedule...\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 262, 262, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 128, 128, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 128, 128, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 128, 128, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 130, 130, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 64, 64, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 64, 64, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 64, 64, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 64, 64, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 64, 64, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 64, 64, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 64, 64, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 64, 64, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 64, 64, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 64, 64, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64, 64, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 64, 64, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 64, 64, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 64, 64, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 64, 64, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 64, 64, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 64, 64, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 64, 64, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 64, 64, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 64, 64, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 64, 64, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 64, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 64, 64, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 64, 64, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 64, 64, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 64, 64, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 64, 64, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 64, 64, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 64, 64, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 64, 64, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 64, 64, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 64, 64, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 32, 32, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 32, 32, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 32, 32, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 32, 32, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 32, 32, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 32, 32, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 32, 32, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 32, 32, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 32, 32, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 32, 32, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 32, 32, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 32, 32, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 32, 32, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 32, 32, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 32, 32, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 32, 32, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 32, 32, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 32, 32, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 32, 32, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 32, 32, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 32, 32, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 32, 32, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 32, 32, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 32, 32, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 32, 32, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 32, 32, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 32, 32, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 32, 32, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 32, 32, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 32, 32, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 32, 32, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 32, 32, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 32, 32, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 32, 32, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 32, 32, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 32, 32, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 32, 32, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 32, 32, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 32, 32, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 32, 32, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 32, 32, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 32, 32, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 16, 16, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 16, 16, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 16, 16, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 16, 16, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 16, 16, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 16, 16, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 16, 16, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 16, 16, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16, 16, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 16, 16, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 16, 16, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 16, 16, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 16, 16, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 16, 16, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 16, 16, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 16, 16, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 16, 16, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 16, 16, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 16, 16, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 16, 16, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 16, 16, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 16, 16, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 16, 16, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 16, 16, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 16, 16, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 16, 16, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 16, 16, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 16, 16, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 16, 16, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 16, 16, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 16, 16, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 16, 16, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 16, 16, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 16, 16, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 16, 16, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 16, 16, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 16, 16, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 16, 16, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 16, 16, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 16, 16, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 16, 16, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 16, 16, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 16, 16, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 16, 16, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 16, 16, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 16, 16, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 16, 16, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 8, 8, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 8, 8, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 8, 8, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 8, 8, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 8, 8, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 8, 8, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 8, 8, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 8, 8, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 8, 8, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 8, 8, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 8, 8, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 8, 8, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 8, 8, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 8, 8, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 8, 8, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 8, 8, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 8, 8, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 8, 8, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 8, 8, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 8, 8, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 8, 8, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 8, 8, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 8, 8, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 8, 8, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 8, 8, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 8, 8, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 8, 8, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 8, 8, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 8, 8, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 8, 8, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 8, 8, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 8, 8, 2048)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 2048)         0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2048)         4196352     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 2048)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "final_output (Dense)            (None, 5)            10245       dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 27,794,309\n",
      "Trainable params: 27,741,189\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "# lrstep = LearningRateScheduler(step_decay)\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', patience=ES_PATIENCE, restore_best_weights=True, verbose=1)\n",
    "rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)\n",
    "lrcycle = OneCycleScheduler(lr_max=LEARNING_RATE, n_data_points=(train_generator.n + valid_generator.n), epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1)\n",
    "\n",
    "callback_list = [es, lrcycle]\n",
    "optimizer = optimizers.Adam(lr=LEARNING_RATE)\n",
    "model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\",  metrics=metric_list)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\n",
      "Iteration 000000: OneCycleScheduler setting learning rate to 4e-05.\n",
      "  1/343 [..............................] - ETA: 2:07:51 - loss: 0.7383 - acc: 0.7500 - kappa: 0.9297\n",
      "Iteration 000001: OneCycleScheduler setting learning rate to 4.023312287518213e-05.\n",
      "  2/343 [..............................] - ETA: 1:04:05 - loss: 0.7058 - acc: 0.6250 - kappa: 0.8672\n",
      "Iteration 000002: OneCycleScheduler setting learning rate to 4.046624575036426e-05.\n",
      "  3/343 [..............................] - ETA: 42:51 - loss: 0.8103 - acc: 0.6250 - kappa: 0.8698  \n",
      "Iteration 000003: OneCycleScheduler setting learning rate to 4.0699368625546386e-05.\n",
      "  4/343 [..............................] - ETA: 32:12 - loss: 0.8271 - acc: 0.6250 - kappa: 0.8848\n",
      "Iteration 000004: OneCycleScheduler setting learning rate to 4.093249150072851e-05.\n",
      "  5/343 [..............................] - ETA: 25:49 - loss: 0.9080 - acc: 0.6500 - kappa: 0.8828\n",
      "Iteration 000005: OneCycleScheduler setting learning rate to 4.1165614375910636e-05.\n",
      "  6/343 [..............................] - ETA: 21:34 - loss: 1.0927 - acc: 0.5625 - kappa: 0.6094\n",
      "Iteration 000006: OneCycleScheduler setting learning rate to 4.139873725109277e-05.\n",
      "  7/343 [..............................] - ETA: 18:31 - loss: 1.0495 - acc: 0.5714 - kappa: 0.6473\n",
      "Iteration 000007: OneCycleScheduler setting learning rate to 4.1631860126274893e-05.\n",
      "  8/343 [..............................] - ETA: 16:15 - loss: 0.9966 - acc: 0.5938 - kappa: 0.6826\n",
      "Iteration 000008: OneCycleScheduler setting learning rate to 4.186498300145702e-05.\n",
      "  9/343 [..............................] - ETA: 14:28 - loss: 0.9222 - acc: 0.6389 - kappa: 0.7179\n",
      "Iteration 000009: OneCycleScheduler setting learning rate to 4.209810587663915e-05.\n",
      " 10/343 [..............................] - ETA: 13:03 - loss: 0.8791 - acc: 0.6625 - kappa: 0.7453\n",
      "Iteration 000010: OneCycleScheduler setting learning rate to 4.2331228751821276e-05.\n",
      " 11/343 [..............................] - ETA: 11:53 - loss: 0.8858 - acc: 0.6705 - kappa: 0.7621\n",
      "Iteration 000011: OneCycleScheduler setting learning rate to 4.25643516270034e-05.\n",
      " 12/343 [>.............................] - ETA: 10:55 - loss: 0.8869 - acc: 0.6667 - kappa: 0.7656\n",
      "Iteration 000012: OneCycleScheduler setting learning rate to 4.279747450218553e-05.\n",
      " 13/343 [>.............................] - ETA: 10:16 - loss: 0.9189 - acc: 0.6538 - kappa: 0.7542\n",
      "Iteration 000013: OneCycleScheduler setting learning rate to 4.303059737736766e-05.\n",
      " 14/343 [>.............................] - ETA: 10:05 - loss: 0.9123 - acc: 0.6518 - kappa: 0.7517\n",
      "Iteration 000014: OneCycleScheduler setting learning rate to 4.3263720252549784e-05.\n",
      " 15/343 [>.............................] - ETA: 9:51 - loss: 0.9184 - acc: 0.6417 - kappa: 0.7495 \n",
      "Iteration 000015: OneCycleScheduler setting learning rate to 4.3496843127731916e-05.\n",
      " 16/343 [>.............................] - ETA: 9:24 - loss: 0.8851 - acc: 0.6562 - kappa: 0.7646\n",
      "Iteration 000016: OneCycleScheduler setting learning rate to 4.372996600291404e-05.\n",
      " 17/343 [>.............................] - ETA: 9:07 - loss: 0.8475 - acc: 0.6765 - kappa: 0.7785\n",
      "Iteration 000017: OneCycleScheduler setting learning rate to 4.3963088878096166e-05.\n",
      " 18/343 [>.............................] - ETA: 8:56 - loss: 0.8473 - acc: 0.6736 - kappa: 0.7799\n",
      "Iteration 000018: OneCycleScheduler setting learning rate to 4.419621175327829e-05.\n",
      " 19/343 [>.............................] - ETA: 8:42 - loss: 0.8363 - acc: 0.6711 - kappa: 0.7850\n",
      "Iteration 000019: OneCycleScheduler setting learning rate to 4.442933462846042e-05.\n",
      " 20/343 [>.............................] - ETA: 8:28 - loss: 0.8216 - acc: 0.6813 - kappa: 0.7895\n",
      "Iteration 000020: OneCycleScheduler setting learning rate to 4.466245750364255e-05.\n",
      " 21/343 [>.............................] - ETA: 8:11 - loss: 0.7959 - acc: 0.6964 - kappa: 0.7995\n",
      "Iteration 000021: OneCycleScheduler setting learning rate to 4.4895580378824674e-05.\n",
      " 22/343 [>.............................] - ETA: 8:00 - loss: 0.7982 - acc: 0.6932 - kappa: 0.8029\n",
      "Iteration 000022: OneCycleScheduler setting learning rate to 4.5128703254006806e-05.\n",
      " 23/343 [=>............................] - ETA: 7:50 - loss: 0.7963 - acc: 0.6902 - kappa: 0.8084\n",
      "Iteration 000023: OneCycleScheduler setting learning rate to 4.536182612918893e-05.\n",
      " 24/343 [=>............................] - ETA: 7:40 - loss: 0.7767 - acc: 0.6927 - kappa: 0.8135\n",
      "Iteration 000024: OneCycleScheduler setting learning rate to 4.5594949004371056e-05.\n",
      " 25/343 [=>............................] - ETA: 7:35 - loss: 0.7765 - acc: 0.6900 - kappa: 0.8097\n",
      "Iteration 000025: OneCycleScheduler setting learning rate to 4.582807187955318e-05.\n",
      " 26/343 [=>............................] - ETA: 7:28 - loss: 0.7818 - acc: 0.6923 - kappa: 0.8158\n",
      "Iteration 000026: OneCycleScheduler setting learning rate to 4.606119475473531e-05.\n",
      " 27/343 [=>............................] - ETA: 7:22 - loss: 0.7815 - acc: 0.6944 - kappa: 0.8122\n",
      "Iteration 000027: OneCycleScheduler setting learning rate to 4.629431762991744e-05.\n",
      " 28/343 [=>............................] - ETA: 7:17 - loss: 0.7631 - acc: 0.7009 - kappa: 0.8178\n",
      "Iteration 000028: OneCycleScheduler setting learning rate to 4.6527440505099564e-05.\n",
      " 29/343 [=>............................] - ETA: 7:14 - loss: 0.7499 - acc: 0.7112 - kappa: 0.8241\n",
      "Iteration 000029: OneCycleScheduler setting learning rate to 4.6760563380281696e-05.\n",
      " 30/343 [=>............................] - ETA: 7:06 - loss: 0.7421 - acc: 0.7167 - kappa: 0.8289\n",
      "Iteration 000030: OneCycleScheduler setting learning rate to 4.699368625546382e-05.\n",
      " 31/343 [=>............................] - ETA: 7:01 - loss: 0.7343 - acc: 0.7218 - kappa: 0.8342\n",
      "Iteration 000031: OneCycleScheduler setting learning rate to 4.7226809130645946e-05.\n",
      " 32/343 [=>............................] - ETA: 6:58 - loss: 0.7457 - acc: 0.7188 - kappa: 0.8372\n",
      "Iteration 000032: OneCycleScheduler setting learning rate to 4.745993200582808e-05.\n",
      " 33/343 [=>............................] - ETA: 6:52 - loss: 0.7435 - acc: 0.7159 - kappa: 0.8400\n",
      "Iteration 000033: OneCycleScheduler setting learning rate to 4.7693054881010203e-05.\n",
      " 34/343 [=>............................] - ETA: 6:46 - loss: 0.7324 - acc: 0.7206 - kappa: 0.8438\n",
      "Iteration 000034: OneCycleScheduler setting learning rate to 4.792617775619233e-05.\n",
      " 35/343 [==>...........................] - ETA: 6:40 - loss: 0.7214 - acc: 0.7250 - kappa: 0.8473\n",
      "Iteration 000035: OneCycleScheduler setting learning rate to 4.815930063137446e-05.\n",
      " 36/343 [==>...........................] - ETA: 6:37 - loss: 0.7120 - acc: 0.7257 - kappa: 0.8496\n",
      "Iteration 000036: OneCycleScheduler setting learning rate to 4.8392423506556586e-05.\n",
      " 37/343 [==>...........................] - ETA: 6:32 - loss: 0.7118 - acc: 0.7297 - kappa: 0.8535\n",
      "Iteration 000037: OneCycleScheduler setting learning rate to 4.862554638173871e-05.\n",
      " 38/343 [==>...........................] - ETA: 6:29 - loss: 0.7269 - acc: 0.7270 - kappa: 0.8522\n",
      "Iteration 000038: OneCycleScheduler setting learning rate to 4.8858669256920836e-05.\n",
      " 39/343 [==>...........................] - ETA: 6:26 - loss: 0.7249 - acc: 0.7276 - kappa: 0.8552\n",
      "Iteration 000039: OneCycleScheduler setting learning rate to 4.909179213210297e-05.\n",
      " 40/343 [==>...........................] - ETA: 6:22 - loss: 0.7213 - acc: 0.7250 - kappa: 0.8539\n",
      "Iteration 000040: OneCycleScheduler setting learning rate to 4.9324915007285094e-05.\n",
      " 41/343 [==>...........................] - ETA: 6:18 - loss: 0.7283 - acc: 0.7256 - kappa: 0.8544\n",
      "Iteration 000041: OneCycleScheduler setting learning rate to 4.955803788246722e-05.\n",
      " 42/343 [==>...........................] - ETA: 6:16 - loss: 0.7311 - acc: 0.7232 - kappa: 0.8549\n",
      "Iteration 000042: OneCycleScheduler setting learning rate to 4.979116075764935e-05.\n",
      " 43/343 [==>...........................] - ETA: 6:12 - loss: 0.7351 - acc: 0.7238 - kappa: 0.8566\n",
      "Iteration 000043: OneCycleScheduler setting learning rate to 5.0024283632831476e-05.\n",
      " 44/343 [==>...........................] - ETA: 6:09 - loss: 0.7293 - acc: 0.7244 - kappa: 0.8592\n",
      "Iteration 000044: OneCycleScheduler setting learning rate to 5.02574065080136e-05.\n",
      " 45/343 [==>...........................] - ETA: 6:07 - loss: 0.7310 - acc: 0.7250 - kappa: 0.8595\n",
      "Iteration 000045: OneCycleScheduler setting learning rate to 5.0490529383195726e-05.\n",
      " 46/343 [===>..........................] - ETA: 6:04 - loss: 0.7358 - acc: 0.7228 - kappa: 0.8599\n",
      "Iteration 000046: OneCycleScheduler setting learning rate to 5.072365225837786e-05.\n",
      " 47/343 [===>..........................] - ETA: 6:04 - loss: 0.7248 - acc: 0.7287 - kappa: 0.8629\n",
      "Iteration 000047: OneCycleScheduler setting learning rate to 5.0956775133559984e-05.\n",
      " 48/343 [===>..........................] - ETA: 6:00 - loss: 0.7277 - acc: 0.7292 - kappa: 0.8643\n",
      "Iteration 000048: OneCycleScheduler setting learning rate to 5.1189898008742116e-05.\n",
      " 49/343 [===>..........................] - ETA: 5:57 - loss: 0.7269 - acc: 0.7296 - kappa: 0.8656\n",
      "Iteration 000049: OneCycleScheduler setting learning rate to 5.142302088392424e-05.\n",
      " 50/343 [===>..........................] - ETA: 5:53 - loss: 0.7192 - acc: 0.7350 - kappa: 0.8683\n",
      "Iteration 000050: OneCycleScheduler setting learning rate to 5.1656143759106366e-05.\n",
      " 51/343 [===>..........................] - ETA: 5:50 - loss: 0.7195 - acc: 0.7328 - kappa: 0.8611\n",
      "Iteration 000051: OneCycleScheduler setting learning rate to 5.188926663428849e-05.\n",
      " 52/343 [===>..........................] - ETA: 5:46 - loss: 0.7313 - acc: 0.7284 - kappa: 0.8600\n",
      "Iteration 000052: OneCycleScheduler setting learning rate to 5.212238950947062e-05.\n",
      " 53/343 [===>..........................] - ETA: 5:45 - loss: 0.7356 - acc: 0.7217 - kappa: 0.8532\n",
      "Iteration 000053: OneCycleScheduler setting learning rate to 5.235551238465275e-05.\n",
      " 54/343 [===>..........................] - ETA: 5:41 - loss: 0.7330 - acc: 0.7222 - kappa: 0.8536\n",
      "Iteration 000054: OneCycleScheduler setting learning rate to 5.2588635259834874e-05.\n",
      " 55/343 [===>..........................] - ETA: 5:39 - loss: 0.7275 - acc: 0.7250 - kappa: 0.8561\n",
      "Iteration 000055: OneCycleScheduler setting learning rate to 5.2821758135017006e-05.\n",
      " 56/343 [===>..........................] - ETA: 5:37 - loss: 0.7267 - acc: 0.7254 - kappa: 0.8574\n",
      "Iteration 000056: OneCycleScheduler setting learning rate to 5.305488101019913e-05.\n",
      " 57/343 [===>..........................] - ETA: 5:36 - loss: 0.7245 - acc: 0.7259 - kappa: 0.8594\n",
      "Iteration 000057: OneCycleScheduler setting learning rate to 5.3288003885381256e-05.\n",
      " 58/343 [====>.........................] - ETA: 5:33 - loss: 0.7229 - acc: 0.7241 - kappa: 0.8584\n",
      "Iteration 000058: OneCycleScheduler setting learning rate to 5.352112676056338e-05.\n",
      " 59/343 [====>.........................] - ETA: 5:30 - loss: 0.7178 - acc: 0.7267 - kappa: 0.8603\n",
      "Iteration 000059: OneCycleScheduler setting learning rate to 5.3754249635745514e-05.\n",
      " 60/343 [====>.........................] - ETA: 5:26 - loss: 0.7140 - acc: 0.7292 - kappa: 0.8621\n",
      "Iteration 000060: OneCycleScheduler setting learning rate to 5.398737251092764e-05.\n",
      " 61/343 [====>.........................] - ETA: 5:23 - loss: 0.7105 - acc: 0.7295 - kappa: 0.8632\n",
      "Iteration 000061: OneCycleScheduler setting learning rate to 5.4220495386109764e-05.\n",
      " 62/343 [====>.........................] - ETA: 5:22 - loss: 0.7105 - acc: 0.7298 - kappa: 0.8649\n",
      "Iteration 000062: OneCycleScheduler setting learning rate to 5.4453618261291896e-05.\n",
      " 63/343 [====>.........................] - ETA: 5:20 - loss: 0.7162 - acc: 0.7262 - kappa: 0.8626\n",
      "Iteration 000063: OneCycleScheduler setting learning rate to 5.468674113647402e-05.\n",
      " 64/343 [====>.........................] - ETA: 5:17 - loss: 0.7119 - acc: 0.7305 - kappa: 0.8647\n",
      "Iteration 000064: OneCycleScheduler setting learning rate to 5.4919864011656146e-05.\n",
      " 65/343 [====>.........................] - ETA: 5:15 - loss: 0.7133 - acc: 0.7308 - kappa: 0.8663\n",
      "Iteration 000065: OneCycleScheduler setting learning rate to 5.515298688683827e-05.\n",
      " 66/343 [====>.........................] - ETA: 5:13 - loss: 0.7112 - acc: 0.7292 - kappa: 0.8665\n",
      "Iteration 000066: OneCycleScheduler setting learning rate to 5.5386109762020404e-05.\n",
      " 67/343 [====>.........................] - ETA: 5:11 - loss: 0.7073 - acc: 0.7295 - kappa: 0.8680\n",
      "Iteration 000067: OneCycleScheduler setting learning rate to 5.561923263720253e-05.\n",
      " 68/343 [====>.........................] - ETA: 5:09 - loss: 0.7115 - acc: 0.7298 - kappa: 0.8695\n",
      "Iteration 000068: OneCycleScheduler setting learning rate to 5.585235551238466e-05.\n",
      " 69/343 [=====>........................] - ETA: 5:09 - loss: 0.7086 - acc: 0.7319 - kappa: 0.8713\n",
      "Iteration 000069: OneCycleScheduler setting learning rate to 5.6085478387566786e-05.\n",
      " 70/343 [=====>........................] - ETA: 5:06 - loss: 0.7101 - acc: 0.7304 - kappa: 0.8713\n",
      "Iteration 000070: OneCycleScheduler setting learning rate to 5.631860126274891e-05.\n",
      " 71/343 [=====>........................] - ETA: 5:04 - loss: 0.7187 - acc: 0.7289 - kappa: 0.8714\n",
      "Iteration 000071: OneCycleScheduler setting learning rate to 5.6551724137931037e-05.\n",
      " 72/343 [=====>........................] - ETA: 5:02 - loss: 0.7196 - acc: 0.7292 - kappa: 0.8722\n",
      "Iteration 000072: OneCycleScheduler setting learning rate to 5.678484701311316e-05.\n",
      " 73/343 [=====>........................] - ETA: 4:58 - loss: 0.7235 - acc: 0.7295 - kappa: 0.8730\n",
      "Iteration 000073: OneCycleScheduler setting learning rate to 5.7017969888295294e-05.\n",
      " 74/343 [=====>........................] - ETA: 4:58 - loss: 0.7372 - acc: 0.7264 - kappa: 0.8695\n",
      "Iteration 000074: OneCycleScheduler setting learning rate to 5.7251092763477426e-05.\n",
      " 75/343 [=====>........................] - ETA: 4:58 - loss: 0.7338 - acc: 0.7283 - kappa: 0.8708\n",
      "Iteration 000075: OneCycleScheduler setting learning rate to 5.748421563865955e-05.\n",
      " 76/343 [=====>........................] - ETA: 4:55 - loss: 0.7318 - acc: 0.7286 - kappa: 0.8716\n",
      "Iteration 000076: OneCycleScheduler setting learning rate to 5.7717338513841676e-05.\n",
      " 77/343 [=====>........................] - ETA: 4:54 - loss: 0.7355 - acc: 0.7256 - kappa: 0.8683\n",
      "Iteration 000077: OneCycleScheduler setting learning rate to 5.79504613890238e-05.\n",
      " 78/343 [=====>........................] - ETA: 4:51 - loss: 0.7357 - acc: 0.7260 - kappa: 0.8696\n",
      "Iteration 000078: OneCycleScheduler setting learning rate to 5.818358426420593e-05.\n",
      " 79/343 [=====>........................] - ETA: 4:50 - loss: 0.7386 - acc: 0.7247 - kappa: 0.8677\n",
      "Iteration 000079: OneCycleScheduler setting learning rate to 5.841670713938806e-05.\n",
      " 80/343 [=====>........................] - ETA: 4:47 - loss: 0.7333 - acc: 0.7266 - kappa: 0.8689\n",
      "Iteration 000080: OneCycleScheduler setting learning rate to 5.8649830014570184e-05.\n",
      " 81/343 [======>.......................] - ETA: 4:46 - loss: 0.7334 - acc: 0.7238 - kappa: 0.8658\n",
      "Iteration 000081: OneCycleScheduler setting learning rate to 5.8882952889752316e-05.\n",
      " 82/343 [======>.......................] - ETA: 4:45 - loss: 0.7387 - acc: 0.7226 - kappa: 0.8651\n",
      "Iteration 000082: OneCycleScheduler setting learning rate to 5.911607576493444e-05.\n",
      " 83/343 [======>.......................] - ETA: 4:44 - loss: 0.7329 - acc: 0.7259 - kappa: 0.8667\n",
      "Iteration 000083: OneCycleScheduler setting learning rate to 5.9349198640116566e-05.\n",
      " 84/343 [======>.......................] - ETA: 4:42 - loss: 0.7382 - acc: 0.7262 - kappa: 0.8660\n",
      "Iteration 000084: OneCycleScheduler setting learning rate to 5.958232151529869e-05.\n",
      " 85/343 [======>.......................] - ETA: 4:41 - loss: 0.7432 - acc: 0.7250 - kappa: 0.8653\n",
      "Iteration 000085: OneCycleScheduler setting learning rate to 5.981544439048082e-05.\n",
      " 86/343 [======>.......................] - ETA: 4:40 - loss: 0.7381 - acc: 0.7267 - kappa: 0.8665\n",
      "Iteration 000086: OneCycleScheduler setting learning rate to 6.004856726566295e-05.\n",
      " 87/343 [======>.......................] - ETA: 4:38 - loss: 0.7326 - acc: 0.7299 - kappa: 0.8680\n",
      "Iteration 000087: OneCycleScheduler setting learning rate to 6.0281690140845074e-05.\n",
      " 88/343 [======>.......................] - ETA: 4:36 - loss: 0.7298 - acc: 0.7301 - kappa: 0.8687\n",
      "Iteration 000088: OneCycleScheduler setting learning rate to 6.0514813016027206e-05.\n",
      " 89/343 [======>.......................] - ETA: 4:35 - loss: 0.7259 - acc: 0.7317 - kappa: 0.8701\n",
      "Iteration 000089: OneCycleScheduler setting learning rate to 6.074793589120933e-05.\n",
      " 90/343 [======>.......................] - ETA: 4:33 - loss: 0.7265 - acc: 0.7306 - kappa: 0.8694\n",
      "Iteration 000090: OneCycleScheduler setting learning rate to 6.0981058766391456e-05.\n",
      " 91/343 [======>.......................] - ETA: 4:32 - loss: 0.7277 - acc: 0.7308 - kappa: 0.8700\n",
      "Iteration 000091: OneCycleScheduler setting learning rate to 6.121418164157358e-05.\n",
      " 92/343 [=======>......................] - ETA: 4:31 - loss: 0.7279 - acc: 0.7296 - kappa: 0.8684\n",
      "Iteration 000092: OneCycleScheduler setting learning rate to 6.144730451675571e-05.\n",
      " 93/343 [=======>......................] - ETA: 4:30 - loss: 0.7276 - acc: 0.7298 - kappa: 0.8690\n",
      "Iteration 000093: OneCycleScheduler setting learning rate to 6.168042739193783e-05.\n",
      " 94/343 [=======>......................] - ETA: 4:28 - loss: 0.7283 - acc: 0.7301 - kappa: 0.8691\n",
      "Iteration 000094: OneCycleScheduler setting learning rate to 6.191355026711997e-05.\n",
      " 95/343 [=======>......................] - ETA: 4:27 - loss: 0.7279 - acc: 0.7303 - kappa: 0.8692\n",
      "Iteration 000095: OneCycleScheduler setting learning rate to 6.21466731423021e-05.\n",
      " 96/343 [=======>......................] - ETA: 4:25 - loss: 0.7270 - acc: 0.7292 - kappa: 0.8692\n",
      "Iteration 000096: OneCycleScheduler setting learning rate to 6.237979601748422e-05.\n",
      " 97/343 [=======>......................] - ETA: 4:24 - loss: 0.7267 - acc: 0.7294 - kappa: 0.8702\n",
      "Iteration 000097: OneCycleScheduler setting learning rate to 6.261291889266635e-05.\n",
      " 98/343 [=======>......................] - ETA: 4:22 - loss: 0.7272 - acc: 0.7270 - kappa: 0.8696\n",
      "Iteration 000098: OneCycleScheduler setting learning rate to 6.284604176784847e-05.\n",
      " 99/343 [=======>......................] - ETA: 4:21 - loss: 0.7255 - acc: 0.7260 - kappa: 0.8696\n",
      "Iteration 000099: OneCycleScheduler setting learning rate to 6.307916464303061e-05.\n",
      "100/343 [=======>......................] - ETA: 4:20 - loss: 0.7213 - acc: 0.7275 - kappa: 0.8709\n",
      "Iteration 000100: OneCycleScheduler setting learning rate to 6.331228751821274e-05.\n",
      "101/343 [=======>......................] - ETA: 4:18 - loss: 0.7202 - acc: 0.7265 - kappa: 0.8709\n",
      "Iteration 000101: OneCycleScheduler setting learning rate to 6.354541039339486e-05.\n",
      "102/343 [=======>......................] - ETA: 4:17 - loss: 0.7182 - acc: 0.7279 - kappa: 0.8721\n",
      "Iteration 000102: OneCycleScheduler setting learning rate to 6.377853326857699e-05.\n",
      "103/343 [========>.....................] - ETA: 4:15 - loss: 0.7151 - acc: 0.7294 - kappa: 0.8733\n",
      "Iteration 000103: OneCycleScheduler setting learning rate to 6.401165614375911e-05.\n",
      "104/343 [========>.....................] - ETA: 4:12 - loss: 0.7112 - acc: 0.7320 - kappa: 0.8745\n",
      "Iteration 000104: OneCycleScheduler setting learning rate to 6.424477901894124e-05.\n",
      "105/343 [========>.....................] - ETA: 4:12 - loss: 0.7188 - acc: 0.7298 - kappa: 0.8682\n",
      "Iteration 000105: OneCycleScheduler setting learning rate to 6.447790189412336e-05.\n",
      "106/343 [========>.....................] - ETA: 4:11 - loss: 0.7218 - acc: 0.7288 - kappa: 0.8688\n",
      "Iteration 000106: OneCycleScheduler setting learning rate to 6.471102476930549e-05.\n",
      "107/343 [========>.....................] - ETA: 4:09 - loss: 0.7223 - acc: 0.7278 - kappa: 0.8689\n",
      "Iteration 000107: OneCycleScheduler setting learning rate to 6.494414764448761e-05.\n",
      "108/343 [========>.....................] - ETA: 4:08 - loss: 0.7291 - acc: 0.7245 - kappa: 0.8683\n",
      "Iteration 000108: OneCycleScheduler setting learning rate to 6.517727051966975e-05.\n",
      "109/343 [========>.....................] - ETA: 4:08 - loss: 0.7320 - acc: 0.7236 - kappa: 0.8683\n",
      "Iteration 000109: OneCycleScheduler setting learning rate to 6.541039339485188e-05.\n",
      "110/343 [========>.....................] - ETA: 4:07 - loss: 0.7315 - acc: 0.7239 - kappa: 0.8689\n",
      "Iteration 000110: OneCycleScheduler setting learning rate to 6.5643516270034e-05.\n",
      "111/343 [========>.....................] - ETA: 4:05 - loss: 0.7293 - acc: 0.7252 - kappa: 0.8698\n",
      "Iteration 000111: OneCycleScheduler setting learning rate to 6.587663914521613e-05.\n",
      "112/343 [========>.....................] - ETA: 4:04 - loss: 0.7274 - acc: 0.7266 - kappa: 0.8709\n",
      "Iteration 000112: OneCycleScheduler setting learning rate to 6.610976202039825e-05.\n",
      "113/343 [========>.....................] - ETA: 4:03 - loss: 0.7225 - acc: 0.7290 - kappa: 0.8720\n",
      "Iteration 000113: OneCycleScheduler setting learning rate to 6.634288489558039e-05.\n",
      "114/343 [========>.....................] - ETA: 4:01 - loss: 0.7196 - acc: 0.7303 - kappa: 0.8731\n",
      "Iteration 000114: OneCycleScheduler setting learning rate to 6.657600777076252e-05.\n",
      "115/343 [=========>....................] - ETA: 4:00 - loss: 0.7185 - acc: 0.7304 - kappa: 0.8739\n",
      "Iteration 000115: OneCycleScheduler setting learning rate to 6.680913064594464e-05.\n",
      "116/343 [=========>....................] - ETA: 3:59 - loss: 0.7146 - acc: 0.7328 - kappa: 0.8750\n",
      "Iteration 000116: OneCycleScheduler setting learning rate to 6.704225352112677e-05.\n",
      "117/343 [=========>....................] - ETA: 3:57 - loss: 0.7138 - acc: 0.7340 - kappa: 0.8760\n",
      "Iteration 000117: OneCycleScheduler setting learning rate to 6.727537639630889e-05.\n",
      "118/343 [=========>....................] - ETA: 3:56 - loss: 0.7141 - acc: 0.7341 - kappa: 0.8768\n",
      "Iteration 000118: OneCycleScheduler setting learning rate to 6.750849927149102e-05.\n",
      "119/343 [=========>....................] - ETA: 3:55 - loss: 0.7125 - acc: 0.7353 - kappa: 0.8776\n",
      "Iteration 000119: OneCycleScheduler setting learning rate to 6.774162214667314e-05.\n",
      "120/343 [=========>....................] - ETA: 3:53 - loss: 0.7116 - acc: 0.7344 - kappa: 0.8770\n",
      "Iteration 000120: OneCycleScheduler setting learning rate to 6.797474502185527e-05.\n",
      "121/343 [=========>....................] - ETA: 3:52 - loss: 0.7070 - acc: 0.7366 - kappa: 0.8780\n",
      "Iteration 000121: OneCycleScheduler setting learning rate to 6.82078678970374e-05.\n",
      "122/343 [=========>....................] - ETA: 3:50 - loss: 0.7086 - acc: 0.7367 - kappa: 0.8779\n",
      "Iteration 000122: OneCycleScheduler setting learning rate to 6.844099077221953e-05.\n",
      "123/343 [=========>....................] - ETA: 3:49 - loss: 0.7073 - acc: 0.7358 - kappa: 0.8774\n",
      "Iteration 000123: OneCycleScheduler setting learning rate to 6.867411364740166e-05.\n",
      "124/343 [=========>....................] - ETA: 3:48 - loss: 0.7165 - acc: 0.7329 - kappa: 0.8732\n",
      "Iteration 000124: OneCycleScheduler setting learning rate to 6.890723652258378e-05.\n",
      "125/343 [=========>....................] - ETA: 3:47 - loss: 0.7153 - acc: 0.7340 - kappa: 0.8742\n",
      "Iteration 000125: OneCycleScheduler setting learning rate to 6.914035939776591e-05.\n",
      "126/343 [==========>...................] - ETA: 3:45 - loss: 0.7210 - acc: 0.7331 - kappa: 0.8742\n",
      "Iteration 000126: OneCycleScheduler setting learning rate to 6.937348227294805e-05.\n",
      "127/343 [==========>...................] - ETA: 3:44 - loss: 0.7195 - acc: 0.7333 - kappa: 0.8742\n",
      "Iteration 000127: OneCycleScheduler setting learning rate to 6.960660514813017e-05.\n",
      "128/343 [==========>...................] - ETA: 3:43 - loss: 0.7238 - acc: 0.7324 - kappa: 0.8730\n",
      "Iteration 000128: OneCycleScheduler setting learning rate to 6.98397280233123e-05.\n",
      "129/343 [==========>...................] - ETA: 3:42 - loss: 0.7248 - acc: 0.7306 - kappa: 0.8725\n",
      "Iteration 000129: OneCycleScheduler setting learning rate to 7.007285089849442e-05.\n",
      "130/343 [==========>...................] - ETA: 3:41 - loss: 0.7251 - acc: 0.7317 - kappa: 0.8734\n",
      "Iteration 000130: OneCycleScheduler setting learning rate to 7.030597377367655e-05.\n",
      "131/343 [==========>...................] - ETA: 3:41 - loss: 0.7332 - acc: 0.7300 - kappa: 0.8705\n",
      "Iteration 000131: OneCycleScheduler setting learning rate to 7.053909664885867e-05.\n",
      "132/343 [==========>...................] - ETA: 3:39 - loss: 0.7324 - acc: 0.7292 - kappa: 0.8706\n",
      "Iteration 000132: OneCycleScheduler setting learning rate to 7.07722195240408e-05.\n",
      "133/343 [==========>...................] - ETA: 3:38 - loss: 0.7284 - acc: 0.7303 - kappa: 0.8715\n",
      "Iteration 000133: OneCycleScheduler setting learning rate to 7.100534239922292e-05.\n",
      "134/343 [==========>...................] - ETA: 3:37 - loss: 0.7312 - acc: 0.7276 - kappa: 0.8687\n",
      "Iteration 000134: OneCycleScheduler setting learning rate to 7.123846527440505e-05.\n",
      "135/343 [==========>...................] - ETA: 3:36 - loss: 0.7304 - acc: 0.7287 - kappa: 0.8696\n",
      "Iteration 000135: OneCycleScheduler setting learning rate to 7.147158814958719e-05.\n",
      "136/343 [==========>...................] - ETA: 3:36 - loss: 0.7332 - acc: 0.7270 - kappa: 0.8685\n",
      "Iteration 000136: OneCycleScheduler setting learning rate to 7.170471102476931e-05.\n",
      "137/343 [==========>...................] - ETA: 3:34 - loss: 0.7338 - acc: 0.7254 - kappa: 0.8680\n",
      "Iteration 000137: OneCycleScheduler setting learning rate to 7.193783389995144e-05.\n",
      "138/343 [===========>..................] - ETA: 3:33 - loss: 0.7324 - acc: 0.7246 - kappa: 0.8676\n",
      "Iteration 000138: OneCycleScheduler setting learning rate to 7.217095677513358e-05.\n",
      "139/343 [===========>..................] - ETA: 3:31 - loss: 0.7315 - acc: 0.7248 - kappa: 0.8680\n",
      "Iteration 000139: OneCycleScheduler setting learning rate to 7.24040796503157e-05.\n",
      "140/343 [===========>..................] - ETA: 3:30 - loss: 0.7292 - acc: 0.7259 - kappa: 0.8689\n",
      "Iteration 000140: OneCycleScheduler setting learning rate to 7.263720252549783e-05.\n",
      "141/343 [===========>..................] - ETA: 3:29 - loss: 0.7272 - acc: 0.7270 - kappa: 0.8698\n",
      "Iteration 000141: OneCycleScheduler setting learning rate to 7.287032540067995e-05.\n",
      "142/343 [===========>..................] - ETA: 3:27 - loss: 0.7342 - acc: 0.7254 - kappa: 0.8693\n",
      "Iteration 000142: OneCycleScheduler setting learning rate to 7.310344827586208e-05.\n",
      "143/343 [===========>..................] - ETA: 3:26 - loss: 0.7365 - acc: 0.7238 - kappa: 0.8689\n",
      "Iteration 000143: OneCycleScheduler setting learning rate to 7.33365711510442e-05.\n",
      "144/343 [===========>..................] - ETA: 3:25 - loss: 0.7343 - acc: 0.7240 - kappa: 0.8693\n",
      "Iteration 000144: OneCycleScheduler setting learning rate to 7.356969402622633e-05.\n",
      "145/343 [===========>..................] - ETA: 3:23 - loss: 0.7324 - acc: 0.7250 - kappa: 0.8700\n",
      "Iteration 000145: OneCycleScheduler setting learning rate to 7.380281690140845e-05.\n",
      "146/343 [===========>..................] - ETA: 3:22 - loss: 0.7314 - acc: 0.7252 - kappa: 0.8707\n",
      "Iteration 000146: OneCycleScheduler setting learning rate to 7.403593977659058e-05.\n",
      "147/343 [===========>..................] - ETA: 3:21 - loss: 0.7307 - acc: 0.7253 - kappa: 0.8711\n",
      "Iteration 000147: OneCycleScheduler setting learning rate to 7.42690626517727e-05.\n",
      "148/343 [===========>..................] - ETA: 3:20 - loss: 0.7360 - acc: 0.7247 - kappa: 0.8711\n",
      "Iteration 000148: OneCycleScheduler setting learning rate to 7.450218552695484e-05.\n",
      "149/343 [============>.................] - ETA: 3:19 - loss: 0.7337 - acc: 0.7257 - kappa: 0.8717\n",
      "Iteration 000149: OneCycleScheduler setting learning rate to 7.473530840213697e-05.\n",
      "150/343 [============>.................] - ETA: 3:18 - loss: 0.7309 - acc: 0.7275 - kappa: 0.8726\n",
      "Iteration 000150: OneCycleScheduler setting learning rate to 7.496843127731909e-05.\n",
      "151/343 [============>.................] - ETA: 3:17 - loss: 0.7290 - acc: 0.7276 - kappa: 0.8730\n",
      "Iteration 000151: OneCycleScheduler setting learning rate to 7.520155415250122e-05.\n",
      "152/343 [============>.................] - ETA: 3:16 - loss: 0.7263 - acc: 0.7286 - kappa: 0.8738\n",
      "Iteration 000152: OneCycleScheduler setting learning rate to 7.543467702768336e-05.\n",
      "153/343 [============>.................] - ETA: 3:15 - loss: 0.7283 - acc: 0.7279 - kappa: 0.8728\n",
      "Iteration 000153: OneCycleScheduler setting learning rate to 7.566779990286548e-05.\n",
      "154/343 [============>.................] - ETA: 3:14 - loss: 0.7258 - acc: 0.7297 - kappa: 0.8736\n",
      "Iteration 000154: OneCycleScheduler setting learning rate to 7.59009227780476e-05.\n",
      "155/343 [============>.................] - ETA: 3:13 - loss: 0.7232 - acc: 0.7315 - kappa: 0.8744\n",
      "Iteration 000155: OneCycleScheduler setting learning rate to 7.613404565322973e-05.\n",
      "156/343 [============>.................] - ETA: 3:11 - loss: 0.7248 - acc: 0.7316 - kappa: 0.8747\n",
      "Iteration 000156: OneCycleScheduler setting learning rate to 7.636716852841186e-05.\n",
      "157/343 [============>.................] - ETA: 3:10 - loss: 0.7230 - acc: 0.7325 - kappa: 0.8748\n",
      "Iteration 000157: OneCycleScheduler setting learning rate to 7.660029140359398e-05.\n",
      "158/343 [============>.................] - ETA: 3:08 - loss: 0.7288 - acc: 0.7302 - kappa: 0.8724\n",
      "Iteration 000158: OneCycleScheduler setting learning rate to 7.683341427877611e-05.\n",
      "159/343 [============>.................] - ETA: 3:07 - loss: 0.7321 - acc: 0.7296 - kappa: 0.8724\n",
      "Iteration 000159: OneCycleScheduler setting learning rate to 7.706653715395823e-05.\n",
      "160/343 [============>.................] - ETA: 3:06 - loss: 0.7302 - acc: 0.7305 - kappa: 0.8731\n",
      "Iteration 000160: OneCycleScheduler setting learning rate to 7.729966002914036e-05.\n",
      "161/343 [=============>................] - ETA: 3:05 - loss: 0.7291 - acc: 0.7306 - kappa: 0.8735\n",
      "Iteration 000161: OneCycleScheduler setting learning rate to 7.753278290432248e-05.\n",
      "162/343 [=============>................] - ETA: 3:04 - loss: 0.7300 - acc: 0.7292 - kappa: 0.8735\n",
      "Iteration 000162: OneCycleScheduler setting learning rate to 7.776590577950462e-05.\n",
      "163/343 [=============>................] - ETA: 3:03 - loss: 0.7291 - acc: 0.7293 - kappa: 0.8738\n",
      "Iteration 000163: OneCycleScheduler setting learning rate to 7.799902865468675e-05.\n",
      "164/343 [=============>................] - ETA: 3:02 - loss: 0.7293 - acc: 0.7287 - kappa: 0.8739\n",
      "Iteration 000164: OneCycleScheduler setting learning rate to 7.823215152986887e-05.\n",
      "165/343 [=============>................] - ETA: 3:01 - loss: 0.7266 - acc: 0.7295 - kappa: 0.8746\n",
      "Iteration 000165: OneCycleScheduler setting learning rate to 7.846527440505101e-05.\n",
      "166/343 [=============>................] - ETA: 3:01 - loss: 0.7275 - acc: 0.7289 - kappa: 0.8746\n",
      "Iteration 000166: OneCycleScheduler setting learning rate to 7.869839728023314e-05.\n",
      "167/343 [=============>................] - ETA: 3:00 - loss: 0.7343 - acc: 0.7260 - kappa: 0.8686\n",
      "Iteration 000167: OneCycleScheduler setting learning rate to 7.893152015541526e-05.\n",
      "168/343 [=============>................] - ETA: 2:59 - loss: 0.7351 - acc: 0.7254 - kappa: 0.8677\n",
      "Iteration 000168: OneCycleScheduler setting learning rate to 7.916464303059739e-05.\n",
      "169/343 [=============>................] - ETA: 2:58 - loss: 0.7350 - acc: 0.7249 - kappa: 0.8677\n",
      "Iteration 000169: OneCycleScheduler setting learning rate to 7.939776590577951e-05.\n",
      "170/343 [=============>................] - ETA: 2:57 - loss: 0.7369 - acc: 0.7235 - kappa: 0.8669\n",
      "Iteration 000170: OneCycleScheduler setting learning rate to 7.963088878096164e-05.\n",
      "171/343 [=============>................] - ETA: 2:56 - loss: 0.7372 - acc: 0.7244 - kappa: 0.8676\n",
      "Iteration 000171: OneCycleScheduler setting learning rate to 7.986401165614376e-05.\n",
      "172/343 [==============>...............] - ETA: 2:55 - loss: 0.7383 - acc: 0.7231 - kappa: 0.8672\n",
      "Iteration 000172: OneCycleScheduler setting learning rate to 8.009713453132589e-05.\n",
      "173/343 [==============>...............] - ETA: 2:54 - loss: 0.7377 - acc: 0.7233 - kappa: 0.8678\n",
      "Iteration 000173: OneCycleScheduler setting learning rate to 8.033025740650801e-05.\n",
      "174/343 [==============>...............] - ETA: 2:53 - loss: 0.7377 - acc: 0.7234 - kappa: 0.8679\n",
      "Iteration 000174: OneCycleScheduler setting learning rate to 8.056338028169014e-05.\n",
      "175/343 [==============>...............] - ETA: 2:52 - loss: 0.7397 - acc: 0.7221 - kappa: 0.8664\n",
      "Iteration 000175: OneCycleScheduler setting learning rate to 8.079650315687228e-05.\n",
      "176/343 [==============>...............] - ETA: 2:51 - loss: 0.7417 - acc: 0.7216 - kappa: 0.8661\n",
      "Iteration 000176: OneCycleScheduler setting learning rate to 8.10296260320544e-05.\n",
      "177/343 [==============>...............] - ETA: 2:50 - loss: 0.7411 - acc: 0.7210 - kappa: 0.8661\n",
      "Iteration 000177: OneCycleScheduler setting learning rate to 8.126274890723653e-05.\n",
      "178/343 [==============>...............] - ETA: 2:49 - loss: 0.7392 - acc: 0.7219 - kappa: 0.8668\n",
      "Iteration 000178: OneCycleScheduler setting learning rate to 8.149587178241867e-05.\n",
      "179/343 [==============>...............] - ETA: 2:47 - loss: 0.7378 - acc: 0.7228 - kappa: 0.8675\n",
      "Iteration 000179: OneCycleScheduler setting learning rate to 8.172899465760079e-05.\n",
      "180/343 [==============>...............] - ETA: 2:46 - loss: 0.7383 - acc: 0.7215 - kappa: 0.8672\n",
      "Iteration 000180: OneCycleScheduler setting learning rate to 8.196211753278292e-05.\n",
      "181/343 [==============>...............] - ETA: 2:45 - loss: 0.7361 - acc: 0.7224 - kappa: 0.8679\n",
      "Iteration 000181: OneCycleScheduler setting learning rate to 8.219524040796504e-05.\n",
      "182/343 [==============>...............] - ETA: 2:44 - loss: 0.7388 - acc: 0.7212 - kappa: 0.8675\n",
      "Iteration 000182: OneCycleScheduler setting learning rate to 8.242836328314717e-05.\n",
      "183/343 [===============>..............] - ETA: 2:43 - loss: 0.7382 - acc: 0.7213 - kappa: 0.8679\n",
      "Iteration 000183: OneCycleScheduler setting learning rate to 8.266148615832929e-05.\n",
      "184/343 [===============>..............] - ETA: 2:42 - loss: 0.7378 - acc: 0.7215 - kappa: 0.8684\n",
      "Iteration 000184: OneCycleScheduler setting learning rate to 8.289460903351142e-05.\n",
      "185/343 [===============>..............] - ETA: 2:41 - loss: 0.7368 - acc: 0.7216 - kappa: 0.8688\n",
      "Iteration 000185: OneCycleScheduler setting learning rate to 8.312773190869354e-05.\n",
      "186/343 [===============>..............] - ETA: 2:40 - loss: 0.7370 - acc: 0.7224 - kappa: 0.8693\n",
      "Iteration 000186: OneCycleScheduler setting learning rate to 8.336085478387567e-05.\n",
      "187/343 [===============>..............] - ETA: 2:39 - loss: 0.7341 - acc: 0.7239 - kappa: 0.8700\n",
      "Iteration 000187: OneCycleScheduler setting learning rate to 8.359397765905779e-05.\n",
      "188/343 [===============>..............] - ETA: 2:37 - loss: 0.7354 - acc: 0.7241 - kappa: 0.8705\n",
      "Iteration 000188: OneCycleScheduler setting learning rate to 8.382710053423993e-05.\n",
      "189/343 [===============>..............] - ETA: 2:36 - loss: 0.7352 - acc: 0.7242 - kappa: 0.8705\n",
      "Iteration 000189: OneCycleScheduler setting learning rate to 8.406022340942206e-05.\n",
      "190/343 [===============>..............] - ETA: 2:35 - loss: 0.7364 - acc: 0.7237 - kappa: 0.8706\n",
      "Iteration 000190: OneCycleScheduler setting learning rate to 8.429334628460418e-05.\n",
      "191/343 [===============>..............] - ETA: 2:34 - loss: 0.7366 - acc: 0.7232 - kappa: 0.8706\n",
      "Iteration 000191: OneCycleScheduler setting learning rate to 8.452646915978631e-05.\n",
      "192/343 [===============>..............] - ETA: 2:33 - loss: 0.7385 - acc: 0.7233 - kappa: 0.8702\n",
      "Iteration 000192: OneCycleScheduler setting learning rate to 8.475959203496845e-05.\n",
      "193/343 [===============>..............] - ETA: 2:32 - loss: 0.7365 - acc: 0.7241 - kappa: 0.8709\n",
      "Iteration 000193: OneCycleScheduler setting learning rate to 8.499271491015057e-05.\n",
      "194/343 [===============>..............] - ETA: 2:31 - loss: 0.7377 - acc: 0.7249 - kappa: 0.8714\n",
      "Iteration 000194: OneCycleScheduler setting learning rate to 8.52258377853327e-05.\n",
      "195/343 [================>.............] - ETA: 2:30 - loss: 0.7375 - acc: 0.7250 - kappa: 0.8719\n",
      "Iteration 000195: OneCycleScheduler setting learning rate to 8.545896066051482e-05.\n",
      "196/343 [================>.............] - ETA: 2:29 - loss: 0.7350 - acc: 0.7258 - kappa: 0.8725\n",
      "Iteration 000196: OneCycleScheduler setting learning rate to 8.569208353569695e-05.\n",
      "197/343 [================>.............] - ETA: 2:28 - loss: 0.7338 - acc: 0.7259 - kappa: 0.8728\n",
      "Iteration 000197: OneCycleScheduler setting learning rate to 8.592520641087907e-05.\n",
      "198/343 [================>.............] - ETA: 2:27 - loss: 0.7327 - acc: 0.7266 - kappa: 0.8734\n",
      "Iteration 000198: OneCycleScheduler setting learning rate to 8.61583292860612e-05.\n",
      "199/343 [================>.............] - ETA: 2:26 - loss: 0.7311 - acc: 0.7274 - kappa: 0.8740\n",
      "Iteration 000199: OneCycleScheduler setting learning rate to 8.639145216124332e-05.\n",
      "200/343 [================>.............] - ETA: 2:25 - loss: 0.7324 - acc: 0.7275 - kappa: 0.8740\n",
      "Iteration 000200: OneCycleScheduler setting learning rate to 8.662457503642545e-05.\n",
      "201/343 [================>.............] - ETA: 2:24 - loss: 0.7400 - acc: 0.7257 - kappa: 0.8721\n",
      "Iteration 000201: OneCycleScheduler setting learning rate to 8.685769791160757e-05.\n",
      "202/343 [================>.............] - ETA: 2:23 - loss: 0.7394 - acc: 0.7259 - kappa: 0.8726\n",
      "Iteration 000202: OneCycleScheduler setting learning rate to 8.709082078678971e-05.\n",
      "203/343 [================>.............] - ETA: 2:21 - loss: 0.7394 - acc: 0.7254 - kappa: 0.8726\n",
      "Iteration 000203: OneCycleScheduler setting learning rate to 8.732394366197184e-05.\n",
      "204/343 [================>.............] - ETA: 2:20 - loss: 0.7377 - acc: 0.7267 - kappa: 0.8732\n",
      "Iteration 000204: OneCycleScheduler setting learning rate to 8.755706653715396e-05.\n",
      "205/343 [================>.............] - ETA: 2:19 - loss: 0.7385 - acc: 0.7262 - kappa: 0.8732\n",
      "Iteration 000205: OneCycleScheduler setting learning rate to 8.77901894123361e-05.\n",
      "206/343 [=================>............] - ETA: 2:18 - loss: 0.7385 - acc: 0.7257 - kappa: 0.8733\n",
      "Iteration 000206: OneCycleScheduler setting learning rate to 8.802331228751823e-05.\n",
      "207/343 [=================>............] - ETA: 2:17 - loss: 0.7390 - acc: 0.7252 - kappa: 0.8725\n",
      "Iteration 000207: OneCycleScheduler setting learning rate to 8.825643516270035e-05.\n",
      "208/343 [=================>............] - ETA: 2:16 - loss: 0.7420 - acc: 0.7242 - kappa: 0.8722\n",
      "Iteration 000208: OneCycleScheduler setting learning rate to 8.848955803788248e-05.\n",
      "209/343 [=================>............] - ETA: 2:15 - loss: 0.7410 - acc: 0.7249 - kappa: 0.8728\n",
      "Iteration 000209: OneCycleScheduler setting learning rate to 8.87226809130646e-05.\n",
      "210/343 [=================>............] - ETA: 2:14 - loss: 0.7397 - acc: 0.7250 - kappa: 0.8732\n",
      "Iteration 000210: OneCycleScheduler setting learning rate to 8.895580378824673e-05.\n",
      "211/343 [=================>............] - ETA: 2:13 - loss: 0.7389 - acc: 0.7251 - kappa: 0.8737\n",
      "Iteration 000211: OneCycleScheduler setting learning rate to 8.918892666342885e-05.\n",
      "212/343 [=================>............] - ETA: 2:12 - loss: 0.7391 - acc: 0.7246 - kappa: 0.8737\n",
      "Iteration 000212: OneCycleScheduler setting learning rate to 8.942204953861098e-05.\n",
      "213/343 [=================>............] - ETA: 2:11 - loss: 0.7387 - acc: 0.7242 - kappa: 0.8739\n",
      "Iteration 000213: OneCycleScheduler setting learning rate to 8.96551724137931e-05.\n",
      "214/343 [=================>............] - ETA: 2:10 - loss: 0.7367 - acc: 0.7249 - kappa: 0.8745\n",
      "Iteration 000214: OneCycleScheduler setting learning rate to 8.988829528897523e-05.\n",
      "215/343 [=================>............] - ETA: 2:09 - loss: 0.7372 - acc: 0.7250 - kappa: 0.8749\n",
      "Iteration 000215: OneCycleScheduler setting learning rate to 9.012141816415737e-05.\n",
      "216/343 [=================>............] - ETA: 2:08 - loss: 0.7361 - acc: 0.7251 - kappa: 0.8752\n",
      "Iteration 000216: OneCycleScheduler setting learning rate to 9.035454103933949e-05.\n",
      "217/343 [=================>............] - ETA: 2:07 - loss: 0.7347 - acc: 0.7264 - kappa: 0.8758\n",
      "Iteration 000217: OneCycleScheduler setting learning rate to 9.058766391452162e-05.\n",
      "218/343 [==================>...........] - ETA: 2:05 - loss: 0.7333 - acc: 0.7265 - kappa: 0.8754\n",
      "Iteration 000218: OneCycleScheduler setting learning rate to 9.082078678970376e-05.\n",
      "219/343 [==================>...........] - ETA: 2:05 - loss: 0.7332 - acc: 0.7266 - kappa: 0.8757\n",
      "Iteration 000219: OneCycleScheduler setting learning rate to 9.105390966488588e-05.\n",
      "220/343 [==================>...........] - ETA: 2:04 - loss: 0.7321 - acc: 0.7273 - kappa: 0.8761\n",
      "Iteration 000220: OneCycleScheduler setting learning rate to 9.1287032540068e-05.\n",
      "221/343 [==================>...........] - ETA: 2:03 - loss: 0.7325 - acc: 0.7268 - kappa: 0.8754\n",
      "Iteration 000221: OneCycleScheduler setting learning rate to 9.152015541525013e-05.\n",
      "222/343 [==================>...........] - ETA: 2:02 - loss: 0.7379 - acc: 0.7252 - kappa: 0.8742\n",
      "Iteration 000222: OneCycleScheduler setting learning rate to 9.175327829043226e-05.\n",
      "223/343 [==================>...........] - ETA: 2:01 - loss: 0.7394 - acc: 0.7237 - kappa: 0.8735\n",
      "Iteration 000223: OneCycleScheduler setting learning rate to 9.198640116561438e-05.\n",
      "224/343 [==================>...........] - ETA: 2:00 - loss: 0.7382 - acc: 0.7238 - kappa: 0.8740\n",
      "Iteration 000224: OneCycleScheduler setting learning rate to 9.221952404079651e-05.\n",
      "225/343 [==================>...........] - ETA: 1:59 - loss: 0.7362 - acc: 0.7250 - kappa: 0.8745\n",
      "Iteration 000225: OneCycleScheduler setting learning rate to 9.245264691597863e-05.\n",
      "226/343 [==================>...........] - ETA: 1:58 - loss: 0.7365 - acc: 0.7246 - kappa: 0.8742\n",
      "Iteration 000226: OneCycleScheduler setting learning rate to 9.268576979116076e-05.\n",
      "227/343 [==================>...........] - ETA: 1:57 - loss: 0.7355 - acc: 0.7247 - kappa: 0.8742\n",
      "Iteration 000227: OneCycleScheduler setting learning rate to 9.291889266634288e-05.\n",
      "228/343 [==================>...........] - ETA: 1:56 - loss: 0.7356 - acc: 0.7242 - kappa: 0.8742\n",
      "Iteration 000228: OneCycleScheduler setting learning rate to 9.315201554152502e-05.\n",
      "229/343 [===================>..........] - ETA: 1:55 - loss: 0.7348 - acc: 0.7243 - kappa: 0.8746\n",
      "Iteration 000229: OneCycleScheduler setting learning rate to 9.338513841670715e-05.\n",
      "230/343 [===================>..........] - ETA: 1:54 - loss: 0.7334 - acc: 0.7250 - kappa: 0.8750\n",
      "Iteration 000230: OneCycleScheduler setting learning rate to 9.361826129188927e-05.\n",
      "231/343 [===================>..........] - ETA: 1:53 - loss: 0.7314 - acc: 0.7262 - kappa: 0.8756\n",
      "Iteration 000231: OneCycleScheduler setting learning rate to 9.38513841670714e-05.\n",
      "232/343 [===================>..........] - ETA: 1:52 - loss: 0.7301 - acc: 0.7268 - kappa: 0.8760\n",
      "Iteration 000232: OneCycleScheduler setting learning rate to 9.408450704225354e-05.\n",
      "233/343 [===================>..........] - ETA: 1:51 - loss: 0.7368 - acc: 0.7248 - kappa: 0.8744\n",
      "Iteration 000233: OneCycleScheduler setting learning rate to 9.431762991743566e-05.\n",
      "234/343 [===================>..........] - ETA: 1:50 - loss: 0.7393 - acc: 0.7233 - kappa: 0.8737\n",
      "Iteration 000234: OneCycleScheduler setting learning rate to 9.455075279261779e-05.\n",
      "235/343 [===================>..........] - ETA: 1:49 - loss: 0.7391 - acc: 0.7239 - kappa: 0.8742\n",
      "Iteration 000235: OneCycleScheduler setting learning rate to 9.478387566779991e-05.\n",
      "236/343 [===================>..........] - ETA: 1:48 - loss: 0.7386 - acc: 0.7246 - kappa: 0.8746\n",
      "Iteration 000236: OneCycleScheduler setting learning rate to 9.501699854298204e-05.\n",
      "237/343 [===================>..........] - ETA: 1:47 - loss: 0.7382 - acc: 0.7242 - kappa: 0.8746\n",
      "Iteration 000237: OneCycleScheduler setting learning rate to 9.525012141816416e-05.\n",
      "238/343 [===================>..........] - ETA: 1:46 - loss: 0.7406 - acc: 0.7237 - kappa: 0.8743\n",
      "Iteration 000238: OneCycleScheduler setting learning rate to 9.548324429334629e-05.\n",
      "239/343 [===================>..........] - ETA: 1:45 - loss: 0.7409 - acc: 0.7233 - kappa: 0.8743\n",
      "Iteration 000239: OneCycleScheduler setting learning rate to 9.571636716852841e-05.\n",
      "240/343 [===================>..........] - ETA: 1:44 - loss: 0.7406 - acc: 0.7240 - kappa: 0.8748\n",
      "Iteration 000240: OneCycleScheduler setting learning rate to 9.594949004371054e-05.\n",
      "241/343 [====================>.........] - ETA: 1:43 - loss: 0.7409 - acc: 0.7241 - kappa: 0.8752\n",
      "Iteration 000241: OneCycleScheduler setting learning rate to 9.618261291889266e-05.\n",
      "242/343 [====================>.........] - ETA: 1:42 - loss: 0.7414 - acc: 0.7237 - kappa: 0.8741\n",
      "Iteration 000242: OneCycleScheduler setting learning rate to 9.64157357940748e-05.\n",
      "243/343 [====================>.........] - ETA: 1:40 - loss: 0.7409 - acc: 0.7238 - kappa: 0.8745\n",
      "Iteration 000243: OneCycleScheduler setting learning rate to 9.664885866925693e-05.\n",
      "244/343 [====================>.........] - ETA: 1:39 - loss: 0.7414 - acc: 0.7239 - kappa: 0.8745\n",
      "Iteration 000244: OneCycleScheduler setting learning rate to 9.688198154443905e-05.\n",
      "245/343 [====================>.........] - ETA: 1:38 - loss: 0.7425 - acc: 0.7235 - kappa: 0.8745\n",
      "Iteration 000245: OneCycleScheduler setting learning rate to 9.711510441962119e-05.\n",
      "246/343 [====================>.........] - ETA: 1:37 - loss: 0.7418 - acc: 0.7241 - kappa: 0.8747\n",
      "Iteration 000246: OneCycleScheduler setting learning rate to 9.734822729480332e-05.\n",
      "247/343 [====================>.........] - ETA: 1:36 - loss: 0.7416 - acc: 0.7242 - kappa: 0.8745\n",
      "Iteration 000247: OneCycleScheduler setting learning rate to 9.758135016998544e-05.\n",
      "248/343 [====================>.........] - ETA: 1:35 - loss: 0.7402 - acc: 0.7248 - kappa: 0.8749\n",
      "Iteration 000248: OneCycleScheduler setting learning rate to 9.781447304516757e-05.\n",
      "249/343 [====================>.........] - ETA: 1:34 - loss: 0.7394 - acc: 0.7254 - kappa: 0.8753\n",
      "Iteration 000249: OneCycleScheduler setting learning rate to 9.804759592034969e-05.\n",
      "250/343 [====================>.........] - ETA: 1:33 - loss: 0.7387 - acc: 0.7255 - kappa: 0.8755\n",
      "Iteration 000250: OneCycleScheduler setting learning rate to 9.828071879553182e-05.\n",
      "251/343 [====================>.........] - ETA: 1:32 - loss: 0.7385 - acc: 0.7256 - kappa: 0.8759\n",
      "Iteration 000251: OneCycleScheduler setting learning rate to 9.851384167071394e-05.\n",
      "252/343 [=====================>........] - ETA: 1:31 - loss: 0.7373 - acc: 0.7257 - kappa: 0.8761\n",
      "Iteration 000252: OneCycleScheduler setting learning rate to 9.874696454589607e-05.\n",
      "253/343 [=====================>........] - ETA: 1:30 - loss: 0.7359 - acc: 0.7263 - kappa: 0.8766\n",
      "Iteration 000253: OneCycleScheduler setting learning rate to 9.89800874210782e-05.\n",
      "254/343 [=====================>........] - ETA: 1:29 - loss: 0.7369 - acc: 0.7259 - kappa: 0.8768\n",
      "Iteration 000254: OneCycleScheduler setting learning rate to 9.921321029626032e-05.\n",
      "255/343 [=====================>........] - ETA: 1:28 - loss: 0.7430 - acc: 0.7245 - kappa: 0.8748\n",
      "Iteration 000255: OneCycleScheduler setting learning rate to 9.944633317144246e-05.\n",
      "256/343 [=====================>........] - ETA: 1:27 - loss: 0.7413 - acc: 0.7251 - kappa: 0.8752\n",
      "Iteration 000256: OneCycleScheduler setting learning rate to 9.967945604662458e-05.\n",
      "257/343 [=====================>........] - ETA: 1:26 - loss: 0.7435 - acc: 0.7242 - kappa: 0.8738\n",
      "Iteration 000257: OneCycleScheduler setting learning rate to 9.991257892180671e-05.\n",
      "258/343 [=====================>........] - ETA: 1:25 - loss: 0.7441 - acc: 0.7238 - kappa: 0.8740\n",
      "Iteration 000258: OneCycleScheduler setting learning rate to 0.00010014570179698885.\n",
      "259/343 [=====================>........] - ETA: 1:24 - loss: 0.7425 - acc: 0.7239 - kappa: 0.8742\n",
      "Iteration 000259: OneCycleScheduler setting learning rate to 0.00010037882467217097.\n",
      "260/343 [=====================>........] - ETA: 1:23 - loss: 0.7413 - acc: 0.7245 - kappa: 0.8747\n",
      "Iteration 000260: OneCycleScheduler setting learning rate to 0.0001006119475473531.\n",
      "261/343 [=====================>........] - ETA: 1:22 - loss: 0.7400 - acc: 0.7251 - kappa: 0.8751\n",
      "Iteration 000261: OneCycleScheduler setting learning rate to 0.00010084507042253522.\n",
      "262/343 [=====================>........] - ETA: 1:21 - loss: 0.7411 - acc: 0.7252 - kappa: 0.8749\n",
      "Iteration 000262: OneCycleScheduler setting learning rate to 0.00010107819329771735.\n",
      "263/343 [======================>.......] - ETA: 1:20 - loss: 0.7429 - acc: 0.7248 - kappa: 0.8749\n",
      "Iteration 000263: OneCycleScheduler setting learning rate to 0.00010131131617289947.\n",
      "264/343 [======================>.......] - ETA: 1:19 - loss: 0.7422 - acc: 0.7249 - kappa: 0.8749\n",
      "Iteration 000264: OneCycleScheduler setting learning rate to 0.0001015444390480816.\n",
      "265/343 [======================>.......] - ETA: 1:18 - loss: 0.7410 - acc: 0.7255 - kappa: 0.8753\n",
      "Iteration 000265: OneCycleScheduler setting learning rate to 0.00010177756192326372.\n",
      "266/343 [======================>.......] - ETA: 1:17 - loss: 0.7401 - acc: 0.7256 - kappa: 0.8756\n",
      "Iteration 000266: OneCycleScheduler setting learning rate to 0.00010201068479844585.\n",
      "267/343 [======================>.......] - ETA: 1:16 - loss: 0.7406 - acc: 0.7247 - kappa: 0.8747\n",
      "Iteration 000267: OneCycleScheduler setting learning rate to 0.00010224380767362797.\n",
      "268/343 [======================>.......] - ETA: 1:15 - loss: 0.7402 - acc: 0.7248 - kappa: 0.8750\n",
      "Iteration 000268: OneCycleScheduler setting learning rate to 0.0001024769305488101.\n",
      "269/343 [======================>.......] - ETA: 1:14 - loss: 0.7404 - acc: 0.7249 - kappa: 0.8752\n",
      "Iteration 000269: OneCycleScheduler setting learning rate to 0.00010271005342399222.\n",
      "270/343 [======================>.......] - ETA: 1:13 - loss: 0.7392 - acc: 0.7255 - kappa: 0.8757\n",
      "Iteration 000270: OneCycleScheduler setting learning rate to 0.00010294317629917438.\n",
      "271/343 [======================>.......] - ETA: 1:12 - loss: 0.7388 - acc: 0.7251 - kappa: 0.8754\n",
      "Iteration 000271: OneCycleScheduler setting learning rate to 0.0001031762991743565.\n",
      "272/343 [======================>.......] - ETA: 1:11 - loss: 0.7394 - acc: 0.7243 - kappa: 0.8748\n",
      "Iteration 000272: OneCycleScheduler setting learning rate to 0.00010340942204953863.\n",
      "273/343 [======================>.......] - ETA: 1:10 - loss: 0.7380 - acc: 0.7248 - kappa: 0.8753\n",
      "Iteration 000273: OneCycleScheduler setting learning rate to 0.00010364254492472075.\n",
      "274/343 [======================>.......] - ETA: 1:09 - loss: 0.7374 - acc: 0.7254 - kappa: 0.8757\n",
      "Iteration 000274: OneCycleScheduler setting learning rate to 0.00010387566779990288.\n",
      "275/343 [=======================>......] - ETA: 1:08 - loss: 0.7369 - acc: 0.7259 - kappa: 0.8761\n",
      "Iteration 000275: OneCycleScheduler setting learning rate to 0.000104108790675085.\n",
      "276/343 [=======================>......] - ETA: 1:07 - loss: 0.7360 - acc: 0.7260 - kappa: 0.8764\n",
      "Iteration 000276: OneCycleScheduler setting learning rate to 0.00010434191355026713.\n",
      "277/343 [=======================>......] - ETA: 1:06 - loss: 0.7421 - acc: 0.7238 - kappa: 0.8735\n",
      "Iteration 000277: OneCycleScheduler setting learning rate to 0.00010457503642544925.\n",
      "278/343 [=======================>......] - ETA: 1:05 - loss: 0.7406 - acc: 0.7244 - kappa: 0.8739\n",
      "Iteration 000278: OneCycleScheduler setting learning rate to 0.00010480815930063138.\n",
      "279/343 [=======================>......] - ETA: 1:04 - loss: 0.7400 - acc: 0.7240 - kappa: 0.8737\n",
      "Iteration 000279: OneCycleScheduler setting learning rate to 0.0001050412821758135.\n",
      "280/343 [=======================>......] - ETA: 1:03 - loss: 0.7392 - acc: 0.7241 - kappa: 0.8739\n",
      "Iteration 000280: OneCycleScheduler setting learning rate to 0.00010527440505099563.\n",
      "281/343 [=======================>......] - ETA: 1:02 - loss: 0.7396 - acc: 0.7238 - kappa: 0.8741\n",
      "Iteration 000281: OneCycleScheduler setting learning rate to 0.00010550752792617775.\n",
      "282/343 [=======================>......] - ETA: 1:01 - loss: 0.7377 - acc: 0.7247 - kappa: 0.8745\n",
      "Iteration 000282: OneCycleScheduler setting learning rate to 0.00010574065080135988.\n",
      "283/343 [=======================>......] - ETA: 1:00 - loss: 0.7371 - acc: 0.7244 - kappa: 0.8745\n",
      "Iteration 000283: OneCycleScheduler setting learning rate to 0.00010597377367654203.\n",
      "284/343 [=======================>......] - ETA: 59s - loss: 0.7355 - acc: 0.7249 - kappa: 0.8749 \n",
      "Iteration 000284: OneCycleScheduler setting learning rate to 0.00010620689655172416.\n",
      "285/343 [=======================>......] - ETA: 58s - loss: 0.7340 - acc: 0.7259 - kappa: 0.8754\n",
      "Iteration 000285: OneCycleScheduler setting learning rate to 0.00010644001942690628.\n",
      "286/343 [========================>.....] - ETA: 57s - loss: 0.7333 - acc: 0.7255 - kappa: 0.8754\n",
      "Iteration 000286: OneCycleScheduler setting learning rate to 0.00010667314230208841.\n",
      "287/343 [========================>.....] - ETA: 56s - loss: 0.7323 - acc: 0.7260 - kappa: 0.8757\n",
      "Iteration 000287: OneCycleScheduler setting learning rate to 0.00010690626517727053.\n",
      "288/343 [========================>.....] - ETA: 55s - loss: 0.7345 - acc: 0.7248 - kappa: 0.8751\n",
      "Iteration 000288: OneCycleScheduler setting learning rate to 0.00010713938805245266.\n",
      "289/343 [========================>.....] - ETA: 54s - loss: 0.7330 - acc: 0.7253 - kappa: 0.8755\n",
      "Iteration 000289: OneCycleScheduler setting learning rate to 0.00010737251092763478.\n",
      "290/343 [========================>.....] - ETA: 53s - loss: 0.7316 - acc: 0.7259 - kappa: 0.8759\n",
      "Iteration 000290: OneCycleScheduler setting learning rate to 0.00010760563380281691.\n",
      "291/343 [========================>.....] - ETA: 52s - loss: 0.7376 - acc: 0.7247 - kappa: 0.8746\n",
      "Iteration 000291: OneCycleScheduler setting learning rate to 0.00010783875667799903.\n",
      "292/343 [========================>.....] - ETA: 51s - loss: 0.7371 - acc: 0.7252 - kappa: 0.8749\n",
      "Iteration 000292: OneCycleScheduler setting learning rate to 0.00010807187955318116.\n",
      "293/343 [========================>.....] - ETA: 50s - loss: 0.7380 - acc: 0.7248 - kappa: 0.8751\n",
      "Iteration 000293: OneCycleScheduler setting learning rate to 0.00010830500242836328.\n",
      "294/343 [========================>.....] - ETA: 49s - loss: 0.7379 - acc: 0.7249 - kappa: 0.8751\n",
      "Iteration 000294: OneCycleScheduler setting learning rate to 0.00010853812530354541.\n",
      "295/343 [========================>.....] - ETA: 48s - loss: 0.7368 - acc: 0.7254 - kappa: 0.8755\n",
      "Iteration 000295: OneCycleScheduler setting learning rate to 0.00010877124817872753.\n",
      "296/343 [========================>.....] - ETA: 47s - loss: 0.7367 - acc: 0.7255 - kappa: 0.8757\n",
      "Iteration 000296: OneCycleScheduler setting learning rate to 0.00010900437105390969.\n",
      "297/343 [========================>.....] - ETA: 46s - loss: 0.7365 - acc: 0.7256 - kappa: 0.8757\n",
      "Iteration 000297: OneCycleScheduler setting learning rate to 0.00010923749392909181.\n",
      "298/343 [=========================>....] - ETA: 45s - loss: 0.7368 - acc: 0.7257 - kappa: 0.8758\n",
      "Iteration 000298: OneCycleScheduler setting learning rate to 0.00010947061680427394.\n",
      "299/343 [=========================>....] - ETA: 44s - loss: 0.7355 - acc: 0.7262 - kappa: 0.8761\n",
      "Iteration 000299: OneCycleScheduler setting learning rate to 0.00010970373967945606.\n",
      "300/343 [=========================>....] - ETA: 43s - loss: 0.7355 - acc: 0.7262 - kappa: 0.8763\n",
      "Iteration 000300: OneCycleScheduler setting learning rate to 0.00010993686255463819.\n",
      "301/343 [=========================>....] - ETA: 42s - loss: 0.7355 - acc: 0.7263 - kappa: 0.8765\n",
      "Iteration 000301: OneCycleScheduler setting learning rate to 0.00011016998542982031.\n",
      "302/343 [=========================>....] - ETA: 41s - loss: 0.7358 - acc: 0.7264 - kappa: 0.8767\n",
      "Iteration 000302: OneCycleScheduler setting learning rate to 0.00011040310830500244.\n",
      "303/343 [=========================>....] - ETA: 40s - loss: 0.7347 - acc: 0.7273 - kappa: 0.8771\n",
      "Iteration 000303: OneCycleScheduler setting learning rate to 0.00011063623118018456.\n",
      "304/343 [=========================>....] - ETA: 39s - loss: 0.7360 - acc: 0.7274 - kappa: 0.8773\n",
      "Iteration 000304: OneCycleScheduler setting learning rate to 0.00011086935405536669.\n",
      "305/343 [=========================>....] - ETA: 38s - loss: 0.7368 - acc: 0.7270 - kappa: 0.8774\n",
      "Iteration 000305: OneCycleScheduler setting learning rate to 0.00011110247693054881.\n",
      "306/343 [=========================>....] - ETA: 37s - loss: 0.7358 - acc: 0.7275 - kappa: 0.8776\n",
      "Iteration 000306: OneCycleScheduler setting learning rate to 0.00011133559980573094.\n",
      "307/343 [=========================>....] - ETA: 36s - loss: 0.7351 - acc: 0.7280 - kappa: 0.8779\n",
      "Iteration 000307: OneCycleScheduler setting learning rate to 0.00011156872268091306.\n",
      "308/343 [=========================>....] - ETA: 35s - loss: 0.7359 - acc: 0.7281 - kappa: 0.8782\n",
      "Iteration 000308: OneCycleScheduler setting learning rate to 0.00011180184555609519.\n",
      "309/343 [==========================>...] - ETA: 34s - loss: 0.7358 - acc: 0.7282 - kappa: 0.8784\n",
      "Iteration 000309: OneCycleScheduler setting learning rate to 0.00011203496843127731.\n",
      "310/343 [==========================>...] - ETA: 33s - loss: 0.7347 - acc: 0.7286 - kappa: 0.8787\n",
      "Iteration 000310: OneCycleScheduler setting learning rate to 0.00011226809130645947.\n",
      "311/343 [==========================>...] - ETA: 32s - loss: 0.7354 - acc: 0.7287 - kappa: 0.8789\n",
      "Iteration 000311: OneCycleScheduler setting learning rate to 0.00011250121418164159.\n",
      "312/343 [==========================>...] - ETA: 31s - loss: 0.7337 - acc: 0.7296 - kappa: 0.8793\n",
      "Iteration 000312: OneCycleScheduler setting learning rate to 0.00011273433705682372.\n",
      "313/343 [==========================>...] - ETA: 30s - loss: 0.7336 - acc: 0.7292 - kappa: 0.8790\n",
      "Iteration 000313: OneCycleScheduler setting learning rate to 0.00011296745993200584.\n",
      "314/343 [==========================>...] - ETA: 29s - loss: 0.7329 - acc: 0.7297 - kappa: 0.8794\n",
      "Iteration 000314: OneCycleScheduler setting learning rate to 0.00011320058280718797.\n",
      "315/343 [==========================>...] - ETA: 28s - loss: 0.7321 - acc: 0.7302 - kappa: 0.8798\n",
      "Iteration 000315: OneCycleScheduler setting learning rate to 0.00011343370568237009.\n",
      "316/343 [==========================>...] - ETA: 27s - loss: 0.7309 - acc: 0.7306 - kappa: 0.8801\n",
      "Iteration 000316: OneCycleScheduler setting learning rate to 0.00011366682855755222.\n",
      "317/343 [==========================>...] - ETA: 26s - loss: 0.7316 - acc: 0.7303 - kappa: 0.8801\n",
      "Iteration 000317: OneCycleScheduler setting learning rate to 0.00011389995143273434.\n",
      "318/343 [==========================>...] - ETA: 25s - loss: 0.7329 - acc: 0.7296 - kappa: 0.8789\n",
      "Iteration 000318: OneCycleScheduler setting learning rate to 0.00011413307430791647.\n",
      "319/343 [==========================>...] - ETA: 24s - loss: 0.7322 - acc: 0.7296 - kappa: 0.8791\n",
      "Iteration 000319: OneCycleScheduler setting learning rate to 0.0001143661971830986.\n",
      "320/343 [==========================>...] - ETA: 23s - loss: 0.7312 - acc: 0.7301 - kappa: 0.8794\n",
      "Iteration 000320: OneCycleScheduler setting learning rate to 0.00011459932005828072.\n",
      "321/343 [===========================>..] - ETA: 22s - loss: 0.7310 - acc: 0.7301 - kappa: 0.8797\n",
      "Iteration 000321: OneCycleScheduler setting learning rate to 0.00011483244293346284.\n",
      "322/343 [===========================>..] - ETA: 21s - loss: 0.7302 - acc: 0.7306 - kappa: 0.8800\n",
      "Iteration 000322: OneCycleScheduler setting learning rate to 0.00011506556580864497.\n",
      "323/343 [===========================>..] - ETA: 20s - loss: 0.7298 - acc: 0.7307 - kappa: 0.8803\n",
      "Iteration 000323: OneCycleScheduler setting learning rate to 0.00011529868868382712.\n",
      "324/343 [===========================>..] - ETA: 19s - loss: 0.7297 - acc: 0.7303 - kappa: 0.8803\n",
      "Iteration 000324: OneCycleScheduler setting learning rate to 0.00011553181155900925.\n",
      "325/343 [===========================>..] - ETA: 18s - loss: 0.7291 - acc: 0.7308 - kappa: 0.8806\n",
      "Iteration 000325: OneCycleScheduler setting learning rate to 0.00011576493443419137.\n",
      "326/343 [===========================>..] - ETA: 17s - loss: 0.7290 - acc: 0.7308 - kappa: 0.8807\n",
      "Iteration 000326: OneCycleScheduler setting learning rate to 0.0001159980573093735.\n",
      "327/343 [===========================>..] - ETA: 16s - loss: 0.7283 - acc: 0.7309 - kappa: 0.8809\n",
      "Iteration 000327: OneCycleScheduler setting learning rate to 0.00011623118018455562.\n",
      "328/343 [===========================>..] - ETA: 15s - loss: 0.7274 - acc: 0.7313 - kappa: 0.8812\n",
      "Iteration 000328: OneCycleScheduler setting learning rate to 0.00011646430305973775.\n",
      "329/343 [===========================>..] - ETA: 14s - loss: 0.7265 - acc: 0.7318 - kappa: 0.8816\n",
      "Iteration 000329: OneCycleScheduler setting learning rate to 0.00011669742593491987.\n",
      "330/343 [===========================>..] - ETA: 13s - loss: 0.7254 - acc: 0.7322 - kappa: 0.8819\n",
      "Iteration 000330: OneCycleScheduler setting learning rate to 0.000116930548810102.\n",
      "331/343 [===========================>..] - ETA: 12s - loss: 0.7257 - acc: 0.7319 - kappa: 0.8819\n",
      "Iteration 000331: OneCycleScheduler setting learning rate to 0.00011716367168528412.\n",
      "332/343 [============================>.] - ETA: 11s - loss: 0.7301 - acc: 0.7308 - kappa: 0.8794\n",
      "Iteration 000332: OneCycleScheduler setting learning rate to 0.00011739679456046625.\n",
      "333/343 [============================>.] - ETA: 10s - loss: 0.7300 - acc: 0.7305 - kappa: 0.8794\n",
      "Iteration 000333: OneCycleScheduler setting learning rate to 0.00011762991743564837.\n",
      "334/343 [============================>.] - ETA: 9s - loss: 0.7284 - acc: 0.7313 - kappa: 0.8797 \n",
      "Iteration 000334: OneCycleScheduler setting learning rate to 0.0001178630403108305.\n",
      "335/343 [============================>.] - ETA: 8s - loss: 0.7267 - acc: 0.7321 - kappa: 0.8801\n",
      "Iteration 000335: OneCycleScheduler setting learning rate to 0.00011809616318601262.\n",
      "336/343 [============================>.] - ETA: 7s - loss: 0.7272 - acc: 0.7314 - kappa: 0.8799\n",
      "Iteration 000336: OneCycleScheduler setting learning rate to 0.00011832928606119478.\n",
      "337/343 [============================>.] - ETA: 6s - loss: 0.7283 - acc: 0.7311 - kappa: 0.8791\n",
      "Iteration 000337: OneCycleScheduler setting learning rate to 0.0001185624089363769.\n",
      "338/343 [============================>.] - ETA: 5s - loss: 0.7282 - acc: 0.7311 - kappa: 0.8792\n",
      "Iteration 000338: OneCycleScheduler setting learning rate to 0.00011879553181155903.\n",
      "339/343 [============================>.] - ETA: 3s - loss: 0.7263 - acc: 0.7319 - kappa: 0.8796\n",
      "Iteration 000339: OneCycleScheduler setting learning rate to 0.00011902865468674115.\n",
      "340/343 [============================>.] - ETA: 2s - loss: 0.7262 - acc: 0.7320 - kappa: 0.8798\n",
      "Iteration 000340: OneCycleScheduler setting learning rate to 0.00011926177756192328.\n",
      "341/343 [============================>.] - ETA: 1s - loss: 0.7259 - acc: 0.7320 - kappa: 0.8801\n",
      "Iteration 000341: OneCycleScheduler setting learning rate to 0.0001194949004371054.\n",
      "342/343 [============================>.] - ETA: 0s - loss: 0.7254 - acc: 0.7325 - kappa: 0.8804\n",
      "Iteration 000342: OneCycleScheduler setting learning rate to 0.00011972802331228753.\n",
      "343/343 [==============================] - 437s 1s/step - loss: 0.7275 - acc: 0.7310 - kappa: 0.8785 - val_loss: 0.5988 - val_acc: 0.8029 - val_kappa: 0.9337\n",
      "Epoch 2/30\n",
      "\n",
      "Iteration 000000: OneCycleScheduler setting learning rate to 4e-05.\n",
      "  1/343 [..............................] - ETA: 1:00 - loss: 1.0581 - acc: 0.6250 - kappa: 0.8047\n",
      "Iteration 000001: OneCycleScheduler setting learning rate to 4.023312287518213e-05.\n",
      "  2/343 [..............................] - ETA: 1:00 - loss: 1.0110 - acc: 0.6250 - kappa: 0.8672\n",
      "Iteration 000002: OneCycleScheduler setting learning rate to 4.046624575036426e-05.\n",
      "  3/343 [..............................] - ETA: 54s - loss: 0.8790 - acc: 0.6667 - kappa: 0.9010 \n",
      "Iteration 000003: OneCycleScheduler setting learning rate to 4.0699368625546386e-05.\n",
      "  4/343 [..............................] - ETA: 53s - loss: 0.7531 - acc: 0.7188 - kappa: 0.9238\n",
      "Iteration 000004: OneCycleScheduler setting learning rate to 4.093249150072851e-05.\n",
      "  5/343 [..............................] - ETA: 51s - loss: 0.7277 - acc: 0.7250 - kappa: 0.9250\n",
      "Iteration 000005: OneCycleScheduler setting learning rate to 4.1165614375910636e-05.\n",
      "  6/343 [..............................] - ETA: 48s - loss: 0.6605 - acc: 0.7500 - kappa: 0.9323\n",
      "Iteration 000006: OneCycleScheduler setting learning rate to 4.139873725109277e-05.\n",
      "  7/343 [..............................] - ETA: 47s - loss: 0.6418 - acc: 0.7679 - kappa: 0.9408\n",
      "Iteration 000007: OneCycleScheduler setting learning rate to 4.1631860126274893e-05.\n",
      "  8/343 [..............................] - ETA: 47s - loss: 0.6049 - acc: 0.7812 - kappa: 0.9443\n",
      "Iteration 000008: OneCycleScheduler setting learning rate to 4.186498300145702e-05.\n",
      "  9/343 [..............................] - ETA: 48s - loss: 0.5800 - acc: 0.7778 - kappa: 0.9470\n",
      "Iteration 000009: OneCycleScheduler setting learning rate to 4.209810587663915e-05.\n",
      " 10/343 [..............................] - ETA: 47s - loss: 0.5374 - acc: 0.8000 - kappa: 0.9523\n",
      "Iteration 000010: OneCycleScheduler setting learning rate to 4.2331228751821276e-05.\n",
      " 11/343 [..............................] - ETA: 47s - loss: 0.5201 - acc: 0.8182 - kappa: 0.9567\n",
      "Iteration 000011: OneCycleScheduler setting learning rate to 4.25643516270034e-05.\n",
      " 12/343 [>.............................] - ETA: 1:11 - loss: 0.5412 - acc: 0.8021 - kappa: 0.9544\n",
      "Iteration 000012: OneCycleScheduler setting learning rate to 4.279747450218553e-05.\n",
      " 13/343 [>.............................] - ETA: 1:34 - loss: 0.5496 - acc: 0.7981 - kappa: 0.9555\n",
      "Iteration 000013: OneCycleScheduler setting learning rate to 4.303059737736766e-05.\n",
      " 14/343 [>.............................] - ETA: 2:09 - loss: 0.6553 - acc: 0.7768 - kappa: 0.8912\n",
      "Iteration 000014: OneCycleScheduler setting learning rate to 4.3263720252549784e-05.\n",
      " 15/343 [>.............................] - ETA: 2:45 - loss: 0.6624 - acc: 0.7750 - kappa: 0.8964\n",
      "Iteration 000015: OneCycleScheduler setting learning rate to 4.3496843127731916e-05.\n",
      " 16/343 [>.............................] - ETA: 3:08 - loss: 0.7171 - acc: 0.7500 - kappa: 0.8789\n",
      "Iteration 000016: OneCycleScheduler setting learning rate to 4.372996600291404e-05.\n",
      " 17/343 [>.............................] - ETA: 3:27 - loss: 0.7237 - acc: 0.7426 - kappa: 0.8695\n",
      "Iteration 000017: OneCycleScheduler setting learning rate to 4.3963088878096166e-05.\n",
      " 18/343 [>.............................] - ETA: 3:36 - loss: 0.7042 - acc: 0.7500 - kappa: 0.8763\n",
      "Iteration 000018: OneCycleScheduler setting learning rate to 4.419621175327829e-05.\n",
      " 19/343 [>.............................] - ETA: 3:42 - loss: 0.6835 - acc: 0.7566 - kappa: 0.8824\n",
      "Iteration 000019: OneCycleScheduler setting learning rate to 4.442933462846042e-05.\n",
      " 20/343 [>.............................] - ETA: 3:46 - loss: 0.6747 - acc: 0.7500 - kappa: 0.8820\n",
      "Iteration 000020: OneCycleScheduler setting learning rate to 4.466245750364255e-05.\n",
      " 21/343 [>.............................] - ETA: 3:49 - loss: 0.6838 - acc: 0.7381 - kappa: 0.8743\n",
      "Iteration 000021: OneCycleScheduler setting learning rate to 4.4895580378824674e-05.\n",
      " 22/343 [>.............................] - ETA: 3:50 - loss: 0.6812 - acc: 0.7386 - kappa: 0.8768\n",
      "Iteration 000022: OneCycleScheduler setting learning rate to 4.5128703254006806e-05.\n",
      " 23/343 [=>............................] - ETA: 3:52 - loss: 0.6597 - acc: 0.7500 - kappa: 0.8821\n",
      "Iteration 000023: OneCycleScheduler setting learning rate to 4.536182612918893e-05.\n",
      " 24/343 [=>............................] - ETA: 3:51 - loss: 0.6524 - acc: 0.7500 - kappa: 0.8841\n",
      "Iteration 000024: OneCycleScheduler setting learning rate to 4.5594949004371056e-05.\n",
      " 25/343 [=>............................] - ETA: 3:54 - loss: 0.6726 - acc: 0.7450 - kappa: 0.8838\n",
      "Iteration 000025: OneCycleScheduler setting learning rate to 4.582807187955318e-05.\n",
      " 26/343 [=>............................] - ETA: 3:55 - loss: 0.6592 - acc: 0.7500 - kappa: 0.8879\n",
      "Iteration 000026: OneCycleScheduler setting learning rate to 4.606119475473531e-05.\n",
      " 27/343 [=>............................] - ETA: 3:55 - loss: 0.6445 - acc: 0.7546 - kappa: 0.8918\n",
      "Iteration 000027: OneCycleScheduler setting learning rate to 4.629431762991744e-05.\n",
      " 28/343 [=>............................] - ETA: 3:57 - loss: 0.6492 - acc: 0.7545 - kappa: 0.8931\n",
      "Iteration 000028: OneCycleScheduler setting learning rate to 4.6527440505099564e-05.\n",
      " 29/343 [=>............................] - ETA: 3:56 - loss: 0.6491 - acc: 0.7543 - kappa: 0.8944\n",
      "Iteration 000029: OneCycleScheduler setting learning rate to 4.6760563380281696e-05.\n",
      " 30/343 [=>............................] - ETA: 3:58 - loss: 0.6402 - acc: 0.7583 - kappa: 0.8969\n",
      "Iteration 000030: OneCycleScheduler setting learning rate to 4.699368625546382e-05.\n",
      " 31/343 [=>............................] - ETA: 3:58 - loss: 0.6398 - acc: 0.7540 - kappa: 0.8939\n",
      "Iteration 000031: OneCycleScheduler setting learning rate to 4.7226809130645946e-05.\n",
      " 32/343 [=>............................] - ETA: 4:00 - loss: 0.6537 - acc: 0.7500 - kappa: 0.8911\n",
      "Iteration 000032: OneCycleScheduler setting learning rate to 4.745993200582808e-05.\n",
      " 33/343 [=>............................] - ETA: 4:02 - loss: 0.6516 - acc: 0.7538 - kappa: 0.8935\n",
      "Iteration 000033: OneCycleScheduler setting learning rate to 4.7693054881010203e-05.\n",
      " 34/343 [=>............................] - ETA: 4:03 - loss: 0.6483 - acc: 0.7500 - kappa: 0.8945\n",
      "Iteration 000034: OneCycleScheduler setting learning rate to 4.792617775619233e-05.\n",
      " 35/343 [==>...........................] - ETA: 4:02 - loss: 0.6491 - acc: 0.7536 - kappa: 0.8973\n",
      "Iteration 000035: OneCycleScheduler setting learning rate to 4.815930063137446e-05.\n",
      " 36/343 [==>...........................] - ETA: 4:01 - loss: 0.6385 - acc: 0.7569 - kappa: 0.9000\n",
      "Iteration 000036: OneCycleScheduler setting learning rate to 4.8392423506556586e-05.\n",
      " 37/343 [==>...........................] - ETA: 4:03 - loss: 0.6343 - acc: 0.7601 - kappa: 0.9024\n",
      "Iteration 000037: OneCycleScheduler setting learning rate to 4.862554638173871e-05.\n",
      " 38/343 [==>...........................] - ETA: 4:06 - loss: 0.6293 - acc: 0.7599 - kappa: 0.9017\n",
      "Iteration 000038: OneCycleScheduler setting learning rate to 4.8858669256920836e-05.\n",
      " 39/343 [==>...........................] - ETA: 4:07 - loss: 0.6198 - acc: 0.7660 - kappa: 0.9042\n",
      "Iteration 000039: OneCycleScheduler setting learning rate to 4.909179213210297e-05.\n",
      " 40/343 [==>...........................] - ETA: 4:09 - loss: 0.6243 - acc: 0.7625 - kappa: 0.9049\n",
      "Iteration 000040: OneCycleScheduler setting learning rate to 4.9324915007285094e-05.\n",
      " 41/343 [==>...........................] - ETA: 4:07 - loss: 0.6154 - acc: 0.7683 - kappa: 0.9072\n",
      "Iteration 000041: OneCycleScheduler setting learning rate to 4.955803788246722e-05.\n",
      " 42/343 [==>...........................] - ETA: 4:08 - loss: 0.6262 - acc: 0.7649 - kappa: 0.9027\n",
      "Iteration 000042: OneCycleScheduler setting learning rate to 4.979116075764935e-05.\n",
      " 43/343 [==>...........................] - ETA: 4:08 - loss: 0.6220 - acc: 0.7674 - kappa: 0.9048\n",
      "Iteration 000043: OneCycleScheduler setting learning rate to 5.0024283632831476e-05.\n",
      " 44/343 [==>...........................] - ETA: 4:06 - loss: 0.6254 - acc: 0.7642 - kappa: 0.9054\n",
      "Iteration 000044: OneCycleScheduler setting learning rate to 5.02574065080136e-05.\n",
      " 45/343 [==>...........................] - ETA: 4:04 - loss: 0.6189 - acc: 0.7667 - kappa: 0.9073\n",
      "Iteration 000045: OneCycleScheduler setting learning rate to 5.0490529383195726e-05.\n",
      " 46/343 [===>..........................] - ETA: 4:05 - loss: 0.6634 - acc: 0.7582 - kappa: 0.8984\n",
      "Iteration 000046: OneCycleScheduler setting learning rate to 5.072365225837786e-05.\n",
      " 47/343 [===>..........................] - ETA: 4:07 - loss: 0.6602 - acc: 0.7633 - kappa: 0.9006\n",
      "Iteration 000047: OneCycleScheduler setting learning rate to 5.0956775133559984e-05.\n",
      " 48/343 [===>..........................] - ETA: 4:06 - loss: 0.6502 - acc: 0.7682 - kappa: 0.9027\n",
      "Iteration 000048: OneCycleScheduler setting learning rate to 5.1189898008742116e-05.\n",
      " 49/343 [===>..........................] - ETA: 4:06 - loss: 0.6539 - acc: 0.7653 - kappa: 0.9021\n",
      "Iteration 000049: OneCycleScheduler setting learning rate to 5.142302088392424e-05.\n",
      " 50/343 [===>..........................] - ETA: 4:06 - loss: 0.6455 - acc: 0.7675 - kappa: 0.9034\n",
      "Iteration 000050: OneCycleScheduler setting learning rate to 5.1656143759106366e-05.\n",
      " 51/343 [===>..........................] - ETA: 4:06 - loss: 0.6454 - acc: 0.7672 - kappa: 0.9047\n",
      "Iteration 000051: OneCycleScheduler setting learning rate to 5.188926663428849e-05.\n",
      " 52/343 [===>..........................] - ETA: 4:05 - loss: 0.6399 - acc: 0.7692 - kappa: 0.9059\n",
      "Iteration 000052: OneCycleScheduler setting learning rate to 5.212238950947062e-05.\n",
      " 53/343 [===>..........................] - ETA: 4:06 - loss: 0.6349 - acc: 0.7712 - kappa: 0.9076\n",
      "Iteration 000053: OneCycleScheduler setting learning rate to 5.235551238465275e-05.\n",
      " 54/343 [===>..........................] - ETA: 4:06 - loss: 0.6329 - acc: 0.7708 - kappa: 0.9070\n",
      "Iteration 000054: OneCycleScheduler setting learning rate to 5.2588635259834874e-05.\n",
      " 55/343 [===>..........................] - ETA: 4:05 - loss: 0.6311 - acc: 0.7705 - kappa: 0.9074\n",
      "Iteration 000055: OneCycleScheduler setting learning rate to 5.2821758135017006e-05.\n",
      " 56/343 [===>..........................] - ETA: 4:07 - loss: 0.6493 - acc: 0.7656 - kappa: 0.9040\n",
      "Iteration 000056: OneCycleScheduler setting learning rate to 5.305488101019913e-05.\n",
      " 57/343 [===>..........................] - ETA: 4:06 - loss: 0.6478 - acc: 0.7654 - kappa: 0.9052\n",
      "Iteration 000057: OneCycleScheduler setting learning rate to 5.3288003885381256e-05.\n",
      " 58/343 [====>.........................] - ETA: 4:04 - loss: 0.6410 - acc: 0.7694 - kappa: 0.9068\n",
      "Iteration 000058: OneCycleScheduler setting learning rate to 5.352112676056338e-05.\n",
      " 59/343 [====>.........................] - ETA: 4:04 - loss: 0.6426 - acc: 0.7691 - kappa: 0.9062\n",
      "Iteration 000059: OneCycleScheduler setting learning rate to 5.3754249635745514e-05.\n",
      " 60/343 [====>.........................] - ETA: 4:04 - loss: 0.6390 - acc: 0.7708 - kappa: 0.9077\n",
      "Iteration 000060: OneCycleScheduler setting learning rate to 5.398737251092764e-05.\n",
      " 61/343 [====>.........................] - ETA: 4:03 - loss: 0.6358 - acc: 0.7725 - kappa: 0.9087\n",
      "Iteration 000061: OneCycleScheduler setting learning rate to 5.4220495386109764e-05.\n",
      " 62/343 [====>.........................] - ETA: 4:03 - loss: 0.6374 - acc: 0.7681 - kappa: 0.9070\n",
      "Iteration 000062: OneCycleScheduler setting learning rate to 5.4453618261291896e-05.\n",
      " 63/343 [====>.........................] - ETA: 4:02 - loss: 0.6379 - acc: 0.7698 - kappa: 0.9084\n",
      "Iteration 000063: OneCycleScheduler setting learning rate to 5.468674113647402e-05.\n",
      " 64/343 [====>.........................] - ETA: 4:03 - loss: 0.6398 - acc: 0.7676 - kappa: 0.9087\n",
      "Iteration 000064: OneCycleScheduler setting learning rate to 5.4919864011656146e-05.\n",
      " 65/343 [====>.........................] - ETA: 4:01 - loss: 0.6351 - acc: 0.7692 - kappa: 0.9100\n",
      "Iteration 000065: OneCycleScheduler setting learning rate to 5.515298688683827e-05.\n",
      " 66/343 [====>.........................] - ETA: 4:00 - loss: 0.6345 - acc: 0.7689 - kappa: 0.9094\n",
      "Iteration 000066: OneCycleScheduler setting learning rate to 5.5386109762020404e-05.\n",
      " 67/343 [====>.........................] - ETA: 3:59 - loss: 0.6270 - acc: 0.7724 - kappa: 0.9108\n",
      "Iteration 000067: OneCycleScheduler setting learning rate to 5.561923263720253e-05.\n",
      " 68/343 [====>.........................] - ETA: 3:57 - loss: 0.6252 - acc: 0.7739 - kappa: 0.9116\n",
      "Iteration 000068: OneCycleScheduler setting learning rate to 5.585235551238466e-05.\n",
      " 69/343 [=====>........................] - ETA: 3:56 - loss: 0.6257 - acc: 0.7736 - kappa: 0.9125\n",
      "Iteration 000069: OneCycleScheduler setting learning rate to 5.6085478387566786e-05.\n",
      " 70/343 [=====>........................] - ETA: 3:56 - loss: 0.6197 - acc: 0.7750 - kappa: 0.9136\n",
      "Iteration 000070: OneCycleScheduler setting learning rate to 5.631860126274891e-05.\n",
      " 71/343 [=====>........................] - ETA: 3:56 - loss: 0.6254 - acc: 0.7711 - kappa: 0.9121\n",
      "Iteration 000071: OneCycleScheduler setting learning rate to 5.6551724137931037e-05.\n",
      " 72/343 [=====>........................] - ETA: 3:55 - loss: 0.6228 - acc: 0.7726 - kappa: 0.9129\n",
      "Iteration 000072: OneCycleScheduler setting learning rate to 5.678484701311316e-05.\n",
      " 73/343 [=====>........................] - ETA: 3:55 - loss: 0.6276 - acc: 0.7688 - kappa: 0.9102\n",
      "Iteration 000073: OneCycleScheduler setting learning rate to 5.7017969888295294e-05.\n",
      " 74/343 [=====>........................] - ETA: 3:55 - loss: 0.6366 - acc: 0.7669 - kappa: 0.9105\n",
      "Iteration 000074: OneCycleScheduler setting learning rate to 5.7251092763477426e-05.\n",
      " 75/343 [=====>........................] - ETA: 3:54 - loss: 0.6365 - acc: 0.7650 - kappa: 0.9107\n",
      "Iteration 000075: OneCycleScheduler setting learning rate to 5.748421563865955e-05.\n",
      " 76/343 [=====>........................] - ETA: 3:53 - loss: 0.6390 - acc: 0.7615 - kappa: 0.9082\n",
      "Iteration 000076: OneCycleScheduler setting learning rate to 5.7717338513841676e-05.\n",
      " 77/343 [=====>........................] - ETA: 3:53 - loss: 0.6342 - acc: 0.7630 - kappa: 0.9093\n",
      "Iteration 000077: OneCycleScheduler setting learning rate to 5.79504613890238e-05.\n",
      " 78/343 [=====>........................] - ETA: 3:52 - loss: 0.6319 - acc: 0.7660 - kappa: 0.9105\n",
      "Iteration 000078: OneCycleScheduler setting learning rate to 5.818358426420593e-05.\n",
      " 79/343 [=====>........................] - ETA: 3:51 - loss: 0.6250 - acc: 0.7690 - kappa: 0.9116\n",
      "Iteration 000079: OneCycleScheduler setting learning rate to 5.841670713938806e-05.\n",
      " 80/343 [=====>........................] - ETA: 3:50 - loss: 0.6203 - acc: 0.7703 - kappa: 0.9126\n",
      "Iteration 000080: OneCycleScheduler setting learning rate to 5.8649830014570184e-05.\n",
      " 81/343 [======>.......................] - ETA: 3:50 - loss: 0.6270 - acc: 0.7701 - kappa: 0.9128\n",
      "Iteration 000081: OneCycleScheduler setting learning rate to 5.8882952889752316e-05.\n",
      " 82/343 [======>.......................] - ETA: 3:48 - loss: 0.6243 - acc: 0.7698 - kappa: 0.9135\n",
      "Iteration 000082: OneCycleScheduler setting learning rate to 5.911607576493444e-05.\n",
      " 83/343 [======>.......................] - ETA: 3:48 - loss: 0.6250 - acc: 0.7681 - kappa: 0.9122\n",
      "Iteration 000083: OneCycleScheduler setting learning rate to 5.9349198640116566e-05.\n",
      " 84/343 [======>.......................] - ETA: 3:47 - loss: 0.6216 - acc: 0.7693 - kappa: 0.9131\n",
      "Iteration 000084: OneCycleScheduler setting learning rate to 5.958232151529869e-05.\n",
      " 85/343 [======>.......................] - ETA: 3:47 - loss: 0.6249 - acc: 0.7676 - kappa: 0.9127\n",
      "Iteration 000085: OneCycleScheduler setting learning rate to 5.981544439048082e-05.\n",
      " 86/343 [======>.......................] - ETA: 3:47 - loss: 0.6220 - acc: 0.7689 - kappa: 0.9133\n",
      "Iteration 000086: OneCycleScheduler setting learning rate to 6.004856726566295e-05.\n",
      " 87/343 [======>.......................] - ETA: 3:47 - loss: 0.6237 - acc: 0.7672 - kappa: 0.9135\n",
      "Iteration 000087: OneCycleScheduler setting learning rate to 6.0281690140845074e-05.\n",
      " 88/343 [======>.......................] - ETA: 3:46 - loss: 0.6319 - acc: 0.7628 - kappa: 0.9088\n",
      "Iteration 000088: OneCycleScheduler setting learning rate to 6.0514813016027206e-05.\n",
      " 89/343 [======>.......................] - ETA: 3:46 - loss: 0.6319 - acc: 0.7640 - kappa: 0.9091\n",
      "Iteration 000089: OneCycleScheduler setting learning rate to 6.074793589120933e-05.\n",
      " 90/343 [======>.......................] - ETA: 3:47 - loss: 0.6288 - acc: 0.7653 - kappa: 0.9100\n",
      "Iteration 000090: OneCycleScheduler setting learning rate to 6.0981058766391456e-05.\n",
      " 91/343 [======>.......................] - ETA: 3:45 - loss: 0.6244 - acc: 0.7679 - kappa: 0.9110\n",
      "Iteration 000091: OneCycleScheduler setting learning rate to 6.121418164157358e-05.\n",
      " 92/343 [=======>......................] - ETA: 3:45 - loss: 0.6236 - acc: 0.7677 - kappa: 0.9112\n",
      "Iteration 000092: OneCycleScheduler setting learning rate to 6.144730451675571e-05.\n",
      " 93/343 [=======>......................] - ETA: 3:44 - loss: 0.6242 - acc: 0.7675 - kappa: 0.9114\n",
      "Iteration 000093: OneCycleScheduler setting learning rate to 6.168042739193783e-05.\n",
      " 94/343 [=======>......................] - ETA: 3:43 - loss: 0.6210 - acc: 0.7686 - kappa: 0.9120\n",
      "Iteration 000094: OneCycleScheduler setting learning rate to 6.191355026711997e-05.\n",
      " 95/343 [=======>......................] - ETA: 3:42 - loss: 0.6253 - acc: 0.7697 - kappa: 0.9126\n",
      "Iteration 000095: OneCycleScheduler setting learning rate to 6.21466731423021e-05.\n",
      " 96/343 [=======>......................] - ETA: 3:40 - loss: 0.6275 - acc: 0.7695 - kappa: 0.9132\n",
      "Iteration 000096: OneCycleScheduler setting learning rate to 6.237979601748422e-05.\n",
      " 97/343 [=======>......................] - ETA: 3:39 - loss: 0.6266 - acc: 0.7693 - kappa: 0.9137\n",
      "Iteration 000097: OneCycleScheduler setting learning rate to 6.261291889266635e-05.\n",
      " 98/343 [=======>......................] - ETA: 3:39 - loss: 0.6231 - acc: 0.7704 - kappa: 0.9145\n",
      "Iteration 000098: OneCycleScheduler setting learning rate to 6.284604176784847e-05.\n",
      " 99/343 [=======>......................] - ETA: 3:37 - loss: 0.6212 - acc: 0.7715 - kappa: 0.9153\n",
      "Iteration 000099: OneCycleScheduler setting learning rate to 6.307916464303061e-05.\n",
      "100/343 [=======>......................] - ETA: 3:36 - loss: 0.6191 - acc: 0.7725 - kappa: 0.9159\n",
      "Iteration 000100: OneCycleScheduler setting learning rate to 6.331228751821274e-05.\n",
      "101/343 [=======>......................] - ETA: 3:35 - loss: 0.6179 - acc: 0.7723 - kappa: 0.9164\n",
      "Iteration 000101: OneCycleScheduler setting learning rate to 6.354541039339486e-05.\n",
      "102/343 [=======>......................] - ETA: 3:35 - loss: 0.6164 - acc: 0.7733 - kappa: 0.9169\n",
      "Iteration 000102: OneCycleScheduler setting learning rate to 6.377853326857699e-05.\n",
      "103/343 [========>.....................] - ETA: 3:34 - loss: 0.6139 - acc: 0.7755 - kappa: 0.9177\n",
      "Iteration 000103: OneCycleScheduler setting learning rate to 6.401165614375911e-05.\n",
      "104/343 [========>.....................] - ETA: 3:33 - loss: 0.6125 - acc: 0.7752 - kappa: 0.9178\n",
      "Iteration 000104: OneCycleScheduler setting learning rate to 6.424477901894124e-05.\n",
      "105/343 [========>.....................] - ETA: 3:32 - loss: 0.6099 - acc: 0.7774 - kappa: 0.9186\n",
      "Iteration 000105: OneCycleScheduler setting learning rate to 6.447790189412336e-05.\n",
      "106/343 [========>.....................] - ETA: 3:31 - loss: 0.6092 - acc: 0.7783 - kappa: 0.9193\n",
      "Iteration 000106: OneCycleScheduler setting learning rate to 6.471102476930549e-05.\n",
      "107/343 [========>.....................] - ETA: 3:30 - loss: 0.6099 - acc: 0.7769 - kappa: 0.9194\n",
      "Iteration 000107: OneCycleScheduler setting learning rate to 6.494414764448761e-05.\n",
      "108/343 [========>.....................] - ETA: 3:30 - loss: 0.6057 - acc: 0.7789 - kappa: 0.9201\n",
      "Iteration 000108: OneCycleScheduler setting learning rate to 6.517727051966975e-05.\n",
      "109/343 [========>.....................] - ETA: 3:30 - loss: 0.6245 - acc: 0.7764 - kappa: 0.9197\n",
      "Iteration 000109: OneCycleScheduler setting learning rate to 6.541039339485188e-05.\n",
      "110/343 [========>.....................] - ETA: 3:29 - loss: 0.6255 - acc: 0.7761 - kappa: 0.9202\n",
      "Iteration 000110: OneCycleScheduler setting learning rate to 6.5643516270034e-05.\n",
      "111/343 [========>.....................] - ETA: 3:28 - loss: 0.6241 - acc: 0.7770 - kappa: 0.9208\n",
      "Iteration 000111: OneCycleScheduler setting learning rate to 6.587663914521613e-05.\n",
      "112/343 [========>.....................] - ETA: 3:26 - loss: 0.6254 - acc: 0.7757 - kappa: 0.9204\n",
      "Iteration 000112: OneCycleScheduler setting learning rate to 6.610976202039825e-05.\n",
      "113/343 [========>.....................] - ETA: 3:25 - loss: 0.6257 - acc: 0.7754 - kappa: 0.9205\n",
      "Iteration 000113: OneCycleScheduler setting learning rate to 6.634288489558039e-05.\n",
      "114/343 [========>.....................] - ETA: 3:25 - loss: 0.6239 - acc: 0.7763 - kappa: 0.9211\n",
      "Iteration 000114: OneCycleScheduler setting learning rate to 6.657600777076252e-05.\n",
      "115/343 [=========>....................] - ETA: 3:25 - loss: 0.6260 - acc: 0.7761 - kappa: 0.9201\n",
      "Iteration 000115: OneCycleScheduler setting learning rate to 6.680913064594464e-05.\n",
      "116/343 [=========>....................] - ETA: 3:24 - loss: 0.6276 - acc: 0.7737 - kappa: 0.9191\n",
      "Iteration 000116: OneCycleScheduler setting learning rate to 6.704225352112677e-05.\n",
      "117/343 [=========>....................] - ETA: 3:25 - loss: 0.6324 - acc: 0.7735 - kappa: 0.9192\n",
      "Iteration 000117: OneCycleScheduler setting learning rate to 6.727537639630889e-05.\n",
      "118/343 [=========>....................] - ETA: 3:24 - loss: 0.6348 - acc: 0.7733 - kappa: 0.9182\n",
      "Iteration 000118: OneCycleScheduler setting learning rate to 6.750849927149102e-05.\n",
      "119/343 [=========>....................] - ETA: 3:24 - loss: 0.6330 - acc: 0.7731 - kappa: 0.9183\n",
      "Iteration 000119: OneCycleScheduler setting learning rate to 6.774162214667314e-05.\n",
      "120/343 [=========>....................] - ETA: 3:23 - loss: 0.6302 - acc: 0.7740 - kappa: 0.9189\n",
      "Iteration 000120: OneCycleScheduler setting learning rate to 6.797474502185527e-05.\n",
      "121/343 [=========>....................] - ETA: 3:23 - loss: 0.6350 - acc: 0.7717 - kappa: 0.9186\n",
      "Iteration 000121: OneCycleScheduler setting learning rate to 6.82078678970374e-05.\n",
      "122/343 [=========>....................] - ETA: 3:22 - loss: 0.6328 - acc: 0.7725 - kappa: 0.9192\n",
      "Iteration 000122: OneCycleScheduler setting learning rate to 6.844099077221953e-05.\n",
      "123/343 [=========>....................] - ETA: 3:21 - loss: 0.6312 - acc: 0.7734 - kappa: 0.9198\n",
      "Iteration 000123: OneCycleScheduler setting learning rate to 6.867411364740166e-05.\n",
      "124/343 [=========>....................] - ETA: 3:20 - loss: 0.6320 - acc: 0.7722 - kappa: 0.9182\n",
      "Iteration 000124: OneCycleScheduler setting learning rate to 6.890723652258378e-05.\n",
      "125/343 [=========>....................] - ETA: 3:19 - loss: 0.6336 - acc: 0.7710 - kappa: 0.9183\n",
      "Iteration 000125: OneCycleScheduler setting learning rate to 6.914035939776591e-05.\n",
      "126/343 [==========>...................] - ETA: 3:18 - loss: 0.6317 - acc: 0.7728 - kappa: 0.9189\n",
      "Iteration 000126: OneCycleScheduler setting learning rate to 6.937348227294805e-05.\n",
      "127/343 [==========>...................] - ETA: 3:18 - loss: 0.6312 - acc: 0.7726 - kappa: 0.9190\n",
      "Iteration 000127: OneCycleScheduler setting learning rate to 6.960660514813017e-05.\n",
      "128/343 [==========>...................] - ETA: 3:17 - loss: 0.6298 - acc: 0.7725 - kappa: 0.9191\n",
      "Iteration 000128: OneCycleScheduler setting learning rate to 6.98397280233123e-05.\n",
      "129/343 [==========>...................] - ETA: 3:16 - loss: 0.6287 - acc: 0.7723 - kappa: 0.9195\n",
      "Iteration 000129: OneCycleScheduler setting learning rate to 7.007285089849442e-05.\n",
      "130/343 [==========>...................] - ETA: 3:16 - loss: 0.6317 - acc: 0.7712 - kappa: 0.9191\n",
      "Iteration 000130: OneCycleScheduler setting learning rate to 7.030597377367655e-05.\n",
      "131/343 [==========>...................] - ETA: 3:15 - loss: 0.6310 - acc: 0.7700 - kappa: 0.9182\n",
      "Iteration 000131: OneCycleScheduler setting learning rate to 7.053909664885867e-05.\n",
      "132/343 [==========>...................] - ETA: 3:15 - loss: 0.6338 - acc: 0.7680 - kappa: 0.9174\n",
      "Iteration 000132: OneCycleScheduler setting learning rate to 7.07722195240408e-05.\n",
      "133/343 [==========>...................] - ETA: 3:14 - loss: 0.6327 - acc: 0.7679 - kappa: 0.9178\n",
      "Iteration 000133: OneCycleScheduler setting learning rate to 7.100534239922292e-05.\n",
      "134/343 [==========>...................] - ETA: 3:13 - loss: 0.6307 - acc: 0.7687 - kappa: 0.9183\n",
      "Iteration 000134: OneCycleScheduler setting learning rate to 7.123846527440505e-05.\n",
      "135/343 [==========>...................] - ETA: 3:11 - loss: 0.6310 - acc: 0.7694 - kappa: 0.9189\n",
      "Iteration 000135: OneCycleScheduler setting learning rate to 7.147158814958719e-05.\n",
      "136/343 [==========>...................] - ETA: 3:10 - loss: 0.6308 - acc: 0.7693 - kappa: 0.9192\n",
      "Iteration 000136: OneCycleScheduler setting learning rate to 7.170471102476931e-05.\n",
      "137/343 [==========>...................] - ETA: 3:10 - loss: 0.6302 - acc: 0.7692 - kappa: 0.9178\n",
      "Iteration 000137: OneCycleScheduler setting learning rate to 7.193783389995144e-05.\n",
      "138/343 [===========>..................] - ETA: 3:09 - loss: 0.6306 - acc: 0.7699 - kappa: 0.9181\n",
      "Iteration 000138: OneCycleScheduler setting learning rate to 7.217095677513358e-05.\n",
      "139/343 [===========>..................] - ETA: 3:09 - loss: 0.6288 - acc: 0.7716 - kappa: 0.9187\n",
      "Iteration 000139: OneCycleScheduler setting learning rate to 7.24040796503157e-05.\n",
      "140/343 [===========>..................] - ETA: 3:07 - loss: 0.6293 - acc: 0.7714 - kappa: 0.9184\n",
      "Iteration 000140: OneCycleScheduler setting learning rate to 7.263720252549783e-05.\n",
      "141/343 [===========>..................] - ETA: 3:06 - loss: 0.6283 - acc: 0.7713 - kappa: 0.9185\n",
      "Iteration 000141: OneCycleScheduler setting learning rate to 7.287032540067995e-05.\n",
      "142/343 [===========>..................] - ETA: 3:05 - loss: 0.6255 - acc: 0.7720 - kappa: 0.9190\n",
      "Iteration 000142: OneCycleScheduler setting learning rate to 7.310344827586208e-05.\n",
      "143/343 [===========>..................] - ETA: 3:04 - loss: 0.6267 - acc: 0.7719 - kappa: 0.9194\n",
      "Iteration 000143: OneCycleScheduler setting learning rate to 7.33365711510442e-05.\n",
      "144/343 [===========>..................] - ETA: 3:03 - loss: 0.6247 - acc: 0.7726 - kappa: 0.9199\n",
      "Iteration 000144: OneCycleScheduler setting learning rate to 7.356969402622633e-05.\n",
      "145/343 [===========>..................] - ETA: 3:02 - loss: 0.6231 - acc: 0.7733 - kappa: 0.9204\n",
      "Iteration 000145: OneCycleScheduler setting learning rate to 7.380281690140845e-05.\n",
      "146/343 [===========>..................] - ETA: 3:02 - loss: 0.6238 - acc: 0.7731 - kappa: 0.9196\n",
      "Iteration 000146: OneCycleScheduler setting learning rate to 7.403593977659058e-05.\n",
      "147/343 [===========>..................] - ETA: 3:01 - loss: 0.6239 - acc: 0.7730 - kappa: 0.9196\n",
      "Iteration 000147: OneCycleScheduler setting learning rate to 7.42690626517727e-05.\n",
      "148/343 [===========>..................] - ETA: 3:00 - loss: 0.6232 - acc: 0.7736 - kappa: 0.9201\n",
      "Iteration 000148: OneCycleScheduler setting learning rate to 7.450218552695484e-05.\n",
      "149/343 [============>.................] - ETA: 2:59 - loss: 0.6258 - acc: 0.7727 - kappa: 0.9181\n",
      "Iteration 000149: OneCycleScheduler setting learning rate to 7.473530840213697e-05.\n",
      "150/343 [============>.................] - ETA: 2:58 - loss: 0.6253 - acc: 0.7725 - kappa: 0.9182\n",
      "Iteration 000150: OneCycleScheduler setting learning rate to 7.496843127731909e-05.\n",
      "151/343 [============>.................] - ETA: 2:58 - loss: 0.6233 - acc: 0.7732 - kappa: 0.9187\n",
      "Iteration 000151: OneCycleScheduler setting learning rate to 7.520155415250122e-05.\n",
      "152/343 [============>.................] - ETA: 2:57 - loss: 0.6227 - acc: 0.7738 - kappa: 0.9192\n",
      "Iteration 000152: OneCycleScheduler setting learning rate to 7.543467702768336e-05.\n",
      "153/343 [============>.................] - ETA: 2:56 - loss: 0.6210 - acc: 0.7753 - kappa: 0.9197\n",
      "Iteration 000153: OneCycleScheduler setting learning rate to 7.566779990286548e-05.\n",
      "154/343 [============>.................] - ETA: 2:56 - loss: 0.6200 - acc: 0.7760 - kappa: 0.9202\n",
      "Iteration 000154: OneCycleScheduler setting learning rate to 7.59009227780476e-05.\n",
      "155/343 [============>.................] - ETA: 2:55 - loss: 0.6232 - acc: 0.7750 - kappa: 0.9199\n",
      "Iteration 000155: OneCycleScheduler setting learning rate to 7.613404565322973e-05.\n",
      "156/343 [============>.................] - ETA: 2:54 - loss: 0.6249 - acc: 0.7740 - kappa: 0.9199\n",
      "Iteration 000156: OneCycleScheduler setting learning rate to 7.636716852841186e-05.\n",
      "157/343 [============>.................] - ETA: 2:53 - loss: 0.6270 - acc: 0.7739 - kappa: 0.9200\n",
      "Iteration 000157: OneCycleScheduler setting learning rate to 7.660029140359398e-05.\n",
      "158/343 [============>.................] - ETA: 2:52 - loss: 0.6247 - acc: 0.7745 - kappa: 0.9204\n",
      "Iteration 000158: OneCycleScheduler setting learning rate to 7.683341427877611e-05.\n",
      "159/343 [============>.................] - ETA: 2:51 - loss: 0.6306 - acc: 0.7744 - kappa: 0.9205\n",
      "Iteration 000159: OneCycleScheduler setting learning rate to 7.706653715395823e-05.\n",
      "160/343 [============>.................] - ETA: 2:50 - loss: 0.6276 - acc: 0.7758 - kappa: 0.9210\n",
      "Iteration 000160: OneCycleScheduler setting learning rate to 7.729966002914036e-05.\n",
      "161/343 [=============>................] - ETA: 2:50 - loss: 0.6292 - acc: 0.7764 - kappa: 0.9211\n",
      "Iteration 000161: OneCycleScheduler setting learning rate to 7.753278290432248e-05.\n",
      "162/343 [=============>................] - ETA: 2:49 - loss: 0.6264 - acc: 0.7778 - kappa: 0.9215\n",
      "Iteration 000162: OneCycleScheduler setting learning rate to 7.776590577950462e-05.\n",
      "163/343 [=============>................] - ETA: 2:48 - loss: 0.6307 - acc: 0.7761 - kappa: 0.9181\n",
      "Iteration 000163: OneCycleScheduler setting learning rate to 7.799902865468675e-05.\n",
      "164/343 [=============>................] - ETA: 2:46 - loss: 0.6289 - acc: 0.7767 - kappa: 0.9186\n",
      "Iteration 000164: OneCycleScheduler setting learning rate to 7.823215152986887e-05.\n",
      "165/343 [=============>................] - ETA: 2:45 - loss: 0.6301 - acc: 0.7765 - kappa: 0.9189\n",
      "Iteration 000165: OneCycleScheduler setting learning rate to 7.846527440505101e-05.\n",
      "166/343 [=============>................] - ETA: 2:44 - loss: 0.6316 - acc: 0.7764 - kappa: 0.9182\n",
      "Iteration 000166: OneCycleScheduler setting learning rate to 7.869839728023314e-05.\n",
      "167/343 [=============>................] - ETA: 2:43 - loss: 0.6289 - acc: 0.7777 - kappa: 0.9187\n",
      "Iteration 000167: OneCycleScheduler setting learning rate to 7.893152015541526e-05.\n",
      "168/343 [=============>................] - ETA: 2:42 - loss: 0.6277 - acc: 0.7783 - kappa: 0.9188\n",
      "Iteration 000168: OneCycleScheduler setting learning rate to 7.916464303059739e-05.\n",
      "169/343 [=============>................] - ETA: 2:41 - loss: 0.6272 - acc: 0.7781 - kappa: 0.9191\n",
      "Iteration 000169: OneCycleScheduler setting learning rate to 7.939776590577951e-05.\n",
      "170/343 [=============>................] - ETA: 2:40 - loss: 0.6257 - acc: 0.7787 - kappa: 0.9195\n",
      "Iteration 000170: OneCycleScheduler setting learning rate to 7.963088878096164e-05.\n",
      "171/343 [=============>................] - ETA: 2:39 - loss: 0.6247 - acc: 0.7785 - kappa: 0.9195\n",
      "Iteration 000171: OneCycleScheduler setting learning rate to 7.986401165614376e-05.\n",
      "172/343 [==============>...............] - ETA: 2:38 - loss: 0.6240 - acc: 0.7791 - kappa: 0.9198\n",
      "Iteration 000172: OneCycleScheduler setting learning rate to 8.009713453132589e-05.\n",
      "173/343 [==============>...............] - ETA: 2:37 - loss: 0.6263 - acc: 0.7782 - kappa: 0.9192\n",
      "Iteration 000173: OneCycleScheduler setting learning rate to 8.033025740650801e-05.\n",
      "174/343 [==============>...............] - ETA: 2:36 - loss: 0.6266 - acc: 0.7780 - kappa: 0.9192\n",
      "Iteration 000174: OneCycleScheduler setting learning rate to 8.056338028169014e-05.\n",
      "175/343 [==============>...............] - ETA: 2:35 - loss: 0.6244 - acc: 0.7793 - kappa: 0.9197\n",
      "Iteration 000175: OneCycleScheduler setting learning rate to 8.079650315687228e-05.\n",
      "176/343 [==============>...............] - ETA: 2:34 - loss: 0.6255 - acc: 0.7791 - kappa: 0.9197\n",
      "Iteration 000176: OneCycleScheduler setting learning rate to 8.10296260320544e-05.\n",
      "177/343 [==============>...............] - ETA: 2:33 - loss: 0.6271 - acc: 0.7782 - kappa: 0.9198\n",
      "Iteration 000177: OneCycleScheduler setting learning rate to 8.126274890723653e-05.\n",
      "178/343 [==============>...............] - ETA: 2:33 - loss: 0.6260 - acc: 0.7788 - kappa: 0.9202\n",
      "Iteration 000178: OneCycleScheduler setting learning rate to 8.149587178241867e-05.\n",
      "179/343 [==============>...............] - ETA: 2:32 - loss: 0.6268 - acc: 0.7779 - kappa: 0.9200\n",
      "Iteration 000179: OneCycleScheduler setting learning rate to 8.172899465760079e-05.\n",
      "180/343 [==============>...............] - ETA: 2:31 - loss: 0.6268 - acc: 0.7778 - kappa: 0.9200\n",
      "Iteration 000180: OneCycleScheduler setting learning rate to 8.196211753278292e-05.\n",
      "181/343 [==============>...............] - ETA: 2:30 - loss: 0.6247 - acc: 0.7790 - kappa: 0.9205\n",
      "Iteration 000181: OneCycleScheduler setting learning rate to 8.219524040796504e-05.\n",
      "182/343 [==============>...............] - ETA: 2:30 - loss: 0.6245 - acc: 0.7788 - kappa: 0.9205\n",
      "Iteration 000182: OneCycleScheduler setting learning rate to 8.242836328314717e-05.\n",
      "183/343 [===============>..............] - ETA: 2:29 - loss: 0.6226 - acc: 0.7801 - kappa: 0.9209\n",
      "Iteration 000183: OneCycleScheduler setting learning rate to 8.266148615832929e-05.\n",
      "184/343 [===============>..............] - ETA: 2:28 - loss: 0.6207 - acc: 0.7806 - kappa: 0.9212\n",
      "Iteration 000184: OneCycleScheduler setting learning rate to 8.289460903351142e-05.\n",
      "185/343 [===============>..............] - ETA: 2:27 - loss: 0.6198 - acc: 0.7811 - kappa: 0.9215\n",
      "Iteration 000185: OneCycleScheduler setting learning rate to 8.312773190869354e-05.\n",
      "186/343 [===============>..............] - ETA: 2:26 - loss: 0.6189 - acc: 0.7809 - kappa: 0.9215\n",
      "Iteration 000186: OneCycleScheduler setting learning rate to 8.336085478387567e-05.\n",
      "187/343 [===============>..............] - ETA: 2:25 - loss: 0.6220 - acc: 0.7807 - kappa: 0.9217\n",
      "Iteration 000187: OneCycleScheduler setting learning rate to 8.359397765905779e-05.\n",
      "188/343 [===============>..............] - ETA: 2:24 - loss: 0.6228 - acc: 0.7799 - kappa: 0.9218\n",
      "Iteration 000188: OneCycleScheduler setting learning rate to 8.382710053423993e-05.\n",
      "189/343 [===============>..............] - ETA: 2:24 - loss: 0.6223 - acc: 0.7791 - kappa: 0.9215\n",
      "Iteration 000189: OneCycleScheduler setting learning rate to 8.406022340942206e-05.\n",
      "190/343 [===============>..............] - ETA: 2:23 - loss: 0.6231 - acc: 0.7783 - kappa: 0.9216\n",
      "Iteration 000190: OneCycleScheduler setting learning rate to 8.429334628460418e-05.\n",
      "191/343 [===============>..............] - ETA: 2:22 - loss: 0.6224 - acc: 0.7788 - kappa: 0.9218\n",
      "Iteration 000191: OneCycleScheduler setting learning rate to 8.452646915978631e-05.\n",
      "192/343 [===============>..............] - ETA: 2:21 - loss: 0.6203 - acc: 0.7793 - kappa: 0.9222\n",
      "Iteration 000192: OneCycleScheduler setting learning rate to 8.475959203496845e-05.\n",
      "193/343 [===============>..............] - ETA: 2:20 - loss: 0.6217 - acc: 0.7785 - kappa: 0.9222\n",
      "Iteration 000193: OneCycleScheduler setting learning rate to 8.499271491015057e-05.\n",
      "194/343 [===============>..............] - ETA: 2:19 - loss: 0.6227 - acc: 0.7771 - kappa: 0.9201\n",
      "Iteration 000194: OneCycleScheduler setting learning rate to 8.52258377853327e-05.\n",
      "195/343 [================>.............] - ETA: 2:18 - loss: 0.6217 - acc: 0.7776 - kappa: 0.9203\n",
      "Iteration 000195: OneCycleScheduler setting learning rate to 8.545896066051482e-05.\n",
      "196/343 [================>.............] - ETA: 2:17 - loss: 0.6201 - acc: 0.7781 - kappa: 0.9207\n",
      "Iteration 000196: OneCycleScheduler setting learning rate to 8.569208353569695e-05.\n",
      "197/343 [================>.............] - ETA: 2:16 - loss: 0.6229 - acc: 0.7766 - kappa: 0.9201\n",
      "Iteration 000197: OneCycleScheduler setting learning rate to 8.592520641087907e-05.\n",
      "198/343 [================>.............] - ETA: 2:15 - loss: 0.6240 - acc: 0.7759 - kappa: 0.9199\n",
      "Iteration 000198: OneCycleScheduler setting learning rate to 8.61583292860612e-05.\n",
      "199/343 [================>.............] - ETA: 2:14 - loss: 0.6250 - acc: 0.7758 - kappa: 0.9193\n",
      "Iteration 000199: OneCycleScheduler setting learning rate to 8.639145216124332e-05.\n",
      "200/343 [================>.............] - ETA: 2:13 - loss: 0.6255 - acc: 0.7762 - kappa: 0.9196\n",
      "Iteration 000200: OneCycleScheduler setting learning rate to 8.662457503642545e-05.\n",
      "201/343 [================>.............] - ETA: 2:12 - loss: 0.6252 - acc: 0.7761 - kappa: 0.9197\n",
      "Iteration 000201: OneCycleScheduler setting learning rate to 8.685769791160757e-05.\n",
      "202/343 [================>.............] - ETA: 2:11 - loss: 0.6235 - acc: 0.7772 - kappa: 0.9201\n",
      "Iteration 000202: OneCycleScheduler setting learning rate to 8.709082078678971e-05.\n",
      "203/343 [================>.............] - ETA: 2:10 - loss: 0.6246 - acc: 0.7777 - kappa: 0.9205\n",
      "Iteration 000203: OneCycleScheduler setting learning rate to 8.732394366197184e-05.\n",
      "204/343 [================>.............] - ETA: 2:09 - loss: 0.6256 - acc: 0.7770 - kappa: 0.9199\n",
      "Iteration 000204: OneCycleScheduler setting learning rate to 8.755706653715396e-05.\n",
      "205/343 [================>.............] - ETA: 2:08 - loss: 0.6241 - acc: 0.7774 - kappa: 0.9202\n",
      "Iteration 000205: OneCycleScheduler setting learning rate to 8.77901894123361e-05.\n",
      "206/343 [=================>............] - ETA: 2:08 - loss: 0.6222 - acc: 0.7785 - kappa: 0.9206\n",
      "Iteration 000206: OneCycleScheduler setting learning rate to 8.802331228751823e-05.\n",
      "207/343 [=================>............] - ETA: 2:07 - loss: 0.6326 - acc: 0.7778 - kappa: 0.9201\n",
      "Iteration 000207: OneCycleScheduler setting learning rate to 8.825643516270035e-05.\n",
      "208/343 [=================>............] - ETA: 2:06 - loss: 0.6309 - acc: 0.7788 - kappa: 0.9204\n",
      "Iteration 000208: OneCycleScheduler setting learning rate to 8.848955803788248e-05.\n",
      "209/343 [=================>............] - ETA: 2:05 - loss: 0.6299 - acc: 0.7799 - kappa: 0.9208\n",
      "Iteration 000209: OneCycleScheduler setting learning rate to 8.87226809130646e-05.\n",
      "210/343 [=================>............] - ETA: 2:04 - loss: 0.6302 - acc: 0.7798 - kappa: 0.9209\n",
      "Iteration 000210: OneCycleScheduler setting learning rate to 8.895580378824673e-05.\n",
      "211/343 [=================>............] - ETA: 2:03 - loss: 0.6287 - acc: 0.7802 - kappa: 0.9209\n",
      "Iteration 000211: OneCycleScheduler setting learning rate to 8.918892666342885e-05.\n",
      "212/343 [=================>............] - ETA: 2:02 - loss: 0.6286 - acc: 0.7807 - kappa: 0.9210\n",
      "Iteration 000212: OneCycleScheduler setting learning rate to 8.942204953861098e-05.\n",
      "213/343 [=================>............] - ETA: 2:01 - loss: 0.6289 - acc: 0.7805 - kappa: 0.9212\n",
      "Iteration 000213: OneCycleScheduler setting learning rate to 8.96551724137931e-05.\n",
      "214/343 [=================>............] - ETA: 2:00 - loss: 0.6286 - acc: 0.7798 - kappa: 0.9210\n",
      "Iteration 000214: OneCycleScheduler setting learning rate to 8.988829528897523e-05.\n",
      "215/343 [=================>............] - ETA: 1:59 - loss: 0.6272 - acc: 0.7802 - kappa: 0.9213\n",
      "Iteration 000215: OneCycleScheduler setting learning rate to 9.012141816415737e-05.\n",
      "216/343 [=================>............] - ETA: 1:58 - loss: 0.6268 - acc: 0.7807 - kappa: 0.9216\n",
      "Iteration 000216: OneCycleScheduler setting learning rate to 9.035454103933949e-05.\n",
      "217/343 [=================>............] - ETA: 1:57 - loss: 0.6256 - acc: 0.7811 - kappa: 0.9219\n",
      "Iteration 000217: OneCycleScheduler setting learning rate to 9.058766391452162e-05.\n",
      "218/343 [==================>...........] - ETA: 1:56 - loss: 0.6249 - acc: 0.7810 - kappa: 0.9220\n",
      "Iteration 000218: OneCycleScheduler setting learning rate to 9.082078678970376e-05.\n",
      "219/343 [==================>...........] - ETA: 1:55 - loss: 0.6262 - acc: 0.7803 - kappa: 0.9218\n",
      "Iteration 000219: OneCycleScheduler setting learning rate to 9.105390966488588e-05.\n",
      "220/343 [==================>...........] - ETA: 1:54 - loss: 0.6251 - acc: 0.7807 - kappa: 0.9220\n",
      "Iteration 000220: OneCycleScheduler setting learning rate to 9.1287032540068e-05.\n",
      "221/343 [==================>...........] - ETA: 1:53 - loss: 0.6242 - acc: 0.7811 - kappa: 0.9223\n",
      "Iteration 000221: OneCycleScheduler setting learning rate to 9.152015541525013e-05.\n",
      "222/343 [==================>...........] - ETA: 1:52 - loss: 0.6224 - acc: 0.7821 - kappa: 0.9226\n",
      "Iteration 000222: OneCycleScheduler setting learning rate to 9.175327829043226e-05.\n",
      "223/343 [==================>...........] - ETA: 1:51 - loss: 0.6249 - acc: 0.7808 - kappa: 0.9217\n",
      "Iteration 000223: OneCycleScheduler setting learning rate to 9.198640116561438e-05.\n",
      "224/343 [==================>...........] - ETA: 1:50 - loss: 0.6240 - acc: 0.7812 - kappa: 0.9219\n",
      "Iteration 000224: OneCycleScheduler setting learning rate to 9.221952404079651e-05.\n",
      "225/343 [==================>...........] - ETA: 1:49 - loss: 0.6245 - acc: 0.7806 - kappa: 0.9214\n",
      "Iteration 000225: OneCycleScheduler setting learning rate to 9.245264691597863e-05.\n",
      "226/343 [==================>...........] - ETA: 1:48 - loss: 0.6244 - acc: 0.7810 - kappa: 0.9217\n",
      "Iteration 000226: OneCycleScheduler setting learning rate to 9.268576979116076e-05.\n",
      "227/343 [==================>...........] - ETA: 1:47 - loss: 0.6244 - acc: 0.7808 - kappa: 0.9218\n",
      "Iteration 000227: OneCycleScheduler setting learning rate to 9.291889266634288e-05.\n",
      "228/343 [==================>...........] - ETA: 1:46 - loss: 0.6225 - acc: 0.7818 - kappa: 0.9221\n",
      "Iteration 000228: OneCycleScheduler setting learning rate to 9.315201554152502e-05.\n",
      "229/343 [===================>..........] - ETA: 1:46 - loss: 0.6222 - acc: 0.7817 - kappa: 0.9221\n",
      "Iteration 000229: OneCycleScheduler setting learning rate to 9.338513841670715e-05.\n",
      "230/343 [===================>..........] - ETA: 1:45 - loss: 0.6235 - acc: 0.7810 - kappa: 0.9208\n",
      "Iteration 000230: OneCycleScheduler setting learning rate to 9.361826129188927e-05.\n",
      "231/343 [===================>..........] - ETA: 1:44 - loss: 0.6293 - acc: 0.7808 - kappa: 0.9199\n",
      "Iteration 000231: OneCycleScheduler setting learning rate to 9.38513841670714e-05.\n",
      "232/343 [===================>..........] - ETA: 1:43 - loss: 0.6269 - acc: 0.7818 - kappa: 0.9203\n",
      "Iteration 000232: OneCycleScheduler setting learning rate to 9.408450704225354e-05.\n",
      "233/343 [===================>..........] - ETA: 1:42 - loss: 0.6278 - acc: 0.7811 - kappa: 0.9203\n",
      "Iteration 000233: OneCycleScheduler setting learning rate to 9.431762991743566e-05.\n",
      "234/343 [===================>..........] - ETA: 1:41 - loss: 0.6269 - acc: 0.7810 - kappa: 0.9204\n",
      "Iteration 000234: OneCycleScheduler setting learning rate to 9.455075279261779e-05.\n",
      "235/343 [===================>..........] - ETA: 1:40 - loss: 0.6263 - acc: 0.7809 - kappa: 0.9206\n",
      "Iteration 000235: OneCycleScheduler setting learning rate to 9.478387566779991e-05.\n",
      "236/343 [===================>..........] - ETA: 1:39 - loss: 0.6254 - acc: 0.7812 - kappa: 0.9208\n",
      "Iteration 000236: OneCycleScheduler setting learning rate to 9.501699854298204e-05.\n",
      "237/343 [===================>..........] - ETA: 1:38 - loss: 0.6264 - acc: 0.7806 - kappa: 0.9199\n",
      "Iteration 000237: OneCycleScheduler setting learning rate to 9.525012141816416e-05.\n",
      "238/343 [===================>..........] - ETA: 1:37 - loss: 0.6288 - acc: 0.7794 - kappa: 0.9187\n",
      "Iteration 000238: OneCycleScheduler setting learning rate to 9.548324429334629e-05.\n",
      "239/343 [===================>..........] - ETA: 1:37 - loss: 0.6288 - acc: 0.7788 - kappa: 0.9187\n",
      "Iteration 000239: OneCycleScheduler setting learning rate to 9.571636716852841e-05.\n",
      "240/343 [===================>..........] - ETA: 1:36 - loss: 0.6277 - acc: 0.7786 - kappa: 0.9187\n",
      "Iteration 000240: OneCycleScheduler setting learning rate to 9.594949004371054e-05.\n",
      "241/343 [====================>.........] - ETA: 1:35 - loss: 0.6281 - acc: 0.7780 - kappa: 0.9186\n",
      "Iteration 000241: OneCycleScheduler setting learning rate to 9.618261291889266e-05.\n",
      "242/343 [====================>.........] - ETA: 1:34 - loss: 0.6271 - acc: 0.7784 - kappa: 0.9189\n",
      "Iteration 000242: OneCycleScheduler setting learning rate to 9.64157357940748e-05.\n",
      "243/343 [====================>.........] - ETA: 1:33 - loss: 0.6282 - acc: 0.7778 - kappa: 0.9184\n",
      "Iteration 000243: OneCycleScheduler setting learning rate to 9.664885866925693e-05.\n",
      "244/343 [====================>.........] - ETA: 1:32 - loss: 0.6285 - acc: 0.7772 - kappa: 0.9179\n",
      "Iteration 000244: OneCycleScheduler setting learning rate to 9.688198154443905e-05.\n",
      "245/343 [====================>.........] - ETA: 1:31 - loss: 0.6271 - acc: 0.7781 - kappa: 0.9183\n",
      "Iteration 000245: OneCycleScheduler setting learning rate to 9.711510441962119e-05.\n",
      "246/343 [====================>.........] - ETA: 1:30 - loss: 0.6279 - acc: 0.7769 - kappa: 0.9181\n",
      "Iteration 000246: OneCycleScheduler setting learning rate to 9.734822729480332e-05.\n",
      "247/343 [====================>.........] - ETA: 1:29 - loss: 0.6268 - acc: 0.7778 - kappa: 0.9184\n",
      "Iteration 000247: OneCycleScheduler setting learning rate to 9.758135016998544e-05.\n",
      "248/343 [====================>.........] - ETA: 1:28 - loss: 0.6288 - acc: 0.7767 - kappa: 0.9172\n",
      "Iteration 000248: OneCycleScheduler setting learning rate to 9.781447304516757e-05.\n",
      "249/343 [====================>.........] - ETA: 1:27 - loss: 0.6284 - acc: 0.7771 - kappa: 0.9174\n",
      "Iteration 000249: OneCycleScheduler setting learning rate to 9.804759592034969e-05.\n",
      "250/343 [====================>.........] - ETA: 1:27 - loss: 0.6274 - acc: 0.7780 - kappa: 0.9177\n",
      "Iteration 000250: OneCycleScheduler setting learning rate to 9.828071879553182e-05.\n",
      "251/343 [====================>.........] - ETA: 1:26 - loss: 0.6269 - acc: 0.7784 - kappa: 0.9180\n",
      "Iteration 000251: OneCycleScheduler setting learning rate to 9.851384167071394e-05.\n",
      "252/343 [=====================>........] - ETA: 1:25 - loss: 0.6254 - acc: 0.7793 - kappa: 0.9184\n",
      "Iteration 000252: OneCycleScheduler setting learning rate to 9.874696454589607e-05.\n",
      "253/343 [=====================>........] - ETA: 1:24 - loss: 0.6261 - acc: 0.7792 - kappa: 0.9186\n",
      "Iteration 000253: OneCycleScheduler setting learning rate to 9.89800874210782e-05.\n",
      "254/343 [=====================>........] - ETA: 1:23 - loss: 0.6266 - acc: 0.7795 - kappa: 0.9188\n",
      "Iteration 000254: OneCycleScheduler setting learning rate to 9.921321029626032e-05.\n",
      "255/343 [=====================>........] - ETA: 1:22 - loss: 0.6264 - acc: 0.7794 - kappa: 0.9188\n",
      "Iteration 000255: OneCycleScheduler setting learning rate to 9.944633317144246e-05.\n",
      "256/343 [=====================>........] - ETA: 1:21 - loss: 0.6251 - acc: 0.7803 - kappa: 0.9191\n",
      "Iteration 000256: OneCycleScheduler setting learning rate to 9.967945604662458e-05.\n",
      "257/343 [=====================>........] - ETA: 1:20 - loss: 0.6276 - acc: 0.7797 - kappa: 0.9180\n",
      "Iteration 000257: OneCycleScheduler setting learning rate to 9.991257892180671e-05.\n",
      "258/343 [=====================>........] - ETA: 1:19 - loss: 0.6299 - acc: 0.7796 - kappa: 0.9182\n",
      "Iteration 000258: OneCycleScheduler setting learning rate to 0.00010014570179698885.\n",
      "259/343 [=====================>........] - ETA: 1:18 - loss: 0.6311 - acc: 0.7790 - kappa: 0.9180\n",
      "Iteration 000259: OneCycleScheduler setting learning rate to 0.00010037882467217097.\n",
      "260/343 [=====================>........] - ETA: 1:17 - loss: 0.6350 - acc: 0.7779 - kappa: 0.9175\n",
      "Iteration 000260: OneCycleScheduler setting learning rate to 0.0001006119475473531.\n",
      "261/343 [=====================>........] - ETA: 1:16 - loss: 0.6356 - acc: 0.7778 - kappa: 0.9176\n",
      "Iteration 000261: OneCycleScheduler setting learning rate to 0.00010084507042253522.\n",
      "262/343 [=====================>........] - ETA: 1:15 - loss: 0.6344 - acc: 0.7786 - kappa: 0.9179\n",
      "Iteration 000262: OneCycleScheduler setting learning rate to 0.00010107819329771735.\n",
      "263/343 [======================>.......] - ETA: 1:14 - loss: 0.6339 - acc: 0.7790 - kappa: 0.9182\n",
      "Iteration 000263: OneCycleScheduler setting learning rate to 0.00010131131617289947.\n",
      "264/343 [======================>.......] - ETA: 1:13 - loss: 0.6342 - acc: 0.7789 - kappa: 0.9184\n",
      "Iteration 000264: OneCycleScheduler setting learning rate to 0.0001015444390480816.\n",
      "265/343 [======================>.......] - ETA: 1:12 - loss: 0.6364 - acc: 0.7783 - kappa: 0.9180\n",
      "Iteration 000265: OneCycleScheduler setting learning rate to 0.00010177756192326372.\n",
      "266/343 [======================>.......] - ETA: 1:12 - loss: 0.6377 - acc: 0.7768 - kappa: 0.9168\n",
      "Iteration 000266: OneCycleScheduler setting learning rate to 0.00010201068479844585.\n",
      "267/343 [======================>.......] - ETA: 1:11 - loss: 0.6366 - acc: 0.7776 - kappa: 0.9171\n",
      "Iteration 000267: OneCycleScheduler setting learning rate to 0.00010224380767362797.\n",
      "268/343 [======================>.......] - ETA: 1:10 - loss: 0.6354 - acc: 0.7785 - kappa: 0.9174\n",
      "Iteration 000268: OneCycleScheduler setting learning rate to 0.0001024769305488101.\n",
      "269/343 [======================>.......] - ETA: 1:09 - loss: 0.6363 - acc: 0.7783 - kappa: 0.9176\n",
      "Iteration 000269: OneCycleScheduler setting learning rate to 0.00010271005342399222.\n",
      "270/343 [======================>.......] - ETA: 1:08 - loss: 0.6358 - acc: 0.7787 - kappa: 0.9179\n",
      "Iteration 000270: OneCycleScheduler setting learning rate to 0.00010294317629917438.\n",
      "271/343 [======================>.......] - ETA: 1:07 - loss: 0.6354 - acc: 0.7786 - kappa: 0.9180\n",
      "Iteration 000271: OneCycleScheduler setting learning rate to 0.0001031762991743565.\n",
      "272/343 [======================>.......] - ETA: 1:06 - loss: 0.6345 - acc: 0.7790 - kappa: 0.9182\n",
      "Iteration 000272: OneCycleScheduler setting learning rate to 0.00010340942204953863.\n",
      "273/343 [======================>.......] - ETA: 1:05 - loss: 0.6342 - acc: 0.7788 - kappa: 0.9184\n",
      "Iteration 000273: OneCycleScheduler setting learning rate to 0.00010364254492472075.\n",
      "274/343 [======================>.......] - ETA: 1:04 - loss: 0.6344 - acc: 0.7787 - kappa: 0.9185\n",
      "Iteration 000274: OneCycleScheduler setting learning rate to 0.00010387566779990288.\n",
      "275/343 [=======================>......] - ETA: 1:03 - loss: 0.6353 - acc: 0.7782 - kappa: 0.9177\n",
      "Iteration 000275: OneCycleScheduler setting learning rate to 0.000104108790675085.\n",
      "276/343 [=======================>......] - ETA: 1:02 - loss: 0.6347 - acc: 0.7785 - kappa: 0.9179\n",
      "Iteration 000276: OneCycleScheduler setting learning rate to 0.00010434191355026713.\n",
      "277/343 [=======================>......] - ETA: 1:01 - loss: 0.6334 - acc: 0.7789 - kappa: 0.9181\n",
      "Iteration 000277: OneCycleScheduler setting learning rate to 0.00010457503642544925.\n",
      "278/343 [=======================>......] - ETA: 1:01 - loss: 0.6323 - acc: 0.7797 - kappa: 0.9184\n",
      "Iteration 000278: OneCycleScheduler setting learning rate to 0.00010480815930063138.\n",
      "279/343 [=======================>......] - ETA: 1:00 - loss: 0.6327 - acc: 0.7791 - kappa: 0.9182\n",
      "Iteration 000279: OneCycleScheduler setting learning rate to 0.0001050412821758135.\n",
      "280/343 [=======================>......] - ETA: 59s - loss: 0.6364 - acc: 0.7781 - kappa: 0.9167 \n",
      "Iteration 000280: OneCycleScheduler setting learning rate to 0.00010527440505099563.\n",
      "281/343 [=======================>......] - ETA: 58s - loss: 0.6356 - acc: 0.7789 - kappa: 0.9170\n",
      "Iteration 000281: OneCycleScheduler setting learning rate to 0.00010550752792617775.\n",
      "282/343 [=======================>......] - ETA: 57s - loss: 0.6348 - acc: 0.7793 - kappa: 0.9173\n",
      "Iteration 000282: OneCycleScheduler setting learning rate to 0.00010574065080135988.\n",
      "283/343 [=======================>......] - ETA: 56s - loss: 0.6341 - acc: 0.7792 - kappa: 0.9173\n",
      "Iteration 000283: OneCycleScheduler setting learning rate to 0.00010597377367654203.\n",
      "284/343 [=======================>......] - ETA: 55s - loss: 0.6354 - acc: 0.7786 - kappa: 0.9170\n",
      "Iteration 000284: OneCycleScheduler setting learning rate to 0.00010620689655172416.\n",
      "285/343 [=======================>......] - ETA: 54s - loss: 0.6350 - acc: 0.7785 - kappa: 0.9170\n",
      "Iteration 000285: OneCycleScheduler setting learning rate to 0.00010644001942690628.\n",
      "286/343 [========================>.....] - ETA: 53s - loss: 0.6348 - acc: 0.7780 - kappa: 0.9166\n",
      "Iteration 000286: OneCycleScheduler setting learning rate to 0.00010667314230208841.\n",
      "287/343 [========================>.....] - ETA: 52s - loss: 0.6338 - acc: 0.7787 - kappa: 0.9169\n",
      "Iteration 000287: OneCycleScheduler setting learning rate to 0.00010690626517727053.\n",
      "288/343 [========================>.....] - ETA: 51s - loss: 0.6325 - acc: 0.7795 - kappa: 0.9172\n",
      "Iteration 000288: OneCycleScheduler setting learning rate to 0.00010713938805245266.\n",
      "289/343 [========================>.....] - ETA: 50s - loss: 0.6320 - acc: 0.7794 - kappa: 0.9174\n",
      "Iteration 000289: OneCycleScheduler setting learning rate to 0.00010737251092763478.\n",
      "290/343 [========================>.....] - ETA: 49s - loss: 0.6337 - acc: 0.7789 - kappa: 0.9172\n",
      "Iteration 000290: OneCycleScheduler setting learning rate to 0.00010760563380281691.\n",
      "291/343 [========================>.....] - ETA: 48s - loss: 0.6328 - acc: 0.7788 - kappa: 0.9174\n",
      "Iteration 000291: OneCycleScheduler setting learning rate to 0.00010783875667799903.\n",
      "292/343 [========================>.....] - ETA: 47s - loss: 0.6316 - acc: 0.7791 - kappa: 0.9176\n",
      "Iteration 000292: OneCycleScheduler setting learning rate to 0.00010807187955318116.\n",
      "293/343 [========================>.....] - ETA: 46s - loss: 0.6304 - acc: 0.7794 - kappa: 0.9179\n",
      "Iteration 000293: OneCycleScheduler setting learning rate to 0.00010830500242836328.\n",
      "294/343 [========================>.....] - ETA: 45s - loss: 0.6296 - acc: 0.7793 - kappa: 0.9181\n",
      "Iteration 000294: OneCycleScheduler setting learning rate to 0.00010853812530354541.\n",
      "295/343 [========================>.....] - ETA: 44s - loss: 0.6287 - acc: 0.7801 - kappa: 0.9184\n",
      "Iteration 000295: OneCycleScheduler setting learning rate to 0.00010877124817872753.\n",
      "296/343 [========================>.....] - ETA: 44s - loss: 0.6290 - acc: 0.7800 - kappa: 0.9185\n",
      "Iteration 000296: OneCycleScheduler setting learning rate to 0.00010900437105390969.\n",
      "297/343 [========================>.....] - ETA: 43s - loss: 0.6322 - acc: 0.7795 - kappa: 0.9184\n",
      "Iteration 000297: OneCycleScheduler setting learning rate to 0.00010923749392909181.\n",
      "298/343 [=========================>....] - ETA: 42s - loss: 0.6328 - acc: 0.7789 - kappa: 0.9180\n",
      "Iteration 000298: OneCycleScheduler setting learning rate to 0.00010947061680427394.\n",
      "299/343 [=========================>....] - ETA: 41s - loss: 0.6315 - acc: 0.7797 - kappa: 0.9183\n",
      "Iteration 000299: OneCycleScheduler setting learning rate to 0.00010970373967945606.\n",
      "300/343 [=========================>....] - ETA: 40s - loss: 0.6309 - acc: 0.7796 - kappa: 0.9184\n",
      "Iteration 000300: OneCycleScheduler setting learning rate to 0.00010993686255463819.\n",
      "301/343 [=========================>....] - ETA: 39s - loss: 0.6326 - acc: 0.7791 - kappa: 0.9185\n",
      "Iteration 000301: OneCycleScheduler setting learning rate to 0.00011016998542982031.\n",
      "302/343 [=========================>....] - ETA: 38s - loss: 0.6331 - acc: 0.7790 - kappa: 0.9183\n",
      "Iteration 000302: OneCycleScheduler setting learning rate to 0.00011040310830500244.\n",
      "303/343 [=========================>....] - ETA: 37s - loss: 0.6317 - acc: 0.7797 - kappa: 0.9186\n",
      "Iteration 000303: OneCycleScheduler setting learning rate to 0.00011063623118018456.\n",
      "304/343 [=========================>....] - ETA: 36s - loss: 0.6318 - acc: 0.7800 - kappa: 0.9186\n",
      "Iteration 000304: OneCycleScheduler setting learning rate to 0.00011086935405536669.\n",
      "305/343 [=========================>....] - ETA: 35s - loss: 0.6326 - acc: 0.7795 - kappa: 0.9185\n",
      "Iteration 000305: OneCycleScheduler setting learning rate to 0.00011110247693054881.\n",
      "306/343 [=========================>....] - ETA: 34s - loss: 0.6325 - acc: 0.7794 - kappa: 0.9185\n",
      "Iteration 000306: OneCycleScheduler setting learning rate to 0.00011133559980573094.\n",
      "307/343 [=========================>....] - ETA: 33s - loss: 0.6312 - acc: 0.7797 - kappa: 0.9188\n",
      "Iteration 000307: OneCycleScheduler setting learning rate to 0.00011156872268091306.\n",
      "308/343 [=========================>....] - ETA: 33s - loss: 0.6313 - acc: 0.7796 - kappa: 0.9188\n",
      "Iteration 000308: OneCycleScheduler setting learning rate to 0.00011180184555609519.\n",
      "309/343 [==========================>...] - ETA: 32s - loss: 0.6322 - acc: 0.7791 - kappa: 0.9188\n",
      "Iteration 000309: OneCycleScheduler setting learning rate to 0.00011203496843127731.\n",
      "310/343 [==========================>...] - ETA: 31s - loss: 0.6322 - acc: 0.7790 - kappa: 0.9189\n",
      "Iteration 000310: OneCycleScheduler setting learning rate to 0.00011226809130645947.\n",
      "311/343 [==========================>...] - ETA: 30s - loss: 0.6307 - acc: 0.7793 - kappa: 0.9191\n",
      "Iteration 000311: OneCycleScheduler setting learning rate to 0.00011250121418164159.\n",
      "312/343 [==========================>...] - ETA: 29s - loss: 0.6312 - acc: 0.7788 - kappa: 0.9187\n",
      "Iteration 000312: OneCycleScheduler setting learning rate to 0.00011273433705682372.\n",
      "313/343 [==========================>...] - ETA: 28s - loss: 0.6326 - acc: 0.7784 - kappa: 0.9184\n",
      "Iteration 000313: OneCycleScheduler setting learning rate to 0.00011296745993200584.\n",
      "314/343 [==========================>...] - ETA: 27s - loss: 0.6316 - acc: 0.7791 - kappa: 0.9186\n",
      "Iteration 000314: OneCycleScheduler setting learning rate to 0.00011320058280718797.\n",
      "315/343 [==========================>...] - ETA: 26s - loss: 0.6348 - acc: 0.7782 - kappa: 0.9169\n",
      "Iteration 000315: OneCycleScheduler setting learning rate to 0.00011343370568237009.\n",
      "316/343 [==========================>...] - ETA: 25s - loss: 0.6351 - acc: 0.7777 - kappa: 0.9168\n",
      "Iteration 000316: OneCycleScheduler setting learning rate to 0.00011366682855755222.\n",
      "317/343 [==========================>...] - ETA: 24s - loss: 0.6345 - acc: 0.7776 - kappa: 0.9169\n",
      "Iteration 000317: OneCycleScheduler setting learning rate to 0.00011389995143273434.\n",
      "318/343 [==========================>...] - ETA: 23s - loss: 0.6368 - acc: 0.7771 - kappa: 0.9168\n",
      "Iteration 000318: OneCycleScheduler setting learning rate to 0.00011413307430791647.\n",
      "319/343 [==========================>...] - ETA: 22s - loss: 0.6363 - acc: 0.7770 - kappa: 0.9170\n",
      "Iteration 000319: OneCycleScheduler setting learning rate to 0.0001143661971830986.\n",
      "320/343 [==========================>...] - ETA: 21s - loss: 0.6367 - acc: 0.7766 - kappa: 0.9166\n",
      "Iteration 000320: OneCycleScheduler setting learning rate to 0.00011459932005828072.\n",
      "321/343 [===========================>..] - ETA: 20s - loss: 0.6375 - acc: 0.7761 - kappa: 0.9165\n",
      "Iteration 000321: OneCycleScheduler setting learning rate to 0.00011483244293346284.\n",
      "322/343 [===========================>..] - ETA: 19s - loss: 0.6378 - acc: 0.7760 - kappa: 0.9163\n",
      "Iteration 000322: OneCycleScheduler setting learning rate to 0.00011506556580864497.\n",
      "323/343 [===========================>..] - ETA: 19s - loss: 0.6377 - acc: 0.7763 - kappa: 0.9165\n",
      "Iteration 000323: OneCycleScheduler setting learning rate to 0.00011529868868382712.\n",
      "324/343 [===========================>..] - ETA: 18s - loss: 0.6390 - acc: 0.7755 - kappa: 0.9159\n",
      "Iteration 000324: OneCycleScheduler setting learning rate to 0.00011553181155900925.\n",
      "325/343 [===========================>..] - ETA: 17s - loss: 0.6384 - acc: 0.7758 - kappa: 0.9161\n",
      "Iteration 000325: OneCycleScheduler setting learning rate to 0.00011576493443419137.\n",
      "326/343 [===========================>..] - ETA: 16s - loss: 0.6377 - acc: 0.7757 - kappa: 0.9163\n",
      "Iteration 000326: OneCycleScheduler setting learning rate to 0.0001159980573093735.\n",
      "327/343 [===========================>..] - ETA: 15s - loss: 0.6381 - acc: 0.7756 - kappa: 0.9163\n",
      "Iteration 000327: OneCycleScheduler setting learning rate to 0.00011623118018455562.\n",
      "328/343 [===========================>..] - ETA: 14s - loss: 0.6389 - acc: 0.7748 - kappa: 0.9162\n",
      "Iteration 000328: OneCycleScheduler setting learning rate to 0.00011646430305973775.\n",
      "329/343 [===========================>..] - ETA: 13s - loss: 0.6395 - acc: 0.7747 - kappa: 0.9161\n",
      "Iteration 000329: OneCycleScheduler setting learning rate to 0.00011669742593491987.\n",
      "330/343 [===========================>..] - ETA: 12s - loss: 0.6405 - acc: 0.7739 - kappa: 0.9157\n",
      "Iteration 000330: OneCycleScheduler setting learning rate to 0.000116930548810102.\n",
      "331/343 [===========================>..] - ETA: 11s - loss: 0.6408 - acc: 0.7738 - kappa: 0.9159\n",
      "Iteration 000331: OneCycleScheduler setting learning rate to 0.00011716367168528412.\n",
      "332/343 [============================>.] - ETA: 10s - loss: 0.6413 - acc: 0.7741 - kappa: 0.9161\n",
      "Iteration 000332: OneCycleScheduler setting learning rate to 0.00011739679456046625.\n",
      "333/343 [============================>.] - ETA: 9s - loss: 0.6417 - acc: 0.7740 - kappa: 0.9160 \n",
      "Iteration 000333: OneCycleScheduler setting learning rate to 0.00011762991743564837.\n",
      "334/343 [============================>.] - ETA: 8s - loss: 0.6424 - acc: 0.7736 - kappa: 0.9157\n",
      "Iteration 000334: OneCycleScheduler setting learning rate to 0.0001178630403108305.\n",
      "335/343 [============================>.] - ETA: 7s - loss: 0.6420 - acc: 0.7735 - kappa: 0.9157\n",
      "Iteration 000335: OneCycleScheduler setting learning rate to 0.00011809616318601262.\n",
      "336/343 [============================>.] - ETA: 6s - loss: 0.6431 - acc: 0.7727 - kappa: 0.9156\n",
      "Iteration 000336: OneCycleScheduler setting learning rate to 0.00011832928606119478.\n",
      "337/343 [============================>.] - ETA: 5s - loss: 0.6438 - acc: 0.7723 - kappa: 0.9155\n",
      "Iteration 000337: OneCycleScheduler setting learning rate to 0.0001185624089363769.\n",
      "338/343 [============================>.] - ETA: 4s - loss: 0.6433 - acc: 0.7726 - kappa: 0.9156\n",
      "Iteration 000338: OneCycleScheduler setting learning rate to 0.00011879553181155903.\n",
      "339/343 [============================>.] - ETA: 3s - loss: 0.6433 - acc: 0.7725 - kappa: 0.9157\n",
      "Iteration 000339: OneCycleScheduler setting learning rate to 0.00011902865468674115.\n",
      "340/343 [============================>.] - ETA: 2s - loss: 0.6434 - acc: 0.7724 - kappa: 0.9153\n",
      "Iteration 000340: OneCycleScheduler setting learning rate to 0.00011926177756192328.\n",
      "341/343 [============================>.] - ETA: 1s - loss: 0.6440 - acc: 0.7716 - kappa: 0.9150\n",
      "Iteration 000341: OneCycleScheduler setting learning rate to 0.0001194949004371054.\n",
      "342/343 [============================>.] - ETA: 0s - loss: 0.6440 - acc: 0.7719 - kappa: 0.9153\n",
      "Iteration 000342: OneCycleScheduler setting learning rate to 0.00011972802331228753.\n",
      "343/343 [==============================] - 420s 1s/step - loss: 0.6435 - acc: 0.7722 - kappa: 0.9155 - val_loss: 0.5722 - val_acc: 0.7753 - val_kappa: 0.9228\n",
      "Epoch 3/30\n",
      "\n",
      "Iteration 000000: OneCycleScheduler setting learning rate to 4e-05.\n",
      "  1/343 [..............................] - ETA: 46s - loss: 0.4063 - acc: 0.8750 - kappa: 0.9688\n",
      "Iteration 000001: OneCycleScheduler setting learning rate to 4.023312287518213e-05.\n",
      "  2/343 [..............................] - ETA: 46s - loss: 0.5546 - acc: 0.8125 - kappa: 0.9492\n",
      "Iteration 000002: OneCycleScheduler setting learning rate to 4.046624575036426e-05.\n",
      "  3/343 [..............................] - ETA: 47s - loss: 0.4402 - acc: 0.8750 - kappa: 0.9661\n",
      "Iteration 000003: OneCycleScheduler setting learning rate to 4.0699368625546386e-05.\n",
      "  4/343 [..............................] - ETA: 44s - loss: 0.5293 - acc: 0.8438 - kappa: 0.9668\n",
      "Iteration 000004: OneCycleScheduler setting learning rate to 4.093249150072851e-05.\n",
      "  5/343 [..............................] - ETA: 45s - loss: 0.5013 - acc: 0.8500 - kappa: 0.9719\n",
      "Iteration 000005: OneCycleScheduler setting learning rate to 4.1165614375910636e-05.\n",
      "  6/343 [..............................] - ETA: 44s - loss: 0.5126 - acc: 0.8542 - kappa: 0.9753\n",
      "Iteration 000006: OneCycleScheduler setting learning rate to 4.139873725109277e-05.\n",
      "  7/343 [..............................] - ETA: 44s - loss: 0.5573 - acc: 0.8214 - kappa: 0.9386\n",
      "Iteration 000007: OneCycleScheduler setting learning rate to 4.1631860126274893e-05.\n",
      "  8/343 [..............................] - ETA: 44s - loss: 0.5593 - acc: 0.8125 - kappa: 0.9375\n",
      "Iteration 000008: OneCycleScheduler setting learning rate to 4.186498300145702e-05.\n",
      "  9/343 [..............................] - ETA: 44s - loss: 0.5654 - acc: 0.8056 - kappa: 0.9410\n",
      "Iteration 000009: OneCycleScheduler setting learning rate to 4.209810587663915e-05.\n",
      " 10/343 [..............................] - ETA: 45s - loss: 0.5721 - acc: 0.7875 - kappa: 0.9344\n",
      "Iteration 000010: OneCycleScheduler setting learning rate to 4.2331228751821276e-05.\n",
      " 11/343 [..............................] - ETA: 44s - loss: 0.5694 - acc: 0.7841 - kappa: 0.9339\n",
      "Iteration 000011: OneCycleScheduler setting learning rate to 4.25643516270034e-05.\n",
      " 12/343 [>.............................] - ETA: 49s - loss: 0.5452 - acc: 0.7917 - kappa: 0.9388\n",
      "Iteration 000012: OneCycleScheduler setting learning rate to 4.279747450218553e-05.\n",
      " 13/343 [>.............................] - ETA: 1:27 - loss: 0.5850 - acc: 0.7596 - kappa: 0.9219\n",
      "Iteration 000013: OneCycleScheduler setting learning rate to 4.303059737736766e-05.\n",
      " 14/343 [>.............................] - ETA: 1:59 - loss: 0.5924 - acc: 0.7500 - kappa: 0.9074\n",
      "Iteration 000014: OneCycleScheduler setting learning rate to 4.3263720252549784e-05.\n",
      " 15/343 [>.............................] - ETA: 2:13 - loss: 0.5761 - acc: 0.7583 - kappa: 0.9130\n",
      "Iteration 000015: OneCycleScheduler setting learning rate to 4.3496843127731916e-05.\n",
      " 16/343 [>.............................] - ETA: 2:30 - loss: 0.5704 - acc: 0.7578 - kappa: 0.9141\n",
      "Iteration 000016: OneCycleScheduler setting learning rate to 4.372996600291404e-05.\n",
      " 17/343 [>.............................] - ETA: 2:44 - loss: 0.5643 - acc: 0.7647 - kappa: 0.9187\n",
      "Iteration 000017: OneCycleScheduler setting learning rate to 4.3963088878096166e-05.\n",
      " 18/343 [>.............................] - ETA: 3:05 - loss: 0.5833 - acc: 0.7500 - kappa: 0.9076\n",
      "Iteration 000018: OneCycleScheduler setting learning rate to 4.419621175327829e-05.\n",
      " 19/343 [>.............................] - ETA: 3:18 - loss: 0.5728 - acc: 0.7632 - kappa: 0.9124\n",
      "Iteration 000019: OneCycleScheduler setting learning rate to 4.442933462846042e-05.\n",
      " 20/343 [>.............................] - ETA: 3:32 - loss: 0.5634 - acc: 0.7688 - kappa: 0.9164\n",
      "Iteration 000020: OneCycleScheduler setting learning rate to 4.466245750364255e-05.\n",
      " 21/343 [>.............................] - ETA: 3:35 - loss: 0.5564 - acc: 0.7738 - kappa: 0.9200\n",
      "Iteration 000021: OneCycleScheduler setting learning rate to 4.4895580378824674e-05.\n",
      " 22/343 [>.............................] - ETA: 3:40 - loss: 0.5533 - acc: 0.7784 - kappa: 0.9233\n",
      "Iteration 000022: OneCycleScheduler setting learning rate to 4.5128703254006806e-05.\n",
      " 23/343 [=>............................] - ETA: 3:44 - loss: 0.5660 - acc: 0.7717 - kappa: 0.9236\n",
      "Iteration 000023: OneCycleScheduler setting learning rate to 4.536182612918893e-05.\n",
      " 24/343 [=>............................] - ETA: 3:44 - loss: 0.5580 - acc: 0.7760 - kappa: 0.9255\n",
      "Iteration 000024: OneCycleScheduler setting learning rate to 4.5594949004371056e-05.\n",
      " 25/343 [=>............................] - ETA: 3:46 - loss: 0.5488 - acc: 0.7800 - kappa: 0.9281\n",
      "Iteration 000025: OneCycleScheduler setting learning rate to 4.582807187955318e-05.\n",
      " 26/343 [=>............................] - ETA: 3:48 - loss: 0.5494 - acc: 0.7837 - kappa: 0.9306\n",
      "Iteration 000026: OneCycleScheduler setting learning rate to 4.606119475473531e-05.\n",
      " 27/343 [=>............................] - ETA: 3:50 - loss: 0.5582 - acc: 0.7870 - kappa: 0.9329\n",
      "Iteration 000027: OneCycleScheduler setting learning rate to 4.629431762991744e-05.\n",
      " 28/343 [=>............................] - ETA: 3:49 - loss: 0.5511 - acc: 0.7946 - kappa: 0.9353\n",
      "Iteration 000028: OneCycleScheduler setting learning rate to 4.6527440505099564e-05.\n",
      " 29/343 [=>............................] - ETA: 3:55 - loss: 0.5633 - acc: 0.7845 - kappa: 0.9243\n",
      "Iteration 000029: OneCycleScheduler setting learning rate to 4.6760563380281696e-05.\n",
      " 30/343 [=>............................] - ETA: 3:58 - loss: 0.5734 - acc: 0.7792 - kappa: 0.9227\n",
      "Iteration 000030: OneCycleScheduler setting learning rate to 4.699368625546382e-05.\n",
      " 31/343 [=>............................] - ETA: 3:58 - loss: 0.5674 - acc: 0.7823 - kappa: 0.9249\n",
      "Iteration 000031: OneCycleScheduler setting learning rate to 4.7226809130645946e-05.\n",
      " 32/343 [=>............................] - ETA: 3:58 - loss: 0.5602 - acc: 0.7812 - kappa: 0.9263\n",
      "Iteration 000032: OneCycleScheduler setting learning rate to 4.745993200582808e-05.\n",
      " 33/343 [=>............................] - ETA: 4:00 - loss: 0.5594 - acc: 0.7841 - kappa: 0.9283\n",
      "Iteration 000033: OneCycleScheduler setting learning rate to 4.7693054881010203e-05.\n",
      " 34/343 [=>............................] - ETA: 4:01 - loss: 0.5631 - acc: 0.7794 - kappa: 0.9283\n",
      "Iteration 000034: OneCycleScheduler setting learning rate to 4.792617775619233e-05.\n",
      " 35/343 [==>...........................] - ETA: 4:02 - loss: 0.5703 - acc: 0.7786 - kappa: 0.9295\n",
      "Iteration 000035: OneCycleScheduler setting learning rate to 4.815930063137446e-05.\n",
      " 36/343 [==>...........................] - ETA: 4:03 - loss: 0.5841 - acc: 0.7743 - kappa: 0.9295\n",
      "Iteration 000036: OneCycleScheduler setting learning rate to 4.8392423506556586e-05.\n",
      " 37/343 [==>...........................] - ETA: 4:03 - loss: 0.5798 - acc: 0.7770 - kappa: 0.9305\n",
      "Iteration 000037: OneCycleScheduler setting learning rate to 4.862554638173871e-05.\n",
      " 38/343 [==>...........................] - ETA: 4:05 - loss: 0.5757 - acc: 0.7796 - kappa: 0.9315\n",
      "Iteration 000038: OneCycleScheduler setting learning rate to 4.8858669256920836e-05.\n",
      " 39/343 [==>...........................] - ETA: 4:05 - loss: 0.5687 - acc: 0.7821 - kappa: 0.9331\n",
      "Iteration 000039: OneCycleScheduler setting learning rate to 4.909179213210297e-05.\n",
      " 40/343 [==>...........................] - ETA: 4:09 - loss: 0.5727 - acc: 0.7781 - kappa: 0.9316\n",
      "Iteration 000040: OneCycleScheduler setting learning rate to 4.9324915007285094e-05.\n",
      " 41/343 [==>...........................] - ETA: 4:08 - loss: 0.5674 - acc: 0.7805 - kappa: 0.9331\n",
      "Iteration 000041: OneCycleScheduler setting learning rate to 4.955803788246722e-05.\n",
      " 42/343 [==>...........................] - ETA: 4:09 - loss: 0.5673 - acc: 0.7827 - kappa: 0.9345\n",
      "Iteration 000042: OneCycleScheduler setting learning rate to 4.979116075764935e-05.\n",
      " 43/343 [==>...........................] - ETA: 4:07 - loss: 0.5636 - acc: 0.7878 - kappa: 0.9360\n",
      "Iteration 000043: OneCycleScheduler setting learning rate to 5.0024283632831476e-05.\n",
      " 44/343 [==>...........................] - ETA: 4:08 - loss: 0.5700 - acc: 0.7841 - kappa: 0.9359\n",
      "Iteration 000044: OneCycleScheduler setting learning rate to 5.02574065080136e-05.\n",
      " 45/343 [==>...........................] - ETA: 4:08 - loss: 0.5733 - acc: 0.7833 - kappa: 0.9366\n",
      "Iteration 000045: OneCycleScheduler setting learning rate to 5.0490529383195726e-05.\n",
      " 46/343 [===>..........................] - ETA: 4:09 - loss: 0.5697 - acc: 0.7826 - kappa: 0.9365\n",
      "Iteration 000046: OneCycleScheduler setting learning rate to 5.072365225837786e-05.\n",
      " 47/343 [===>..........................] - ETA: 4:08 - loss: 0.5638 - acc: 0.7872 - kappa: 0.9378\n",
      "Iteration 000047: OneCycleScheduler setting learning rate to 5.0956775133559984e-05.\n",
      " 48/343 [===>..........................] - ETA: 4:06 - loss: 0.5552 - acc: 0.7891 - kappa: 0.9390\n",
      "Iteration 000048: OneCycleScheduler setting learning rate to 5.1189898008742116e-05.\n",
      " 49/343 [===>..........................] - ETA: 4:06 - loss: 0.5527 - acc: 0.7883 - kappa: 0.9396\n",
      "Iteration 000049: OneCycleScheduler setting learning rate to 5.142302088392424e-05.\n",
      " 50/343 [===>..........................] - ETA: 4:05 - loss: 0.5576 - acc: 0.7875 - kappa: 0.9402\n",
      "Iteration 000050: OneCycleScheduler setting learning rate to 5.1656143759106366e-05.\n",
      " 51/343 [===>..........................] - ETA: 4:03 - loss: 0.5541 - acc: 0.7892 - kappa: 0.9412\n",
      "Iteration 000051: OneCycleScheduler setting learning rate to 5.188926663428849e-05.\n",
      " 52/343 [===>..........................] - ETA: 4:02 - loss: 0.5539 - acc: 0.7885 - kappa: 0.9410\n",
      "Iteration 000052: OneCycleScheduler setting learning rate to 5.212238950947062e-05.\n",
      " 53/343 [===>..........................] - ETA: 4:02 - loss: 0.5502 - acc: 0.7901 - kappa: 0.9419\n",
      "Iteration 000053: OneCycleScheduler setting learning rate to 5.235551238465275e-05.\n",
      " 54/343 [===>..........................] - ETA: 4:00 - loss: 0.5534 - acc: 0.7894 - kappa: 0.9417\n",
      "Iteration 000054: OneCycleScheduler setting learning rate to 5.2588635259834874e-05.\n",
      " 55/343 [===>..........................] - ETA: 3:59 - loss: 0.5620 - acc: 0.7864 - kappa: 0.9415\n",
      "Iteration 000055: OneCycleScheduler setting learning rate to 5.2821758135017006e-05.\n",
      " 56/343 [===>..........................] - ETA: 3:58 - loss: 0.5645 - acc: 0.7857 - kappa: 0.9413\n",
      "Iteration 000056: OneCycleScheduler setting learning rate to 5.305488101019913e-05.\n",
      " 57/343 [===>..........................] - ETA: 3:58 - loss: 0.5679 - acc: 0.7829 - kappa: 0.9401\n",
      "Iteration 000057: OneCycleScheduler setting learning rate to 5.3288003885381256e-05.\n",
      " 58/343 [====>.........................] - ETA: 3:56 - loss: 0.5670 - acc: 0.7823 - kappa: 0.9399\n",
      "Iteration 000058: OneCycleScheduler setting learning rate to 5.352112676056338e-05.\n",
      " 59/343 [====>.........................] - ETA: 3:57 - loss: 0.5620 - acc: 0.7839 - kappa: 0.9408\n",
      "Iteration 000059: OneCycleScheduler setting learning rate to 5.3754249635745514e-05.\n",
      " 60/343 [====>.........................] - ETA: 3:56 - loss: 0.5696 - acc: 0.7792 - kappa: 0.9385\n",
      "Iteration 000060: OneCycleScheduler setting learning rate to 5.398737251092764e-05.\n",
      " 61/343 [====>.........................] - ETA: 3:55 - loss: 0.5641 - acc: 0.7807 - kappa: 0.9394\n",
      "Iteration 000061: OneCycleScheduler setting learning rate to 5.4220495386109764e-05.\n",
      " 62/343 [====>.........................] - ETA: 3:54 - loss: 0.5666 - acc: 0.7802 - kappa: 0.9399\n",
      "Iteration 000062: OneCycleScheduler setting learning rate to 5.4453618261291896e-05.\n",
      " 63/343 [====>.........................] - ETA: 3:53 - loss: 0.5670 - acc: 0.7798 - kappa: 0.9397\n",
      "Iteration 000063: OneCycleScheduler setting learning rate to 5.468674113647402e-05.\n",
      " 64/343 [====>.........................] - ETA: 3:52 - loss: 0.5642 - acc: 0.7793 - kappa: 0.9402\n",
      "Iteration 000064: OneCycleScheduler setting learning rate to 5.4919864011656146e-05.\n",
      " 65/343 [====>.........................] - ETA: 3:50 - loss: 0.5592 - acc: 0.7827 - kappa: 0.9411\n",
      "Iteration 000065: OneCycleScheduler setting learning rate to 5.515298688683827e-05.\n",
      " 66/343 [====>.........................] - ETA: 3:49 - loss: 0.5703 - acc: 0.7784 - kappa: 0.9362\n",
      "Iteration 000066: OneCycleScheduler setting learning rate to 5.5386109762020404e-05.\n",
      " 67/343 [====>.........................] - ETA: 3:49 - loss: 0.5748 - acc: 0.7799 - kappa: 0.9370\n",
      "Iteration 000067: OneCycleScheduler setting learning rate to 5.561923263720253e-05.\n",
      " 68/343 [====>.........................] - ETA: 3:49 - loss: 0.5804 - acc: 0.7757 - kappa: 0.9361\n",
      "Iteration 000068: OneCycleScheduler setting learning rate to 5.585235551238466e-05.\n",
      " 69/343 [=====>........................] - ETA: 3:48 - loss: 0.5764 - acc: 0.7772 - kappa: 0.9369\n",
      "Iteration 000069: OneCycleScheduler setting learning rate to 5.6085478387566786e-05.\n",
      " 70/343 [=====>........................] - ETA: 3:48 - loss: 0.5829 - acc: 0.7732 - kappa: 0.9324\n",
      "Iteration 000070: OneCycleScheduler setting learning rate to 5.631860126274891e-05.\n",
      " 71/343 [=====>........................] - ETA: 3:47 - loss: 0.5825 - acc: 0.7746 - kappa: 0.9316\n",
      "Iteration 000071: OneCycleScheduler setting learning rate to 5.6551724137931037e-05.\n",
      " 72/343 [=====>........................] - ETA: 3:47 - loss: 0.5787 - acc: 0.7743 - kappa: 0.9315\n",
      "Iteration 000072: OneCycleScheduler setting learning rate to 5.678484701311316e-05.\n",
      " 73/343 [=====>........................] - ETA: 3:48 - loss: 0.5756 - acc: 0.7757 - kappa: 0.9324\n",
      "Iteration 000073: OneCycleScheduler setting learning rate to 5.7017969888295294e-05.\n",
      " 74/343 [=====>........................] - ETA: 3:48 - loss: 0.5780 - acc: 0.7753 - kappa: 0.9329\n",
      "Iteration 000074: OneCycleScheduler setting learning rate to 5.7251092763477426e-05.\n",
      " 75/343 [=====>........................] - ETA: 3:49 - loss: 0.5804 - acc: 0.7750 - kappa: 0.9328\n",
      "Iteration 000075: OneCycleScheduler setting learning rate to 5.748421563865955e-05.\n",
      " 76/343 [=====>........................] - ETA: 3:51 - loss: 0.5792 - acc: 0.7747 - kappa: 0.9328\n",
      "Iteration 000076: OneCycleScheduler setting learning rate to 5.7717338513841676e-05.\n",
      " 77/343 [=====>........................] - ETA: 3:51 - loss: 0.5751 - acc: 0.7776 - kappa: 0.9336\n",
      "Iteration 000077: OneCycleScheduler setting learning rate to 5.79504613890238e-05.\n",
      " 78/343 [=====>........................] - ETA: 3:50 - loss: 0.5732 - acc: 0.7788 - kappa: 0.9341\n",
      "Iteration 000078: OneCycleScheduler setting learning rate to 5.818358426420593e-05.\n",
      " 79/343 [=====>........................] - ETA: 3:49 - loss: 0.5674 - acc: 0.7816 - kappa: 0.9349\n",
      "Iteration 000079: OneCycleScheduler setting learning rate to 5.841670713938806e-05.\n",
      " 80/343 [=====>........................] - ETA: 3:48 - loss: 0.5675 - acc: 0.7828 - kappa: 0.9354\n",
      "Iteration 000080: OneCycleScheduler setting learning rate to 5.8649830014570184e-05.\n",
      " 81/343 [======>.......................] - ETA: 3:48 - loss: 0.5635 - acc: 0.7840 - kappa: 0.9358\n",
      "Iteration 000081: OneCycleScheduler setting learning rate to 5.8882952889752316e-05.\n",
      " 82/343 [======>.......................] - ETA: 3:48 - loss: 0.5692 - acc: 0.7805 - kappa: 0.9319\n",
      "Iteration 000082: OneCycleScheduler setting learning rate to 5.911607576493444e-05.\n",
      " 83/343 [======>.......................] - ETA: 3:47 - loss: 0.5642 - acc: 0.7831 - kappa: 0.9327\n",
      "Iteration 000083: OneCycleScheduler setting learning rate to 5.9349198640116566e-05.\n",
      " 84/343 [======>.......................] - ETA: 3:48 - loss: 0.5675 - acc: 0.7812 - kappa: 0.9327\n",
      "Iteration 000084: OneCycleScheduler setting learning rate to 5.958232151529869e-05.\n",
      " 85/343 [======>.......................] - ETA: 3:48 - loss: 0.5691 - acc: 0.7794 - kappa: 0.9320\n",
      "Iteration 000085: OneCycleScheduler setting learning rate to 5.981544439048082e-05.\n",
      " 86/343 [======>.......................] - ETA: 3:47 - loss: 0.5698 - acc: 0.7776 - kappa: 0.9320\n",
      "Iteration 000086: OneCycleScheduler setting learning rate to 6.004856726566295e-05.\n",
      " 87/343 [======>.......................] - ETA: 3:45 - loss: 0.5810 - acc: 0.7773 - kappa: 0.9324\n",
      "Iteration 000087: OneCycleScheduler setting learning rate to 6.0281690140845074e-05.\n",
      " 88/343 [======>.......................] - ETA: 3:45 - loss: 0.5813 - acc: 0.7784 - kappa: 0.9328\n",
      "Iteration 000088: OneCycleScheduler setting learning rate to 6.0514813016027206e-05.\n",
      " 89/343 [======>.......................] - ETA: 3:45 - loss: 0.5825 - acc: 0.7781 - kappa: 0.9328\n",
      "Iteration 000089: OneCycleScheduler setting learning rate to 6.074793589120933e-05.\n",
      " 90/343 [======>.......................] - ETA: 3:44 - loss: 0.5885 - acc: 0.7764 - kappa: 0.9313\n",
      "Iteration 000090: OneCycleScheduler setting learning rate to 6.0981058766391456e-05.\n",
      " 91/343 [======>.......................] - ETA: 3:43 - loss: 0.5856 - acc: 0.7775 - kappa: 0.9320\n",
      "Iteration 000091: OneCycleScheduler setting learning rate to 6.121418164157358e-05.\n",
      " 92/343 [=======>......................] - ETA: 3:42 - loss: 0.5851 - acc: 0.7745 - kappa: 0.9306\n",
      "Iteration 000092: OneCycleScheduler setting learning rate to 6.144730451675571e-05.\n",
      " 93/343 [=======>......................] - ETA: 3:42 - loss: 0.5848 - acc: 0.7728 - kappa: 0.9306\n",
      "Iteration 000093: OneCycleScheduler setting learning rate to 6.168042739193783e-05.\n",
      " 94/343 [=======>......................] - ETA: 3:42 - loss: 0.5845 - acc: 0.7713 - kappa: 0.9306\n",
      "Iteration 000094: OneCycleScheduler setting learning rate to 6.191355026711997e-05.\n",
      " 95/343 [=======>......................] - ETA: 3:41 - loss: 0.5843 - acc: 0.7711 - kappa: 0.9306\n",
      "Iteration 000095: OneCycleScheduler setting learning rate to 6.21466731423021e-05.\n",
      " 96/343 [=======>......................] - ETA: 3:40 - loss: 0.5799 - acc: 0.7734 - kappa: 0.9313\n",
      "Iteration 000096: OneCycleScheduler setting learning rate to 6.237979601748422e-05.\n",
      " 97/343 [=======>......................] - ETA: 3:39 - loss: 0.5768 - acc: 0.7745 - kappa: 0.9319\n",
      "Iteration 000097: OneCycleScheduler setting learning rate to 6.261291889266635e-05.\n",
      " 98/343 [=======>......................] - ETA: 3:38 - loss: 0.5811 - acc: 0.7742 - kappa: 0.9323\n",
      "Iteration 000098: OneCycleScheduler setting learning rate to 6.284604176784847e-05.\n",
      " 99/343 [=======>......................] - ETA: 3:37 - loss: 0.5823 - acc: 0.7740 - kappa: 0.9323\n",
      "Iteration 000099: OneCycleScheduler setting learning rate to 6.307916464303061e-05.\n",
      "100/343 [=======>......................] - ETA: 3:37 - loss: 0.5900 - acc: 0.7725 - kappa: 0.9310\n",
      "Iteration 000100: OneCycleScheduler setting learning rate to 6.331228751821274e-05.\n",
      "101/343 [=======>......................] - ETA: 3:36 - loss: 0.5862 - acc: 0.7735 - kappa: 0.9316\n",
      "Iteration 000101: OneCycleScheduler setting learning rate to 6.354541039339486e-05.\n",
      "102/343 [=======>......................] - ETA: 3:36 - loss: 0.5878 - acc: 0.7745 - kappa: 0.9320\n",
      "Iteration 000102: OneCycleScheduler setting learning rate to 6.377853326857699e-05.\n",
      "103/343 [========>.....................] - ETA: 3:36 - loss: 0.5846 - acc: 0.7755 - kappa: 0.9326\n",
      "Iteration 000103: OneCycleScheduler setting learning rate to 6.401165614375911e-05.\n",
      "104/343 [========>.....................] - ETA: 3:35 - loss: 0.5819 - acc: 0.7776 - kappa: 0.9332\n",
      "Iteration 000104: OneCycleScheduler setting learning rate to 6.424477901894124e-05.\n",
      "105/343 [========>.....................] - ETA: 3:34 - loss: 0.5795 - acc: 0.7786 - kappa: 0.9338\n",
      "Iteration 000105: OneCycleScheduler setting learning rate to 6.447790189412336e-05.\n",
      "106/343 [========>.....................] - ETA: 3:33 - loss: 0.5774 - acc: 0.7783 - kappa: 0.9332\n",
      "Iteration 000106: OneCycleScheduler setting learning rate to 6.471102476930549e-05.\n",
      "107/343 [========>.....................] - ETA: 3:31 - loss: 0.5749 - acc: 0.7780 - kappa: 0.9336\n",
      "Iteration 000107: OneCycleScheduler setting learning rate to 6.494414764448761e-05.\n",
      "108/343 [========>.....................] - ETA: 3:30 - loss: 0.5720 - acc: 0.7789 - kappa: 0.9339\n",
      "Iteration 000108: OneCycleScheduler setting learning rate to 6.517727051966975e-05.\n",
      "109/343 [========>.....................] - ETA: 3:30 - loss: 0.5721 - acc: 0.7787 - kappa: 0.9342\n",
      "Iteration 000109: OneCycleScheduler setting learning rate to 6.541039339485188e-05.\n",
      "110/343 [========>.....................] - ETA: 3:30 - loss: 0.5745 - acc: 0.7773 - kappa: 0.9342\n",
      "Iteration 000110: OneCycleScheduler setting learning rate to 6.5643516270034e-05.\n",
      "111/343 [========>.....................] - ETA: 3:29 - loss: 0.5711 - acc: 0.7793 - kappa: 0.9348\n",
      "Iteration 000111: OneCycleScheduler setting learning rate to 6.587663914521613e-05.\n",
      "112/343 [========>.....................] - ETA: 3:28 - loss: 0.5691 - acc: 0.7801 - kappa: 0.9353\n",
      "Iteration 000112: OneCycleScheduler setting learning rate to 6.610976202039825e-05.\n",
      "113/343 [========>.....................] - ETA: 3:27 - loss: 0.5706 - acc: 0.7810 - kappa: 0.9358\n",
      "Iteration 000113: OneCycleScheduler setting learning rate to 6.634288489558039e-05.\n",
      "114/343 [========>.....................] - ETA: 3:27 - loss: 0.5729 - acc: 0.7807 - kappa: 0.9361\n",
      "Iteration 000114: OneCycleScheduler setting learning rate to 6.657600777076252e-05.\n",
      "115/343 [=========>....................] - ETA: 3:26 - loss: 0.5740 - acc: 0.7783 - kappa: 0.9349\n",
      "Iteration 000115: OneCycleScheduler setting learning rate to 6.680913064594464e-05.\n",
      "116/343 [=========>....................] - ETA: 3:26 - loss: 0.5720 - acc: 0.7791 - kappa: 0.9354\n",
      "Iteration 000116: OneCycleScheduler setting learning rate to 6.704225352112677e-05.\n",
      "117/343 [=========>....................] - ETA: 3:25 - loss: 0.5774 - acc: 0.7767 - kappa: 0.9306\n",
      "Iteration 000117: OneCycleScheduler setting learning rate to 6.727537639630889e-05.\n",
      "118/343 [=========>....................] - ETA: 3:24 - loss: 0.5749 - acc: 0.7775 - kappa: 0.9309\n",
      "Iteration 000118: OneCycleScheduler setting learning rate to 6.750849927149102e-05.\n",
      "119/343 [=========>....................] - ETA: 3:23 - loss: 0.5747 - acc: 0.7784 - kappa: 0.9312\n",
      "Iteration 000119: OneCycleScheduler setting learning rate to 6.774162214667314e-05.\n",
      "120/343 [=========>....................] - ETA: 3:22 - loss: 0.5748 - acc: 0.7792 - kappa: 0.9317\n",
      "Iteration 000120: OneCycleScheduler setting learning rate to 6.797474502185527e-05.\n",
      "121/343 [=========>....................] - ETA: 3:22 - loss: 0.5807 - acc: 0.7779 - kappa: 0.9299\n",
      "Iteration 000121: OneCycleScheduler setting learning rate to 6.82078678970374e-05.\n",
      "122/343 [=========>....................] - ETA: 3:21 - loss: 0.5794 - acc: 0.7777 - kappa: 0.9299\n",
      "Iteration 000122: OneCycleScheduler setting learning rate to 6.844099077221953e-05.\n",
      "123/343 [=========>....................] - ETA: 3:20 - loss: 0.5773 - acc: 0.7785 - kappa: 0.9303\n",
      "Iteration 000123: OneCycleScheduler setting learning rate to 6.867411364740166e-05.\n",
      "124/343 [=========>....................] - ETA: 3:19 - loss: 0.5758 - acc: 0.7792 - kappa: 0.9308\n",
      "Iteration 000124: OneCycleScheduler setting learning rate to 6.890723652258378e-05.\n",
      "125/343 [=========>....................] - ETA: 3:18 - loss: 0.5765 - acc: 0.7800 - kappa: 0.9311\n",
      "Iteration 000125: OneCycleScheduler setting learning rate to 6.914035939776591e-05.\n",
      "126/343 [==========>...................] - ETA: 3:17 - loss: 0.5748 - acc: 0.7817 - kappa: 0.9316\n",
      "Iteration 000126: OneCycleScheduler setting learning rate to 6.937348227294805e-05.\n",
      "127/343 [==========>...................] - ETA: 3:16 - loss: 0.5732 - acc: 0.7815 - kappa: 0.9319\n",
      "Iteration 000127: OneCycleScheduler setting learning rate to 6.960660514813017e-05.\n",
      "128/343 [==========>...................] - ETA: 3:16 - loss: 0.5730 - acc: 0.7812 - kappa: 0.9319\n",
      "Iteration 000128: OneCycleScheduler setting learning rate to 6.98397280233123e-05.\n",
      "129/343 [==========>...................] - ETA: 3:15 - loss: 0.5716 - acc: 0.7810 - kappa: 0.9322\n",
      "Iteration 000129: OneCycleScheduler setting learning rate to 7.007285089849442e-05.\n",
      "130/343 [==========>...................] - ETA: 3:14 - loss: 0.5707 - acc: 0.7808 - kappa: 0.9322\n",
      "Iteration 000130: OneCycleScheduler setting learning rate to 7.030597377367655e-05.\n",
      "131/343 [==========>...................] - ETA: 3:13 - loss: 0.5707 - acc: 0.7805 - kappa: 0.9324\n",
      "Iteration 000131: OneCycleScheduler setting learning rate to 7.053909664885867e-05.\n",
      "132/343 [==========>...................] - ETA: 3:13 - loss: 0.5687 - acc: 0.7812 - kappa: 0.9329\n",
      "Iteration 000132: OneCycleScheduler setting learning rate to 7.07722195240408e-05.\n",
      "133/343 [==========>...................] - ETA: 3:11 - loss: 0.5686 - acc: 0.7810 - kappa: 0.9332\n",
      "Iteration 000133: OneCycleScheduler setting learning rate to 7.100534239922292e-05.\n",
      "134/343 [==========>...................] - ETA: 3:11 - loss: 0.5697 - acc: 0.7799 - kappa: 0.9327\n",
      "Iteration 000134: OneCycleScheduler setting learning rate to 7.123846527440505e-05.\n",
      "135/343 [==========>...................] - ETA: 3:10 - loss: 0.5740 - acc: 0.7778 - kappa: 0.9318\n",
      "Iteration 000135: OneCycleScheduler setting learning rate to 7.147158814958719e-05.\n",
      "136/343 [==========>...................] - ETA: 3:09 - loss: 0.5766 - acc: 0.7767 - kappa: 0.9314\n",
      "Iteration 000136: OneCycleScheduler setting learning rate to 7.170471102476931e-05.\n",
      "137/343 [==========>...................] - ETA: 3:08 - loss: 0.5758 - acc: 0.7765 - kappa: 0.9309\n",
      "Iteration 000137: OneCycleScheduler setting learning rate to 7.193783389995144e-05.\n",
      "138/343 [===========>..................] - ETA: 3:07 - loss: 0.5738 - acc: 0.7781 - kappa: 0.9314\n",
      "Iteration 000138: OneCycleScheduler setting learning rate to 7.217095677513358e-05.\n",
      "139/343 [===========>..................] - ETA: 3:06 - loss: 0.5714 - acc: 0.7788 - kappa: 0.9317\n",
      "Iteration 000139: OneCycleScheduler setting learning rate to 7.24040796503157e-05.\n",
      "140/343 [===========>..................] - ETA: 3:05 - loss: 0.5678 - acc: 0.7804 - kappa: 0.9322\n",
      "Iteration 000140: OneCycleScheduler setting learning rate to 7.263720252549783e-05.\n",
      "141/343 [===========>..................] - ETA: 3:04 - loss: 0.5644 - acc: 0.7819 - kappa: 0.9327\n",
      "Iteration 000141: OneCycleScheduler setting learning rate to 7.287032540067995e-05.\n",
      "142/343 [===========>..................] - ETA: 3:03 - loss: 0.5628 - acc: 0.7826 - kappa: 0.9329\n",
      "Iteration 000142: OneCycleScheduler setting learning rate to 7.310344827586208e-05.\n",
      "143/343 [===========>..................] - ETA: 3:02 - loss: 0.5620 - acc: 0.7832 - kappa: 0.9332\n",
      "Iteration 000143: OneCycleScheduler setting learning rate to 7.33365711510442e-05.\n",
      "144/343 [===========>..................] - ETA: 3:02 - loss: 0.5610 - acc: 0.7830 - kappa: 0.9334\n",
      "Iteration 000144: OneCycleScheduler setting learning rate to 7.356969402622633e-05.\n",
      "145/343 [===========>..................] - ETA: 3:00 - loss: 0.5588 - acc: 0.7845 - kappa: 0.9339\n",
      "Iteration 000145: OneCycleScheduler setting learning rate to 7.380281690140845e-05.\n",
      "146/343 [===========>..................] - ETA: 3:00 - loss: 0.5580 - acc: 0.7842 - kappa: 0.9341\n",
      "Iteration 000146: OneCycleScheduler setting learning rate to 7.403593977659058e-05.\n",
      "147/343 [===========>..................] - ETA: 2:59 - loss: 0.5599 - acc: 0.7832 - kappa: 0.9337\n",
      "Iteration 000147: OneCycleScheduler setting learning rate to 7.42690626517727e-05.\n",
      "148/343 [===========>..................] - ETA: 2:58 - loss: 0.5612 - acc: 0.7821 - kappa: 0.9333\n",
      "Iteration 000148: OneCycleScheduler setting learning rate to 7.450218552695484e-05.\n",
      "149/343 [============>.................] - ETA: 2:57 - loss: 0.5583 - acc: 0.7836 - kappa: 0.9338\n",
      "Iteration 000149: OneCycleScheduler setting learning rate to 7.473530840213697e-05.\n",
      "150/343 [============>.................] - ETA: 2:57 - loss: 0.5584 - acc: 0.7842 - kappa: 0.9342\n",
      "Iteration 000150: OneCycleScheduler setting learning rate to 7.496843127731909e-05.\n",
      "151/343 [============>.................] - ETA: 2:56 - loss: 0.5585 - acc: 0.7839 - kappa: 0.9341\n",
      "Iteration 000151: OneCycleScheduler setting learning rate to 7.520155415250122e-05.\n",
      "152/343 [============>.................] - ETA: 2:56 - loss: 0.5615 - acc: 0.7821 - kappa: 0.9327\n",
      "Iteration 000152: OneCycleScheduler setting learning rate to 7.543467702768336e-05.\n",
      "153/343 [============>.................] - ETA: 2:56 - loss: 0.5651 - acc: 0.7810 - kappa: 0.9323\n",
      "Iteration 000153: OneCycleScheduler setting learning rate to 7.566779990286548e-05.\n",
      "154/343 [============>.................] - ETA: 2:55 - loss: 0.5637 - acc: 0.7817 - kappa: 0.9327\n",
      "Iteration 000154: OneCycleScheduler setting learning rate to 7.59009227780476e-05.\n",
      "155/343 [============>.................] - ETA: 2:54 - loss: 0.5632 - acc: 0.7823 - kappa: 0.9327\n",
      "Iteration 000155: OneCycleScheduler setting learning rate to 7.613404565322973e-05.\n",
      "156/343 [============>.................] - ETA: 2:53 - loss: 0.5617 - acc: 0.7829 - kappa: 0.9331\n",
      "Iteration 000156: OneCycleScheduler setting learning rate to 7.636716852841186e-05.\n",
      "157/343 [============>.................] - ETA: 2:52 - loss: 0.5599 - acc: 0.7826 - kappa: 0.9333\n",
      "Iteration 000157: OneCycleScheduler setting learning rate to 7.660029140359398e-05.\n",
      "158/343 [============>.................] - ETA: 2:52 - loss: 0.5600 - acc: 0.7832 - kappa: 0.9335\n",
      "Iteration 000158: OneCycleScheduler setting learning rate to 7.683341427877611e-05.\n",
      "159/343 [============>.................] - ETA: 2:51 - loss: 0.5600 - acc: 0.7830 - kappa: 0.9338\n",
      "Iteration 000159: OneCycleScheduler setting learning rate to 7.706653715395823e-05.\n",
      "160/343 [============>.................] - ETA: 2:50 - loss: 0.5605 - acc: 0.7820 - kappa: 0.9337\n",
      "Iteration 000160: OneCycleScheduler setting learning rate to 7.729966002914036e-05.\n",
      "161/343 [=============>................] - ETA: 2:49 - loss: 0.5621 - acc: 0.7811 - kappa: 0.9337\n",
      "Iteration 000161: OneCycleScheduler setting learning rate to 7.753278290432248e-05.\n",
      "162/343 [=============>................] - ETA: 2:48 - loss: 0.5630 - acc: 0.7816 - kappa: 0.9339\n",
      "Iteration 000162: OneCycleScheduler setting learning rate to 7.776590577950462e-05.\n",
      "163/343 [=============>................] - ETA: 2:47 - loss: 0.5615 - acc: 0.7822 - kappa: 0.9343\n",
      "Iteration 000163: OneCycleScheduler setting learning rate to 7.799902865468675e-05.\n",
      "164/343 [=============>................] - ETA: 2:47 - loss: 0.5638 - acc: 0.7805 - kappa: 0.9339\n",
      "Iteration 000164: OneCycleScheduler setting learning rate to 7.823215152986887e-05.\n",
      "165/343 [=============>................] - ETA: 2:46 - loss: 0.5662 - acc: 0.7803 - kappa: 0.9341\n",
      "Iteration 000165: OneCycleScheduler setting learning rate to 7.846527440505101e-05.\n",
      "166/343 [=============>................] - ETA: 2:45 - loss: 0.5656 - acc: 0.7809 - kappa: 0.9345\n",
      "Iteration 000166: OneCycleScheduler setting learning rate to 7.869839728023314e-05.\n",
      "167/343 [=============>................] - ETA: 2:44 - loss: 0.5643 - acc: 0.7814 - kappa: 0.9348\n",
      "Iteration 000167: OneCycleScheduler setting learning rate to 7.893152015541526e-05.\n",
      "168/343 [=============>................] - ETA: 2:43 - loss: 0.5625 - acc: 0.7820 - kappa: 0.9352\n",
      "Iteration 000168: OneCycleScheduler setting learning rate to 7.916464303059739e-05.\n",
      "169/343 [=============>................] - ETA: 2:42 - loss: 0.5627 - acc: 0.7825 - kappa: 0.9354\n",
      "Iteration 000169: OneCycleScheduler setting learning rate to 7.939776590577951e-05.\n",
      "170/343 [=============>................] - ETA: 2:40 - loss: 0.5641 - acc: 0.7816 - kappa: 0.9341\n",
      "Iteration 000170: OneCycleScheduler setting learning rate to 7.963088878096164e-05.\n",
      "171/343 [=============>................] - ETA: 2:39 - loss: 0.5637 - acc: 0.7822 - kappa: 0.9343\n",
      "Iteration 000171: OneCycleScheduler setting learning rate to 7.986401165614376e-05.\n",
      "172/343 [==============>...............] - ETA: 2:39 - loss: 0.5626 - acc: 0.7827 - kappa: 0.9346\n",
      "Iteration 000172: OneCycleScheduler setting learning rate to 8.009713453132589e-05.\n",
      "173/343 [==============>...............] - ETA: 2:38 - loss: 0.5640 - acc: 0.7818 - kappa: 0.9343\n",
      "Iteration 000173: OneCycleScheduler setting learning rate to 8.033025740650801e-05.\n",
      "174/343 [==============>...............] - ETA: 2:37 - loss: 0.5624 - acc: 0.7816 - kappa: 0.9345\n",
      "Iteration 000174: OneCycleScheduler setting learning rate to 8.056338028169014e-05.\n",
      "175/343 [==============>...............] - ETA: 2:36 - loss: 0.5615 - acc: 0.7821 - kappa: 0.9347\n",
      "Iteration 000175: OneCycleScheduler setting learning rate to 8.079650315687228e-05.\n",
      "176/343 [==============>...............] - ETA: 2:35 - loss: 0.5600 - acc: 0.7834 - kappa: 0.9351\n",
      "Iteration 000176: OneCycleScheduler setting learning rate to 8.10296260320544e-05.\n",
      "177/343 [==============>...............] - ETA: 2:34 - loss: 0.5584 - acc: 0.7839 - kappa: 0.9354\n",
      "Iteration 000177: OneCycleScheduler setting learning rate to 8.126274890723653e-05.\n",
      "178/343 [==============>...............] - ETA: 2:33 - loss: 0.5575 - acc: 0.7844 - kappa: 0.9357\n",
      "Iteration 000178: OneCycleScheduler setting learning rate to 8.149587178241867e-05.\n",
      "179/343 [==============>...............] - ETA: 2:32 - loss: 0.5563 - acc: 0.7849 - kappa: 0.9360\n",
      "Iteration 000179: OneCycleScheduler setting learning rate to 8.172899465760079e-05.\n",
      "180/343 [==============>...............] - ETA: 2:31 - loss: 0.5546 - acc: 0.7854 - kappa: 0.9363\n",
      "Iteration 000180: OneCycleScheduler setting learning rate to 8.196211753278292e-05.\n",
      "181/343 [==============>...............] - ETA: 2:30 - loss: 0.5525 - acc: 0.7866 - kappa: 0.9367\n",
      "Iteration 000181: OneCycleScheduler setting learning rate to 8.219524040796504e-05.\n",
      "182/343 [==============>...............] - ETA: 2:29 - loss: 0.5512 - acc: 0.7871 - kappa: 0.9370\n",
      "Iteration 000182: OneCycleScheduler setting learning rate to 8.242836328314717e-05.\n",
      "183/343 [===============>..............] - ETA: 2:28 - loss: 0.5515 - acc: 0.7869 - kappa: 0.9372\n",
      "Iteration 000183: OneCycleScheduler setting learning rate to 8.266148615832929e-05.\n",
      "184/343 [===============>..............] - ETA: 2:28 - loss: 0.5531 - acc: 0.7867 - kappa: 0.9371\n",
      "Iteration 000184: OneCycleScheduler setting learning rate to 8.289460903351142e-05.\n",
      "185/343 [===============>..............] - ETA: 2:26 - loss: 0.5540 - acc: 0.7858 - kappa: 0.9368\n",
      "Iteration 000185: OneCycleScheduler setting learning rate to 8.312773190869354e-05.\n",
      "186/343 [===============>..............] - ETA: 2:26 - loss: 0.5571 - acc: 0.7849 - kappa: 0.9361\n",
      "Iteration 000186: OneCycleScheduler setting learning rate to 8.336085478387567e-05.\n",
      "187/343 [===============>..............] - ETA: 2:25 - loss: 0.5557 - acc: 0.7854 - kappa: 0.9364\n",
      "Iteration 000187: OneCycleScheduler setting learning rate to 8.359397765905779e-05.\n",
      "188/343 [===============>..............] - ETA: 2:24 - loss: 0.5585 - acc: 0.7846 - kappa: 0.9352\n",
      "Iteration 000188: OneCycleScheduler setting learning rate to 8.382710053423993e-05.\n",
      "189/343 [===============>..............] - ETA: 2:23 - loss: 0.5582 - acc: 0.7851 - kappa: 0.9354\n",
      "Iteration 000189: OneCycleScheduler setting learning rate to 8.406022340942206e-05.\n",
      "190/343 [===============>..............] - ETA: 2:22 - loss: 0.5611 - acc: 0.7836 - kappa: 0.9347\n",
      "Iteration 000190: OneCycleScheduler setting learning rate to 8.429334628460418e-05.\n",
      "191/343 [===============>..............] - ETA: 2:21 - loss: 0.5588 - acc: 0.7847 - kappa: 0.9350\n",
      "Iteration 000191: OneCycleScheduler setting learning rate to 8.452646915978631e-05.\n",
      "192/343 [===============>..............] - ETA: 2:20 - loss: 0.5600 - acc: 0.7839 - kappa: 0.9350\n",
      "Iteration 000192: OneCycleScheduler setting learning rate to 8.475959203496845e-05.\n",
      "193/343 [===============>..............] - ETA: 2:19 - loss: 0.5588 - acc: 0.7850 - kappa: 0.9354\n",
      "Iteration 000193: OneCycleScheduler setting learning rate to 8.499271491015057e-05.\n",
      "194/343 [===============>..............] - ETA: 2:18 - loss: 0.5576 - acc: 0.7861 - kappa: 0.9357\n",
      "Iteration 000194: OneCycleScheduler setting learning rate to 8.52258377853327e-05.\n",
      "195/343 [================>.............] - ETA: 2:17 - loss: 0.5598 - acc: 0.7846 - kappa: 0.9354\n",
      "Iteration 000195: OneCycleScheduler setting learning rate to 8.545896066051482e-05.\n",
      "196/343 [================>.............] - ETA: 2:16 - loss: 0.5622 - acc: 0.7832 - kappa: 0.9351\n",
      "Iteration 000196: OneCycleScheduler setting learning rate to 8.569208353569695e-05.\n",
      "197/343 [================>.............] - ETA: 2:15 - loss: 0.5612 - acc: 0.7836 - kappa: 0.9354\n",
      "Iteration 000197: OneCycleScheduler setting learning rate to 8.592520641087907e-05.\n",
      "198/343 [================>.............] - ETA: 2:14 - loss: 0.5595 - acc: 0.7841 - kappa: 0.9356\n",
      "Iteration 000198: OneCycleScheduler setting learning rate to 8.61583292860612e-05.\n",
      "199/343 [================>.............] - ETA: 2:13 - loss: 0.5584 - acc: 0.7839 - kappa: 0.9358\n",
      "Iteration 000199: OneCycleScheduler setting learning rate to 8.639145216124332e-05.\n",
      "200/343 [================>.............] - ETA: 2:12 - loss: 0.5585 - acc: 0.7837 - kappa: 0.9358\n",
      "Iteration 000200: OneCycleScheduler setting learning rate to 8.662457503642545e-05.\n",
      "201/343 [================>.............] - ETA: 2:11 - loss: 0.5590 - acc: 0.7836 - kappa: 0.9359\n",
      "Iteration 000201: OneCycleScheduler setting learning rate to 8.685769791160757e-05.\n",
      "202/343 [================>.............] - ETA: 2:10 - loss: 0.5599 - acc: 0.7834 - kappa: 0.9359\n",
      "Iteration 000202: OneCycleScheduler setting learning rate to 8.709082078678971e-05.\n",
      "203/343 [================>.............] - ETA: 2:10 - loss: 0.5602 - acc: 0.7833 - kappa: 0.9361\n",
      "Iteration 000203: OneCycleScheduler setting learning rate to 8.732394366197184e-05.\n",
      "204/343 [================>.............] - ETA: 2:09 - loss: 0.5610 - acc: 0.7837 - kappa: 0.9362\n",
      "Iteration 000204: OneCycleScheduler setting learning rate to 8.755706653715396e-05.\n",
      "205/343 [================>.............] - ETA: 2:08 - loss: 0.5595 - acc: 0.7841 - kappa: 0.9365\n",
      "Iteration 000205: OneCycleScheduler setting learning rate to 8.77901894123361e-05.\n",
      "206/343 [=================>............] - ETA: 2:07 - loss: 0.5604 - acc: 0.7834 - kappa: 0.9359\n",
      "Iteration 000206: OneCycleScheduler setting learning rate to 8.802331228751823e-05.\n",
      "207/343 [=================>............] - ETA: 2:06 - loss: 0.5604 - acc: 0.7838 - kappa: 0.9360\n",
      "Iteration 000207: OneCycleScheduler setting learning rate to 8.825643516270035e-05.\n",
      "208/343 [=================>............] - ETA: 2:05 - loss: 0.5587 - acc: 0.7843 - kappa: 0.9363\n",
      "Iteration 000208: OneCycleScheduler setting learning rate to 8.848955803788248e-05.\n",
      "209/343 [=================>............] - ETA: 2:04 - loss: 0.5579 - acc: 0.7847 - kappa: 0.9366\n",
      "Iteration 000209: OneCycleScheduler setting learning rate to 8.87226809130646e-05.\n",
      "210/343 [=================>............] - ETA: 2:03 - loss: 0.5591 - acc: 0.7845 - kappa: 0.9367\n",
      "Iteration 000210: OneCycleScheduler setting learning rate to 8.895580378824673e-05.\n",
      "211/343 [=================>............] - ETA: 2:02 - loss: 0.5617 - acc: 0.7850 - kappa: 0.9370\n",
      "Iteration 000211: OneCycleScheduler setting learning rate to 8.918892666342885e-05.\n",
      "212/343 [=================>............] - ETA: 2:01 - loss: 0.5609 - acc: 0.7854 - kappa: 0.9371\n",
      "Iteration 000212: OneCycleScheduler setting learning rate to 8.942204953861098e-05.\n",
      "213/343 [=================>............] - ETA: 2:00 - loss: 0.5614 - acc: 0.7852 - kappa: 0.9371\n",
      "Iteration 000213: OneCycleScheduler setting learning rate to 8.96551724137931e-05.\n",
      "214/343 [=================>............] - ETA: 2:00 - loss: 0.5613 - acc: 0.7856 - kappa: 0.9372\n",
      "Iteration 000214: OneCycleScheduler setting learning rate to 8.988829528897523e-05.\n",
      "215/343 [=================>............] - ETA: 1:59 - loss: 0.5625 - acc: 0.7849 - kappa: 0.9366\n",
      "Iteration 000215: OneCycleScheduler setting learning rate to 9.012141816415737e-05.\n",
      "216/343 [=================>............] - ETA: 1:58 - loss: 0.5620 - acc: 0.7853 - kappa: 0.9369\n",
      "Iteration 000216: OneCycleScheduler setting learning rate to 9.035454103933949e-05.\n",
      "217/343 [=================>............] - ETA: 1:57 - loss: 0.5609 - acc: 0.7863 - kappa: 0.9372\n",
      "Iteration 000217: OneCycleScheduler setting learning rate to 9.058766391452162e-05.\n",
      "218/343 [==================>...........] - ETA: 1:56 - loss: 0.5606 - acc: 0.7867 - kappa: 0.9374\n",
      "Iteration 000218: OneCycleScheduler setting learning rate to 9.082078678970376e-05.\n",
      "219/343 [==================>...........] - ETA: 1:55 - loss: 0.5616 - acc: 0.7865 - kappa: 0.9374\n",
      "Iteration 000219: OneCycleScheduler setting learning rate to 9.105390966488588e-05.\n",
      "220/343 [==================>...........] - ETA: 1:54 - loss: 0.5612 - acc: 0.7869 - kappa: 0.9376\n",
      "Iteration 000220: OneCycleScheduler setting learning rate to 9.1287032540068e-05.\n",
      "221/343 [==================>...........] - ETA: 1:53 - loss: 0.5611 - acc: 0.7868 - kappa: 0.9376\n",
      "Iteration 000221: OneCycleScheduler setting learning rate to 9.152015541525013e-05.\n",
      "222/343 [==================>...........] - ETA: 1:52 - loss: 0.5621 - acc: 0.7855 - kappa: 0.9373\n",
      "Iteration 000222: OneCycleScheduler setting learning rate to 9.175327829043226e-05.\n",
      "223/343 [==================>...........] - ETA: 1:52 - loss: 0.5652 - acc: 0.7842 - kappa: 0.9367\n",
      "Iteration 000223: OneCycleScheduler setting learning rate to 9.198640116561438e-05.\n",
      "224/343 [==================>...........] - ETA: 1:51 - loss: 0.5633 - acc: 0.7852 - kappa: 0.9370\n",
      "Iteration 000224: OneCycleScheduler setting learning rate to 9.221952404079651e-05.\n",
      "225/343 [==================>...........] - ETA: 1:50 - loss: 0.5618 - acc: 0.7861 - kappa: 0.9373\n",
      "Iteration 000225: OneCycleScheduler setting learning rate to 9.245264691597863e-05.\n",
      "226/343 [==================>...........] - ETA: 1:49 - loss: 0.5631 - acc: 0.7860 - kappa: 0.9373\n",
      "Iteration 000226: OneCycleScheduler setting learning rate to 9.268576979116076e-05.\n",
      "227/343 [==================>...........] - ETA: 1:48 - loss: 0.5625 - acc: 0.7863 - kappa: 0.9375\n",
      "Iteration 000227: OneCycleScheduler setting learning rate to 9.291889266634288e-05.\n",
      "228/343 [==================>...........] - ETA: 1:47 - loss: 0.5624 - acc: 0.7867 - kappa: 0.9377\n",
      "Iteration 000228: OneCycleScheduler setting learning rate to 9.315201554152502e-05.\n",
      "229/343 [===================>..........] - ETA: 1:46 - loss: 0.5623 - acc: 0.7871 - kappa: 0.9379\n",
      "Iteration 000229: OneCycleScheduler setting learning rate to 9.338513841670715e-05.\n",
      "230/343 [===================>..........] - ETA: 1:45 - loss: 0.5634 - acc: 0.7864 - kappa: 0.9378\n",
      "Iteration 000230: OneCycleScheduler setting learning rate to 9.361826129188927e-05.\n",
      "231/343 [===================>..........] - ETA: 1:44 - loss: 0.5661 - acc: 0.7846 - kappa: 0.9369\n",
      "Iteration 000231: OneCycleScheduler setting learning rate to 9.38513841670714e-05.\n",
      "232/343 [===================>..........] - ETA: 1:43 - loss: 0.5652 - acc: 0.7856 - kappa: 0.9372\n",
      "Iteration 000232: OneCycleScheduler setting learning rate to 9.408450704225354e-05.\n",
      "233/343 [===================>..........] - ETA: 1:42 - loss: 0.5634 - acc: 0.7865 - kappa: 0.9374\n",
      "Iteration 000233: OneCycleScheduler setting learning rate to 9.431762991743566e-05.\n",
      "234/343 [===================>..........] - ETA: 1:41 - loss: 0.5638 - acc: 0.7863 - kappa: 0.9376\n",
      "Iteration 000234: OneCycleScheduler setting learning rate to 9.455075279261779e-05.\n",
      "235/343 [===================>..........] - ETA: 1:41 - loss: 0.5681 - acc: 0.7851 - kappa: 0.9370\n",
      "Iteration 000235: OneCycleScheduler setting learning rate to 9.478387566779991e-05.\n",
      "236/343 [===================>..........] - ETA: 1:40 - loss: 0.5714 - acc: 0.7839 - kappa: 0.9356\n",
      "Iteration 000236: OneCycleScheduler setting learning rate to 9.501699854298204e-05.\n",
      "237/343 [===================>..........] - ETA: 1:39 - loss: 0.5708 - acc: 0.7838 - kappa: 0.9356\n",
      "Iteration 000237: OneCycleScheduler setting learning rate to 9.525012141816416e-05.\n",
      "238/343 [===================>..........] - ETA: 1:38 - loss: 0.5695 - acc: 0.7847 - kappa: 0.9359\n",
      "Iteration 000238: OneCycleScheduler setting learning rate to 9.548324429334629e-05.\n",
      "239/343 [===================>..........] - ETA: 1:37 - loss: 0.5721 - acc: 0.7840 - kappa: 0.9353\n",
      "Iteration 000239: OneCycleScheduler setting learning rate to 9.571636716852841e-05.\n",
      "240/343 [===================>..........] - ETA: 1:36 - loss: 0.5716 - acc: 0.7844 - kappa: 0.9356\n",
      "Iteration 000240: OneCycleScheduler setting learning rate to 9.594949004371054e-05.\n",
      "241/343 [====================>.........] - ETA: 1:35 - loss: 0.5700 - acc: 0.7853 - kappa: 0.9358\n",
      "Iteration 000241: OneCycleScheduler setting learning rate to 9.618261291889266e-05.\n",
      "242/343 [====================>.........] - ETA: 1:34 - loss: 0.5684 - acc: 0.7862 - kappa: 0.9361\n",
      "Iteration 000242: OneCycleScheduler setting learning rate to 9.64157357940748e-05.\n",
      "243/343 [====================>.........] - ETA: 1:33 - loss: 0.5713 - acc: 0.7855 - kappa: 0.9356\n",
      "Iteration 000243: OneCycleScheduler setting learning rate to 9.664885866925693e-05.\n",
      "244/343 [====================>.........] - ETA: 1:32 - loss: 0.5715 - acc: 0.7848 - kappa: 0.9353\n",
      "Iteration 000244: OneCycleScheduler setting learning rate to 9.688198154443905e-05.\n",
      "245/343 [====================>.........] - ETA: 1:31 - loss: 0.5710 - acc: 0.7852 - kappa: 0.9356\n",
      "Iteration 000245: OneCycleScheduler setting learning rate to 9.711510441962119e-05.\n",
      "246/343 [====================>.........] - ETA: 1:30 - loss: 0.5706 - acc: 0.7856 - kappa: 0.9358\n",
      "Iteration 000246: OneCycleScheduler setting learning rate to 9.734822729480332e-05.\n",
      "247/343 [====================>.........] - ETA: 1:30 - loss: 0.5712 - acc: 0.7849 - kappa: 0.9353\n",
      "Iteration 000247: OneCycleScheduler setting learning rate to 9.758135016998544e-05.\n",
      "248/343 [====================>.........] - ETA: 1:29 - loss: 0.5707 - acc: 0.7853 - kappa: 0.9355\n",
      "Iteration 000248: OneCycleScheduler setting learning rate to 9.781447304516757e-05.\n",
      "249/343 [====================>.........] - ETA: 1:28 - loss: 0.5709 - acc: 0.7851 - kappa: 0.9356\n",
      "Iteration 000249: OneCycleScheduler setting learning rate to 9.804759592034969e-05.\n",
      "250/343 [====================>.........] - ETA: 1:27 - loss: 0.5704 - acc: 0.7850 - kappa: 0.9354\n",
      "Iteration 000250: OneCycleScheduler setting learning rate to 9.828071879553182e-05.\n",
      "251/343 [====================>.........] - ETA: 1:26 - loss: 0.5720 - acc: 0.7844 - kappa: 0.9351\n",
      "Iteration 000251: OneCycleScheduler setting learning rate to 9.851384167071394e-05.\n",
      "252/343 [=====================>........] - ETA: 1:25 - loss: 0.5723 - acc: 0.7842 - kappa: 0.9353\n",
      "Iteration 000252: OneCycleScheduler setting learning rate to 9.874696454589607e-05.\n",
      "253/343 [=====================>........] - ETA: 1:24 - loss: 0.5715 - acc: 0.7841 - kappa: 0.9354\n",
      "Iteration 000253: OneCycleScheduler setting learning rate to 9.89800874210782e-05.\n",
      "254/343 [=====================>........] - ETA: 1:23 - loss: 0.5718 - acc: 0.7830 - kappa: 0.9352\n",
      "Iteration 000254: OneCycleScheduler setting learning rate to 9.921321029626032e-05.\n",
      "255/343 [=====================>........] - ETA: 1:22 - loss: 0.5735 - acc: 0.7814 - kappa: 0.9343\n",
      "Iteration 000255: OneCycleScheduler setting learning rate to 9.944633317144246e-05.\n",
      "256/343 [=====================>........] - ETA: 1:21 - loss: 0.5726 - acc: 0.7817 - kappa: 0.9345\n",
      "Iteration 000256: OneCycleScheduler setting learning rate to 9.967945604662458e-05.\n",
      "257/343 [=====================>........] - ETA: 1:20 - loss: 0.5717 - acc: 0.7821 - kappa: 0.9347\n",
      "Iteration 000257: OneCycleScheduler setting learning rate to 9.991257892180671e-05.\n",
      "258/343 [=====================>........] - ETA: 1:19 - loss: 0.5764 - acc: 0.7800 - kappa: 0.9325\n",
      "Iteration 000258: OneCycleScheduler setting learning rate to 0.00010014570179698885.\n",
      "259/343 [=====================>........] - ETA: 1:19 - loss: 0.5799 - acc: 0.7799 - kappa: 0.9326\n",
      "Iteration 000259: OneCycleScheduler setting learning rate to 0.00010037882467217097.\n",
      "260/343 [=====================>........] - ETA: 1:18 - loss: 0.5812 - acc: 0.7793 - kappa: 0.9324\n",
      "Iteration 000260: OneCycleScheduler setting learning rate to 0.0001006119475473531.\n",
      "261/343 [=====================>........] - ETA: 1:17 - loss: 0.5820 - acc: 0.7787 - kappa: 0.9324\n",
      "Iteration 000261: OneCycleScheduler setting learning rate to 0.00010084507042253522.\n",
      "262/343 [=====================>........] - ETA: 1:16 - loss: 0.5805 - acc: 0.7796 - kappa: 0.9326\n",
      "Iteration 000262: OneCycleScheduler setting learning rate to 0.00010107819329771735.\n",
      "263/343 [======================>.......] - ETA: 1:15 - loss: 0.5796 - acc: 0.7799 - kappa: 0.9329\n",
      "Iteration 000263: OneCycleScheduler setting learning rate to 0.00010131131617289947.\n",
      "264/343 [======================>.......] - ETA: 1:14 - loss: 0.5798 - acc: 0.7798 - kappa: 0.9329\n",
      "Iteration 000264: OneCycleScheduler setting learning rate to 0.0001015444390480816.\n",
      "265/343 [======================>.......] - ETA: 1:13 - loss: 0.5798 - acc: 0.7792 - kappa: 0.9326\n",
      "Iteration 000265: OneCycleScheduler setting learning rate to 0.00010177756192326372.\n",
      "266/343 [======================>.......] - ETA: 1:12 - loss: 0.5805 - acc: 0.7782 - kappa: 0.9318\n",
      "Iteration 000266: OneCycleScheduler setting learning rate to 0.00010201068479844585.\n",
      "267/343 [======================>.......] - ETA: 1:11 - loss: 0.5825 - acc: 0.7772 - kappa: 0.9302\n",
      "Iteration 000267: OneCycleScheduler setting learning rate to 0.00010224380767362797.\n",
      "268/343 [======================>.......] - ETA: 1:10 - loss: 0.5808 - acc: 0.7780 - kappa: 0.9305\n",
      "Iteration 000268: OneCycleScheduler setting learning rate to 0.0001024769305488101.\n",
      "269/343 [======================>.......] - ETA: 1:09 - loss: 0.5826 - acc: 0.7774 - kappa: 0.9305\n",
      "Iteration 000269: OneCycleScheduler setting learning rate to 0.00010271005342399222.\n",
      "270/343 [======================>.......] - ETA: 1:08 - loss: 0.5829 - acc: 0.7778 - kappa: 0.9307\n",
      "Iteration 000270: OneCycleScheduler setting learning rate to 0.00010294317629917438.\n",
      "271/343 [======================>.......] - ETA: 1:07 - loss: 0.5841 - acc: 0.7772 - kappa: 0.9305\n",
      "Iteration 000271: OneCycleScheduler setting learning rate to 0.0001031762991743565.\n",
      "272/343 [======================>.......] - ETA: 1:06 - loss: 0.5840 - acc: 0.7771 - kappa: 0.9306\n",
      "Iteration 000272: OneCycleScheduler setting learning rate to 0.00010340942204953863.\n",
      "273/343 [======================>.......] - ETA: 1:06 - loss: 0.5903 - acc: 0.7766 - kappa: 0.9302\n",
      "Iteration 000273: OneCycleScheduler setting learning rate to 0.00010364254492472075.\n",
      "274/343 [======================>.......] - ETA: 1:05 - loss: 0.5894 - acc: 0.7769 - kappa: 0.9303\n",
      "Iteration 000274: OneCycleScheduler setting learning rate to 0.00010387566779990288.\n",
      "275/343 [=======================>......] - ETA: 1:04 - loss: 0.5889 - acc: 0.7768 - kappa: 0.9305\n",
      "Iteration 000275: OneCycleScheduler setting learning rate to 0.000104108790675085.\n",
      "276/343 [=======================>......] - ETA: 1:03 - loss: 0.5910 - acc: 0.7758 - kappa: 0.9303\n",
      "Iteration 000276: OneCycleScheduler setting learning rate to 0.00010434191355026713.\n",
      "277/343 [=======================>......] - ETA: 1:02 - loss: 0.5923 - acc: 0.7762 - kappa: 0.9303\n",
      "Iteration 000277: OneCycleScheduler setting learning rate to 0.00010457503642544925.\n",
      "278/343 [=======================>......] - ETA: 1:01 - loss: 0.5930 - acc: 0.7761 - kappa: 0.9301\n",
      "Iteration 000278: OneCycleScheduler setting learning rate to 0.00010480815930063138.\n",
      "279/343 [=======================>......] - ETA: 1:00 - loss: 0.5922 - acc: 0.7764 - kappa: 0.9303\n",
      "Iteration 000279: OneCycleScheduler setting learning rate to 0.0001050412821758135.\n",
      "280/343 [=======================>......] - ETA: 59s - loss: 0.5927 - acc: 0.7768 - kappa: 0.9304 \n",
      "Iteration 000280: OneCycleScheduler setting learning rate to 0.00010527440505099563.\n",
      "281/343 [=======================>......] - ETA: 58s - loss: 0.5918 - acc: 0.7771 - kappa: 0.9305\n",
      "Iteration 000281: OneCycleScheduler setting learning rate to 0.00010550752792617775.\n",
      "282/343 [=======================>......] - ETA: 57s - loss: 0.5910 - acc: 0.7775 - kappa: 0.9308\n",
      "Iteration 000282: OneCycleScheduler setting learning rate to 0.00010574065080135988.\n",
      "283/343 [=======================>......] - ETA: 56s - loss: 0.5907 - acc: 0.7778 - kappa: 0.9310\n",
      "Iteration 000283: OneCycleScheduler setting learning rate to 0.00010597377367654203.\n",
      "284/343 [=======================>......] - ETA: 55s - loss: 0.5900 - acc: 0.7782 - kappa: 0.9312\n",
      "Iteration 000284: OneCycleScheduler setting learning rate to 0.00010620689655172416.\n",
      "285/343 [=======================>......] - ETA: 54s - loss: 0.5891 - acc: 0.7785 - kappa: 0.9314\n",
      "Iteration 000285: OneCycleScheduler setting learning rate to 0.00010644001942690628.\n",
      "286/343 [========================>.....] - ETA: 53s - loss: 0.5892 - acc: 0.7780 - kappa: 0.9310\n",
      "Iteration 000286: OneCycleScheduler setting learning rate to 0.00010667314230208841.\n",
      "287/343 [========================>.....] - ETA: 52s - loss: 0.5882 - acc: 0.7783 - kappa: 0.9312\n",
      "Iteration 000287: OneCycleScheduler setting learning rate to 0.00010690626517727053.\n",
      "288/343 [========================>.....] - ETA: 51s - loss: 0.5892 - acc: 0.7782 - kappa: 0.9312\n",
      "Iteration 000288: OneCycleScheduler setting learning rate to 0.00010713938805245266.\n",
      "289/343 [========================>.....] - ETA: 50s - loss: 0.5887 - acc: 0.7785 - kappa: 0.9314\n",
      "Iteration 000289: OneCycleScheduler setting learning rate to 0.00010737251092763478.\n",
      "290/343 [========================>.....] - ETA: 49s - loss: 0.5879 - acc: 0.7784 - kappa: 0.9314\n",
      "Iteration 000290: OneCycleScheduler setting learning rate to 0.00010760563380281691.\n",
      "291/343 [========================>.....] - ETA: 49s - loss: 0.5878 - acc: 0.7784 - kappa: 0.9314\n",
      "Iteration 000291: OneCycleScheduler setting learning rate to 0.00010783875667799903.\n",
      "292/343 [========================>.....] - ETA: 48s - loss: 0.5871 - acc: 0.7783 - kappa: 0.9315\n",
      "Iteration 000292: OneCycleScheduler setting learning rate to 0.00010807187955318116.\n",
      "293/343 [========================>.....] - ETA: 47s - loss: 0.5879 - acc: 0.7777 - kappa: 0.9311\n",
      "Iteration 000293: OneCycleScheduler setting learning rate to 0.00010830500242836328.\n",
      "294/343 [========================>.....] - ETA: 46s - loss: 0.5869 - acc: 0.7781 - kappa: 0.9313\n",
      "Iteration 000294: OneCycleScheduler setting learning rate to 0.00010853812530354541.\n",
      "295/343 [========================>.....] - ETA: 45s - loss: 0.5878 - acc: 0.7780 - kappa: 0.9314\n",
      "Iteration 000295: OneCycleScheduler setting learning rate to 0.00010877124817872753.\n",
      "296/343 [========================>.....] - ETA: 44s - loss: 0.5887 - acc: 0.7779 - kappa: 0.9314\n",
      "Iteration 000296: OneCycleScheduler setting learning rate to 0.00010900437105390969.\n",
      "297/343 [========================>.....] - ETA: 43s - loss: 0.5874 - acc: 0.7786 - kappa: 0.9316\n",
      "Iteration 000297: OneCycleScheduler setting learning rate to 0.00010923749392909181.\n",
      "298/343 [=========================>....] - ETA: 42s - loss: 0.5870 - acc: 0.7789 - kappa: 0.9318\n",
      "Iteration 000298: OneCycleScheduler setting learning rate to 0.00010947061680427394.\n",
      "299/343 [=========================>....] - ETA: 41s - loss: 0.5876 - acc: 0.7784 - kappa: 0.9313\n",
      "Iteration 000299: OneCycleScheduler setting learning rate to 0.00010970373967945606.\n",
      "300/343 [=========================>....] - ETA: 40s - loss: 0.5862 - acc: 0.7792 - kappa: 0.9316\n",
      "Iteration 000300: OneCycleScheduler setting learning rate to 0.00010993686255463819.\n",
      "301/343 [=========================>....] - ETA: 39s - loss: 0.5857 - acc: 0.7791 - kappa: 0.9317\n",
      "Iteration 000301: OneCycleScheduler setting learning rate to 0.00011016998542982031.\n",
      "302/343 [=========================>....] - ETA: 38s - loss: 0.5850 - acc: 0.7794 - kappa: 0.9319\n",
      "Iteration 000302: OneCycleScheduler setting learning rate to 0.00011040310830500244.\n",
      "303/343 [=========================>....] - ETA: 37s - loss: 0.5838 - acc: 0.7797 - kappa: 0.9320\n",
      "Iteration 000303: OneCycleScheduler setting learning rate to 0.00011063623118018456.\n",
      "304/343 [=========================>....] - ETA: 36s - loss: 0.5835 - acc: 0.7796 - kappa: 0.9320\n",
      "Iteration 000304: OneCycleScheduler setting learning rate to 0.00011086935405536669.\n",
      "305/343 [=========================>....] - ETA: 35s - loss: 0.5829 - acc: 0.7795 - kappa: 0.9320\n",
      "Iteration 000305: OneCycleScheduler setting learning rate to 0.00011110247693054881.\n",
      "306/343 [=========================>....] - ETA: 34s - loss: 0.5832 - acc: 0.7790 - kappa: 0.9320\n",
      "Iteration 000306: OneCycleScheduler setting learning rate to 0.00011133559980573094.\n",
      "307/343 [=========================>....] - ETA: 33s - loss: 0.5827 - acc: 0.7789 - kappa: 0.9321\n",
      "Iteration 000307: OneCycleScheduler setting learning rate to 0.00011156872268091306.\n",
      "308/343 [=========================>....] - ETA: 33s - loss: 0.5812 - acc: 0.7796 - kappa: 0.9323\n",
      "Iteration 000308: OneCycleScheduler setting learning rate to 0.00011180184555609519.\n",
      "309/343 [==========================>...] - ETA: 32s - loss: 0.5798 - acc: 0.7803 - kappa: 0.9325\n",
      "Iteration 000309: OneCycleScheduler setting learning rate to 0.00011203496843127731.\n",
      "310/343 [==========================>...] - ETA: 31s - loss: 0.5799 - acc: 0.7798 - kappa: 0.9325\n",
      "Iteration 000310: OneCycleScheduler setting learning rate to 0.00011226809130645947.\n",
      "311/343 [==========================>...] - ETA: 30s - loss: 0.5786 - acc: 0.7801 - kappa: 0.9327\n",
      "Iteration 000311: OneCycleScheduler setting learning rate to 0.00011250121418164159.\n",
      "312/343 [==========================>...] - ETA: 29s - loss: 0.5780 - acc: 0.7804 - kappa: 0.9329\n",
      "Iteration 000312: OneCycleScheduler setting learning rate to 0.00011273433705682372.\n",
      "313/343 [==========================>...] - ETA: 28s - loss: 0.5784 - acc: 0.7804 - kappa: 0.9327\n",
      "Iteration 000313: OneCycleScheduler setting learning rate to 0.00011296745993200584.\n",
      "314/343 [==========================>...] - ETA: 27s - loss: 0.5778 - acc: 0.7807 - kappa: 0.9328\n",
      "Iteration 000314: OneCycleScheduler setting learning rate to 0.00011320058280718797.\n",
      "315/343 [==========================>...] - ETA: 26s - loss: 0.5779 - acc: 0.7810 - kappa: 0.9330\n",
      "Iteration 000315: OneCycleScheduler setting learning rate to 0.00011343370568237009.\n",
      "316/343 [==========================>...] - ETA: 25s - loss: 0.5783 - acc: 0.7809 - kappa: 0.9330\n",
      "Iteration 000316: OneCycleScheduler setting learning rate to 0.00011366682855755222.\n",
      "317/343 [==========================>...] - ETA: 24s - loss: 0.5775 - acc: 0.7812 - kappa: 0.9331\n",
      "Iteration 000317: OneCycleScheduler setting learning rate to 0.00011389995143273434.\n",
      "318/343 [==========================>...] - ETA: 23s - loss: 0.5782 - acc: 0.7811 - kappa: 0.9330\n",
      "Iteration 000318: OneCycleScheduler setting learning rate to 0.00011413307430791647.\n",
      "319/343 [==========================>...] - ETA: 22s - loss: 0.5794 - acc: 0.7802 - kappa: 0.9326\n",
      "Iteration 000319: OneCycleScheduler setting learning rate to 0.0001143661971830986.\n",
      "320/343 [==========================>...] - ETA: 21s - loss: 0.5791 - acc: 0.7805 - kappa: 0.9327\n",
      "Iteration 000320: OneCycleScheduler setting learning rate to 0.00011459932005828072.\n",
      "321/343 [===========================>..] - ETA: 20s - loss: 0.5778 - acc: 0.7812 - kappa: 0.9329\n",
      "Iteration 000321: OneCycleScheduler setting learning rate to 0.00011483244293346284.\n",
      "322/343 [===========================>..] - ETA: 19s - loss: 0.5791 - acc: 0.7807 - kappa: 0.9327\n",
      "Iteration 000322: OneCycleScheduler setting learning rate to 0.00011506556580864497.\n",
      "323/343 [===========================>..] - ETA: 18s - loss: 0.5792 - acc: 0.7802 - kappa: 0.9327\n",
      "Iteration 000323: OneCycleScheduler setting learning rate to 0.00011529868868382712.\n",
      "324/343 [===========================>..] - ETA: 18s - loss: 0.5800 - acc: 0.7797 - kappa: 0.9325\n",
      "Iteration 000324: OneCycleScheduler setting learning rate to 0.00011553181155900925.\n",
      "325/343 [===========================>..] - ETA: 17s - loss: 0.5796 - acc: 0.7800 - kappa: 0.9327\n",
      "Iteration 000325: OneCycleScheduler setting learning rate to 0.00011576493443419137.\n",
      "326/343 [===========================>..] - ETA: 16s - loss: 0.5793 - acc: 0.7799 - kappa: 0.9327\n",
      "Iteration 000326: OneCycleScheduler setting learning rate to 0.0001159980573093735.\n",
      "327/343 [===========================>..] - ETA: 15s - loss: 0.5805 - acc: 0.7794 - kappa: 0.9325\n",
      "Iteration 000327: OneCycleScheduler setting learning rate to 0.00011623118018455562.\n",
      "328/343 [===========================>..] - ETA: 14s - loss: 0.5805 - acc: 0.7793 - kappa: 0.9326\n",
      "Iteration 000328: OneCycleScheduler setting learning rate to 0.00011646430305973775.\n",
      "329/343 [===========================>..] - ETA: 13s - loss: 0.5805 - acc: 0.7793 - kappa: 0.9324\n",
      "Iteration 000329: OneCycleScheduler setting learning rate to 0.00011669742593491987.\n",
      "330/343 [===========================>..] - ETA: 12s - loss: 0.5823 - acc: 0.7788 - kappa: 0.9321\n",
      "Iteration 000330: OneCycleScheduler setting learning rate to 0.000116930548810102.\n",
      "331/343 [===========================>..] - ETA: 11s - loss: 0.5810 - acc: 0.7795 - kappa: 0.9323\n",
      "Iteration 000331: OneCycleScheduler setting learning rate to 0.00011716367168528412.\n",
      "332/343 [============================>.] - ETA: 10s - loss: 0.5823 - acc: 0.7790 - kappa: 0.9319\n",
      "Iteration 000332: OneCycleScheduler setting learning rate to 0.00011739679456046625.\n",
      "333/343 [============================>.] - ETA: 9s - loss: 0.5820 - acc: 0.7789 - kappa: 0.9319 \n",
      "Iteration 000333: OneCycleScheduler setting learning rate to 0.00011762991743564837.\n",
      "334/343 [============================>.] - ETA: 8s - loss: 0.5829 - acc: 0.7784 - kappa: 0.9315\n",
      "Iteration 000334: OneCycleScheduler setting learning rate to 0.0001178630403108305.\n",
      "335/343 [============================>.] - ETA: 7s - loss: 0.5833 - acc: 0.7787 - kappa: 0.9317\n",
      "Iteration 000335: OneCycleScheduler setting learning rate to 0.00011809616318601262.\n",
      "336/343 [============================>.] - ETA: 6s - loss: 0.5829 - acc: 0.7790 - kappa: 0.9318\n",
      "Iteration 000336: OneCycleScheduler setting learning rate to 0.00011832928606119478.\n",
      "337/343 [============================>.] - ETA: 5s - loss: 0.5864 - acc: 0.7782 - kappa: 0.9317\n",
      "Iteration 000337: OneCycleScheduler setting learning rate to 0.0001185624089363769.\n",
      "338/343 [============================>.] - ETA: 4s - loss: 0.5855 - acc: 0.7785 - kappa: 0.9319\n",
      "Iteration 000338: OneCycleScheduler setting learning rate to 0.00011879553181155903.\n",
      "339/343 [============================>.] - ETA: 3s - loss: 0.5848 - acc: 0.7788 - kappa: 0.9320\n",
      "Iteration 000339: OneCycleScheduler setting learning rate to 0.00011902865468674115.\n",
      "340/343 [============================>.] - ETA: 2s - loss: 0.5841 - acc: 0.7790 - kappa: 0.9321\n",
      "Iteration 000340: OneCycleScheduler setting learning rate to 0.00011926177756192328.\n",
      "341/343 [============================>.] - ETA: 1s - loss: 0.5839 - acc: 0.7790 - kappa: 0.9321\n",
      "Iteration 000341: OneCycleScheduler setting learning rate to 0.0001194949004371054.\n",
      "342/343 [============================>.] - ETA: 0s - loss: 0.5826 - acc: 0.7796 - kappa: 0.9323\n",
      "Iteration 000342: OneCycleScheduler setting learning rate to 0.00011972802331228753.\n",
      "343/343 [==============================] - 419s 1s/step - loss: 0.5822 - acc: 0.7795 - kappa: 0.9323 - val_loss: 0.6677 - val_acc: 0.7533 - val_kappa: 0.9133\n",
      "Epoch 4/30\n",
      "\n",
      "Iteration 000000: OneCycleScheduler setting learning rate to 4e-05.\n",
      "  1/343 [..............................] - ETA: 1:01 - loss: 0.3924 - acc: 0.8750 - kappa: 0.9688\n",
      "Iteration 000001: OneCycleScheduler setting learning rate to 4.023312287518213e-05.\n",
      "  2/343 [..............................] - ETA: 52s - loss: 0.6287 - acc: 0.7500 - kappa: 0.9219 \n",
      "Iteration 000002: OneCycleScheduler setting learning rate to 4.046624575036426e-05.\n",
      "  3/343 [..............................] - ETA: 49s - loss: 0.8556 - acc: 0.7083 - kappa: 0.8542\n",
      "Iteration 000003: OneCycleScheduler setting learning rate to 4.0699368625546386e-05.\n",
      "  4/343 [..............................] - ETA: 47s - loss: 0.9933 - acc: 0.7188 - kappa: 0.8730\n",
      "Iteration 000004: OneCycleScheduler setting learning rate to 4.093249150072851e-05.\n",
      "  5/343 [..............................] - ETA: 47s - loss: 0.9412 - acc: 0.7000 - kappa: 0.8594\n",
      "Iteration 000005: OneCycleScheduler setting learning rate to 4.1165614375910636e-05.\n",
      "  6/343 [..............................] - ETA: 49s - loss: 0.8276 - acc: 0.7292 - kappa: 0.8815\n",
      "Iteration 000006: OneCycleScheduler setting learning rate to 4.139873725109277e-05.\n",
      "  7/343 [..............................] - ETA: 48s - loss: 0.7891 - acc: 0.7500 - kappa: 0.8973\n",
      "Iteration 000007: OneCycleScheduler setting learning rate to 4.1631860126274893e-05.\n",
      "  8/343 [..............................] - ETA: 47s - loss: 0.7739 - acc: 0.7500 - kappa: 0.8945\n",
      "Iteration 000008: OneCycleScheduler setting learning rate to 4.186498300145702e-05.\n",
      "  9/343 [..............................] - ETA: 47s - loss: 0.7173 - acc: 0.7639 - kappa: 0.9028\n",
      "Iteration 000009: OneCycleScheduler setting learning rate to 4.209810587663915e-05.\n",
      " 10/343 [..............................] - ETA: 47s - loss: 0.6896 - acc: 0.7750 - kappa: 0.9094\n",
      "Iteration 000010: OneCycleScheduler setting learning rate to 4.2331228751821276e-05.\n",
      " 11/343 [..............................] - ETA: 46s - loss: 0.7161 - acc: 0.7500 - kappa: 0.8920\n",
      "Iteration 000011: OneCycleScheduler setting learning rate to 4.25643516270034e-05.\n",
      " 12/343 [>.............................] - ETA: 57s - loss: 0.6873 - acc: 0.7604 - kappa: 0.9004\n",
      "Iteration 000012: OneCycleScheduler setting learning rate to 4.279747450218553e-05.\n",
      " 13/343 [>.............................] - ETA: 1:24 - loss: 0.7005 - acc: 0.7404 - kappa: 0.8786\n",
      "Iteration 000013: OneCycleScheduler setting learning rate to 4.303059737736766e-05.\n",
      " 14/343 [>.............................] - ETA: 1:49 - loss: 0.6955 - acc: 0.7411 - kappa: 0.8850\n",
      "Iteration 000014: OneCycleScheduler setting learning rate to 4.3263720252549784e-05.\n",
      " 15/343 [>.............................] - ETA: 2:15 - loss: 0.6859 - acc: 0.7417 - kappa: 0.8906\n",
      "Iteration 000015: OneCycleScheduler setting learning rate to 4.3496843127731916e-05.\n",
      " 16/343 [>.............................] - ETA: 2:33 - loss: 0.6542 - acc: 0.7578 - kappa: 0.8975\n",
      "Iteration 000016: OneCycleScheduler setting learning rate to 4.372996600291404e-05.\n",
      " 17/343 [>.............................] - ETA: 3:01 - loss: 0.6437 - acc: 0.7574 - kappa: 0.8994\n",
      "Iteration 000017: OneCycleScheduler setting learning rate to 4.3963088878096166e-05.\n",
      " 18/343 [>.............................] - ETA: 3:13 - loss: 0.6516 - acc: 0.7431 - kappa: 0.8980\n",
      "Iteration 000018: OneCycleScheduler setting learning rate to 4.419621175327829e-05.\n",
      " 19/343 [>.............................] - ETA: 3:22 - loss: 0.6466 - acc: 0.7434 - kappa: 0.9017\n",
      "Iteration 000019: OneCycleScheduler setting learning rate to 4.442933462846042e-05.\n",
      " 20/343 [>.............................] - ETA: 3:29 - loss: 0.6281 - acc: 0.7562 - kappa: 0.9066\n",
      "Iteration 000020: OneCycleScheduler setting learning rate to 4.466245750364255e-05.\n",
      " 21/343 [>.............................] - ETA: 3:37 - loss: 0.6318 - acc: 0.7500 - kappa: 0.9018\n",
      "Iteration 000021: OneCycleScheduler setting learning rate to 4.4895580378824674e-05.\n",
      " 22/343 [>.............................] - ETA: 3:38 - loss: 0.6234 - acc: 0.7557 - kappa: 0.9059\n",
      "Iteration 000022: OneCycleScheduler setting learning rate to 4.5128703254006806e-05.\n",
      " 23/343 [=>............................] - ETA: 3:44 - loss: 0.6301 - acc: 0.7554 - kappa: 0.9046\n",
      "Iteration 000023: OneCycleScheduler setting learning rate to 4.536182612918893e-05.\n",
      " 24/343 [=>............................] - ETA: 3:49 - loss: 0.6450 - acc: 0.7552 - kappa: 0.9033\n",
      "Iteration 000024: OneCycleScheduler setting learning rate to 4.5594949004371056e-05.\n",
      " 25/343 [=>............................] - ETA: 3:52 - loss: 0.6260 - acc: 0.7650 - kappa: 0.9072\n",
      "Iteration 000025: OneCycleScheduler setting learning rate to 4.582807187955318e-05.\n",
      " 26/343 [=>............................] - ETA: 3:54 - loss: 0.6405 - acc: 0.7644 - kappa: 0.9059\n",
      "Iteration 000026: OneCycleScheduler setting learning rate to 4.606119475473531e-05.\n",
      " 27/343 [=>............................] - ETA: 3:56 - loss: 0.6728 - acc: 0.7593 - kappa: 0.9068\n",
      "Iteration 000027: OneCycleScheduler setting learning rate to 4.629431762991744e-05.\n",
      " 28/343 [=>............................] - ETA: 4:01 - loss: 0.6545 - acc: 0.7679 - kappa: 0.9102\n",
      "Iteration 000028: OneCycleScheduler setting learning rate to 4.6527440505099564e-05.\n",
      " 29/343 [=>............................] - ETA: 4:00 - loss: 0.6412 - acc: 0.7716 - kappa: 0.9122\n",
      "Iteration 000029: OneCycleScheduler setting learning rate to 4.6760563380281696e-05.\n",
      " 30/343 [=>............................] - ETA: 4:00 - loss: 0.6343 - acc: 0.7750 - kappa: 0.9148\n",
      "Iteration 000030: OneCycleScheduler setting learning rate to 4.699368625546382e-05.\n",
      " 31/343 [=>............................] - ETA: 3:59 - loss: 0.6407 - acc: 0.7702 - kappa: 0.9153\n",
      "Iteration 000031: OneCycleScheduler setting learning rate to 4.7226809130645946e-05.\n",
      " 32/343 [=>............................] - ETA: 3:58 - loss: 0.6430 - acc: 0.7734 - kappa: 0.9177\n",
      "Iteration 000032: OneCycleScheduler setting learning rate to 4.745993200582808e-05.\n",
      " 33/343 [=>............................] - ETA: 4:01 - loss: 0.6782 - acc: 0.7614 - kappa: 0.8965\n",
      "Iteration 000033: OneCycleScheduler setting learning rate to 4.7693054881010203e-05.\n",
      " 34/343 [=>............................] - ETA: 3:58 - loss: 0.6660 - acc: 0.7684 - kappa: 0.8996\n",
      "Iteration 000034: OneCycleScheduler setting learning rate to 4.792617775619233e-05.\n",
      " 35/343 [==>...........................] - ETA: 3:58 - loss: 0.6589 - acc: 0.7714 - kappa: 0.9004\n",
      "Iteration 000035: OneCycleScheduler setting learning rate to 4.815930063137446e-05.\n",
      " 36/343 [==>...........................] - ETA: 3:57 - loss: 0.6486 - acc: 0.7743 - kappa: 0.9030\n",
      "Iteration 000036: OneCycleScheduler setting learning rate to 4.8392423506556586e-05.\n",
      " 37/343 [==>...........................] - ETA: 3:57 - loss: 0.6357 - acc: 0.7804 - kappa: 0.9056\n",
      "Iteration 000037: OneCycleScheduler setting learning rate to 4.862554638173871e-05.\n",
      " 38/343 [==>...........................] - ETA: 3:56 - loss: 0.6242 - acc: 0.7862 - kappa: 0.9081\n",
      "Iteration 000038: OneCycleScheduler setting learning rate to 4.8858669256920836e-05.\n",
      " 39/343 [==>...........................] - ETA: 3:56 - loss: 0.6182 - acc: 0.7885 - kappa: 0.9097\n",
      "Iteration 000039: OneCycleScheduler setting learning rate to 4.909179213210297e-05.\n",
      " 40/343 [==>...........................] - ETA: 3:58 - loss: 0.6201 - acc: 0.7875 - kappa: 0.9111\n",
      "Iteration 000040: OneCycleScheduler setting learning rate to 4.9324915007285094e-05.\n",
      " 41/343 [==>...........................] - ETA: 3:59 - loss: 0.6199 - acc: 0.7835 - kappa: 0.9116\n",
      "Iteration 000041: OneCycleScheduler setting learning rate to 4.955803788246722e-05.\n",
      " 42/343 [==>...........................] - ETA: 4:00 - loss: 0.6195 - acc: 0.7827 - kappa: 0.9129\n",
      "Iteration 000042: OneCycleScheduler setting learning rate to 4.979116075764935e-05.\n",
      " 43/343 [==>...........................] - ETA: 4:01 - loss: 0.6230 - acc: 0.7820 - kappa: 0.9121\n",
      "Iteration 000043: OneCycleScheduler setting learning rate to 5.0024283632831476e-05.\n",
      " 44/343 [==>...........................] - ETA: 4:01 - loss: 0.6200 - acc: 0.7812 - kappa: 0.9125\n",
      "Iteration 000044: OneCycleScheduler setting learning rate to 5.02574065080136e-05.\n",
      " 45/343 [==>...........................] - ETA: 4:00 - loss: 0.6308 - acc: 0.7750 - kappa: 0.9082\n",
      "Iteration 000045: OneCycleScheduler setting learning rate to 5.0490529383195726e-05.\n",
      " 46/343 [===>..........................] - ETA: 3:59 - loss: 0.6222 - acc: 0.7772 - kappa: 0.9100\n",
      "Iteration 000046: OneCycleScheduler setting learning rate to 5.072365225837786e-05.\n",
      " 47/343 [===>..........................] - ETA: 3:58 - loss: 0.6180 - acc: 0.7766 - kappa: 0.9112\n",
      "Iteration 000047: OneCycleScheduler setting learning rate to 5.0956775133559984e-05.\n",
      " 48/343 [===>..........................] - ETA: 3:57 - loss: 0.6150 - acc: 0.7760 - kappa: 0.9105\n",
      "Iteration 000048: OneCycleScheduler setting learning rate to 5.1189898008742116e-05.\n",
      " 49/343 [===>..........................] - ETA: 3:56 - loss: 0.6099 - acc: 0.7781 - kappa: 0.9117\n",
      "Iteration 000049: OneCycleScheduler setting learning rate to 5.142302088392424e-05.\n",
      " 50/343 [===>..........................] - ETA: 3:57 - loss: 0.6046 - acc: 0.7800 - kappa: 0.9128\n",
      "Iteration 000050: OneCycleScheduler setting learning rate to 5.1656143759106366e-05.\n",
      " 51/343 [===>..........................] - ETA: 3:57 - loss: 0.6151 - acc: 0.7770 - kappa: 0.9121\n",
      "Iteration 000051: OneCycleScheduler setting learning rate to 5.188926663428849e-05.\n",
      " 52/343 [===>..........................] - ETA: 3:57 - loss: 0.6160 - acc: 0.7764 - kappa: 0.9124\n",
      "Iteration 000052: OneCycleScheduler setting learning rate to 5.212238950947062e-05.\n",
      " 53/343 [===>..........................] - ETA: 3:58 - loss: 0.6145 - acc: 0.7783 - kappa: 0.9135\n",
      "Iteration 000053: OneCycleScheduler setting learning rate to 5.235551238465275e-05.\n",
      " 54/343 [===>..........................] - ETA: 3:57 - loss: 0.6113 - acc: 0.7778 - kappa: 0.9145\n",
      "Iteration 000054: OneCycleScheduler setting learning rate to 5.2588635259834874e-05.\n",
      " 55/343 [===>..........................] - ETA: 3:55 - loss: 0.6081 - acc: 0.7773 - kappa: 0.9148\n",
      "Iteration 000055: OneCycleScheduler setting learning rate to 5.2821758135017006e-05.\n",
      " 56/343 [===>..........................] - ETA: 3:56 - loss: 0.6109 - acc: 0.7768 - kappa: 0.9157\n",
      "Iteration 000056: OneCycleScheduler setting learning rate to 5.305488101019913e-05.\n",
      " 57/343 [===>..........................] - ETA: 3:55 - loss: 0.6074 - acc: 0.7763 - kappa: 0.9160\n",
      "Iteration 000057: OneCycleScheduler setting learning rate to 5.3288003885381256e-05.\n",
      " 58/343 [====>.........................] - ETA: 3:54 - loss: 0.6140 - acc: 0.7737 - kappa: 0.9162\n",
      "Iteration 000058: OneCycleScheduler setting learning rate to 5.352112676056338e-05.\n",
      " 59/343 [====>.........................] - ETA: 3:54 - loss: 0.6106 - acc: 0.7733 - kappa: 0.9164\n",
      "Iteration 000059: OneCycleScheduler setting learning rate to 5.3754249635745514e-05.\n",
      " 60/343 [====>.........................] - ETA: 3:53 - loss: 0.6115 - acc: 0.7729 - kappa: 0.9173\n",
      "Iteration 000060: OneCycleScheduler setting learning rate to 5.398737251092764e-05.\n",
      " 61/343 [====>.........................] - ETA: 3:52 - loss: 0.6125 - acc: 0.7725 - kappa: 0.9182\n",
      "Iteration 000061: OneCycleScheduler setting learning rate to 5.4220495386109764e-05.\n",
      " 62/343 [====>.........................] - ETA: 3:53 - loss: 0.6197 - acc: 0.7661 - kappa: 0.9163\n",
      "Iteration 000062: OneCycleScheduler setting learning rate to 5.4453618261291896e-05.\n",
      " 63/343 [====>.........................] - ETA: 3:53 - loss: 0.6197 - acc: 0.7639 - kappa: 0.9165\n",
      "Iteration 000063: OneCycleScheduler setting learning rate to 5.468674113647402e-05.\n",
      " 64/343 [====>.........................] - ETA: 3:52 - loss: 0.6266 - acc: 0.7617 - kappa: 0.9159\n",
      "Iteration 000064: OneCycleScheduler setting learning rate to 5.4919864011656146e-05.\n",
      " 65/343 [====>.........................] - ETA: 3:51 - loss: 0.6247 - acc: 0.7615 - kappa: 0.9161\n",
      "Iteration 000065: OneCycleScheduler setting learning rate to 5.515298688683827e-05.\n",
      " 66/343 [====>.........................] - ETA: 3:51 - loss: 0.6210 - acc: 0.7633 - kappa: 0.9169\n",
      "Iteration 000066: OneCycleScheduler setting learning rate to 5.5386109762020404e-05.\n",
      " 67/343 [====>.........................] - ETA: 3:51 - loss: 0.6178 - acc: 0.7649 - kappa: 0.9177\n",
      "Iteration 000067: OneCycleScheduler setting learning rate to 5.561923263720253e-05.\n",
      " 68/343 [====>.........................] - ETA: 3:50 - loss: 0.6202 - acc: 0.7610 - kappa: 0.9148\n",
      "Iteration 000068: OneCycleScheduler setting learning rate to 5.585235551238466e-05.\n",
      " 69/343 [=====>........................] - ETA: 3:51 - loss: 0.6216 - acc: 0.7609 - kappa: 0.9155\n",
      "Iteration 000069: OneCycleScheduler setting learning rate to 5.6085478387566786e-05.\n",
      " 70/343 [=====>........................] - ETA: 3:50 - loss: 0.6234 - acc: 0.7607 - kappa: 0.9163\n",
      "Iteration 000070: OneCycleScheduler setting learning rate to 5.631860126274891e-05.\n",
      " 71/343 [=====>........................] - ETA: 3:49 - loss: 0.6193 - acc: 0.7641 - kappa: 0.9175\n",
      "Iteration 000071: OneCycleScheduler setting learning rate to 5.6551724137931037e-05.\n",
      " 72/343 [=====>........................] - ETA: 3:49 - loss: 0.6280 - acc: 0.7604 - kappa: 0.9147\n",
      "Iteration 000072: OneCycleScheduler setting learning rate to 5.678484701311316e-05.\n",
      " 73/343 [=====>........................] - ETA: 3:48 - loss: 0.6277 - acc: 0.7603 - kappa: 0.9149\n",
      "Iteration 000073: OneCycleScheduler setting learning rate to 5.7017969888295294e-05.\n",
      " 74/343 [=====>........................] - ETA: 3:48 - loss: 0.6286 - acc: 0.7601 - kappa: 0.9144\n",
      "Iteration 000074: OneCycleScheduler setting learning rate to 5.7251092763477426e-05.\n",
      " 75/343 [=====>........................] - ETA: 3:46 - loss: 0.6241 - acc: 0.7600 - kappa: 0.9146\n",
      "Iteration 000075: OneCycleScheduler setting learning rate to 5.748421563865955e-05.\n",
      " 76/343 [=====>........................] - ETA: 3:45 - loss: 0.6176 - acc: 0.7632 - kappa: 0.9157\n",
      "Iteration 000076: OneCycleScheduler setting learning rate to 5.7717338513841676e-05.\n",
      " 77/343 [=====>........................] - ETA: 3:45 - loss: 0.6247 - acc: 0.7614 - kappa: 0.9131\n",
      "Iteration 000077: OneCycleScheduler setting learning rate to 5.79504613890238e-05.\n",
      " 78/343 [=====>........................] - ETA: 3:45 - loss: 0.6261 - acc: 0.7612 - kappa: 0.9127\n",
      "Iteration 000078: OneCycleScheduler setting learning rate to 5.818358426420593e-05.\n",
      " 79/343 [=====>........................] - ETA: 3:44 - loss: 0.6223 - acc: 0.7627 - kappa: 0.9134\n",
      "Iteration 000079: OneCycleScheduler setting learning rate to 5.841670713938806e-05.\n",
      " 80/343 [=====>........................] - ETA: 3:43 - loss: 0.6191 - acc: 0.7641 - kappa: 0.9144\n",
      "Iteration 000080: OneCycleScheduler setting learning rate to 5.8649830014570184e-05.\n",
      " 81/343 [======>.......................] - ETA: 3:42 - loss: 0.6154 - acc: 0.7670 - kappa: 0.9154\n",
      "Iteration 000081: OneCycleScheduler setting learning rate to 5.8882952889752316e-05.\n",
      " 82/343 [======>.......................] - ETA: 3:41 - loss: 0.6106 - acc: 0.7683 - kappa: 0.9163\n",
      "Iteration 000082: OneCycleScheduler setting learning rate to 5.911607576493444e-05.\n",
      " 83/343 [======>.......................] - ETA: 3:41 - loss: 0.6083 - acc: 0.7696 - kappa: 0.9170\n",
      "Iteration 000083: OneCycleScheduler setting learning rate to 5.9349198640116566e-05.\n",
      " 84/343 [======>.......................] - ETA: 3:41 - loss: 0.6075 - acc: 0.7693 - kappa: 0.9171\n",
      "Iteration 000084: OneCycleScheduler setting learning rate to 5.958232151529869e-05.\n",
      " 85/343 [======>.......................] - ETA: 3:41 - loss: 0.6027 - acc: 0.7706 - kappa: 0.9180\n",
      "Iteration 000085: OneCycleScheduler setting learning rate to 5.981544439048082e-05.\n",
      " 86/343 [======>.......................] - ETA: 3:41 - loss: 0.6037 - acc: 0.7703 - kappa: 0.9186\n",
      "Iteration 000086: OneCycleScheduler setting learning rate to 6.004856726566295e-05.\n",
      " 87/343 [======>.......................] - ETA: 3:40 - loss: 0.6026 - acc: 0.7701 - kappa: 0.9173\n",
      "Iteration 000087: OneCycleScheduler setting learning rate to 6.0281690140845074e-05.\n",
      " 88/343 [======>.......................] - ETA: 3:40 - loss: 0.5972 - acc: 0.7727 - kappa: 0.9182\n",
      "Iteration 000088: OneCycleScheduler setting learning rate to 6.0514813016027206e-05.\n",
      " 89/343 [======>.......................] - ETA: 3:40 - loss: 0.6003 - acc: 0.7711 - kappa: 0.9177\n",
      "Iteration 000089: OneCycleScheduler setting learning rate to 6.074793589120933e-05.\n",
      " 90/343 [======>.......................] - ETA: 3:39 - loss: 0.5976 - acc: 0.7722 - kappa: 0.9186\n",
      "Iteration 000090: OneCycleScheduler setting learning rate to 6.0981058766391456e-05.\n",
      " 91/343 [======>.......................] - ETA: 3:38 - loss: 0.6001 - acc: 0.7734 - kappa: 0.9191\n",
      "Iteration 000091: OneCycleScheduler setting learning rate to 6.121418164157358e-05.\n",
      " 92/343 [=======>......................] - ETA: 3:38 - loss: 0.5968 - acc: 0.7745 - kappa: 0.9199\n",
      "Iteration 000092: OneCycleScheduler setting learning rate to 6.144730451675571e-05.\n",
      " 93/343 [=======>......................] - ETA: 3:37 - loss: 0.5919 - acc: 0.7769 - kappa: 0.9208\n",
      "Iteration 000093: OneCycleScheduler setting learning rate to 6.168042739193783e-05.\n",
      " 94/343 [=======>......................] - ETA: 3:36 - loss: 0.5895 - acc: 0.7779 - kappa: 0.9215\n",
      "Iteration 000094: OneCycleScheduler setting learning rate to 6.191355026711997e-05.\n",
      " 95/343 [=======>......................] - ETA: 3:35 - loss: 0.5912 - acc: 0.7750 - kappa: 0.9194\n",
      "Iteration 000095: OneCycleScheduler setting learning rate to 6.21466731423021e-05.\n",
      " 96/343 [=======>......................] - ETA: 3:34 - loss: 0.5913 - acc: 0.7747 - kappa: 0.9199\n",
      "Iteration 000096: OneCycleScheduler setting learning rate to 6.237979601748422e-05.\n",
      " 97/343 [=======>......................] - ETA: 3:33 - loss: 0.5927 - acc: 0.7758 - kappa: 0.9204\n",
      "Iteration 000097: OneCycleScheduler setting learning rate to 6.261291889266635e-05.\n",
      " 98/343 [=======>......................] - ETA: 3:32 - loss: 0.5905 - acc: 0.7768 - kappa: 0.9212\n",
      "Iteration 000098: OneCycleScheduler setting learning rate to 6.284604176784847e-05.\n",
      " 99/343 [=======>......................] - ETA: 3:31 - loss: 0.5862 - acc: 0.7790 - kappa: 0.9220\n",
      "Iteration 000099: OneCycleScheduler setting learning rate to 6.307916464303061e-05.\n",
      "100/343 [=======>......................] - ETA: 3:31 - loss: 0.5831 - acc: 0.7800 - kappa: 0.9227\n",
      "Iteration 000100: OneCycleScheduler setting learning rate to 6.331228751821274e-05.\n",
      "101/343 [=======>......................] - ETA: 3:30 - loss: 0.5831 - acc: 0.7785 - kappa: 0.9227\n",
      "Iteration 000101: OneCycleScheduler setting learning rate to 6.354541039339486e-05.\n",
      "102/343 [=======>......................] - ETA: 3:29 - loss: 0.5799 - acc: 0.7794 - kappa: 0.9234\n",
      "Iteration 000102: OneCycleScheduler setting learning rate to 6.377853326857699e-05.\n",
      "103/343 [========>.....................] - ETA: 3:29 - loss: 0.5803 - acc: 0.7791 - kappa: 0.9229\n",
      "Iteration 000103: OneCycleScheduler setting learning rate to 6.401165614375911e-05.\n",
      "104/343 [========>.....................] - ETA: 3:29 - loss: 0.5807 - acc: 0.7776 - kappa: 0.9225\n",
      "Iteration 000104: OneCycleScheduler setting learning rate to 6.424477901894124e-05.\n",
      "105/343 [========>.....................] - ETA: 3:28 - loss: 0.5799 - acc: 0.7774 - kappa: 0.9229\n",
      "Iteration 000105: OneCycleScheduler setting learning rate to 6.447790189412336e-05.\n",
      "106/343 [========>.....................] - ETA: 3:27 - loss: 0.5797 - acc: 0.7771 - kappa: 0.9230\n",
      "Iteration 000106: OneCycleScheduler setting learning rate to 6.471102476930549e-05.\n",
      "107/343 [========>.....................] - ETA: 3:26 - loss: 0.5771 - acc: 0.7780 - kappa: 0.9236\n",
      "Iteration 000107: OneCycleScheduler setting learning rate to 6.494414764448761e-05.\n",
      "108/343 [========>.....................] - ETA: 3:25 - loss: 0.5742 - acc: 0.7789 - kappa: 0.9243\n",
      "Iteration 000108: OneCycleScheduler setting learning rate to 6.517727051966975e-05.\n",
      "109/343 [========>.....................] - ETA: 3:25 - loss: 0.5725 - acc: 0.7798 - kappa: 0.9249\n",
      "Iteration 000109: OneCycleScheduler setting learning rate to 6.541039339485188e-05.\n",
      "110/343 [========>.....................] - ETA: 3:24 - loss: 0.5691 - acc: 0.7818 - kappa: 0.9256\n",
      "Iteration 000110: OneCycleScheduler setting learning rate to 6.5643516270034e-05.\n",
      "111/343 [========>.....................] - ETA: 3:24 - loss: 0.5683 - acc: 0.7838 - kappa: 0.9262\n",
      "Iteration 000111: OneCycleScheduler setting learning rate to 6.587663914521613e-05.\n",
      "112/343 [========>.....................] - ETA: 3:24 - loss: 0.5735 - acc: 0.7824 - kappa: 0.9258\n",
      "Iteration 000112: OneCycleScheduler setting learning rate to 6.610976202039825e-05.\n",
      "113/343 [========>.....................] - ETA: 3:23 - loss: 0.5723 - acc: 0.7832 - kappa: 0.9264\n",
      "Iteration 000113: OneCycleScheduler setting learning rate to 6.634288489558039e-05.\n",
      "114/343 [========>.....................] - ETA: 3:22 - loss: 0.5704 - acc: 0.7829 - kappa: 0.9267\n",
      "Iteration 000114: OneCycleScheduler setting learning rate to 6.657600777076252e-05.\n",
      "115/343 [=========>....................] - ETA: 3:21 - loss: 0.5668 - acc: 0.7848 - kappa: 0.9274\n",
      "Iteration 000115: OneCycleScheduler setting learning rate to 6.680913064594464e-05.\n",
      "116/343 [=========>....................] - ETA: 3:21 - loss: 0.5693 - acc: 0.7834 - kappa: 0.9269\n",
      "Iteration 000116: OneCycleScheduler setting learning rate to 6.704225352112677e-05.\n",
      "117/343 [=========>....................] - ETA: 3:20 - loss: 0.5677 - acc: 0.7831 - kappa: 0.9269\n",
      "Iteration 000117: OneCycleScheduler setting learning rate to 6.727537639630889e-05.\n",
      "118/343 [=========>....................] - ETA: 3:19 - loss: 0.5668 - acc: 0.7818 - kappa: 0.9270\n",
      "Iteration 000118: OneCycleScheduler setting learning rate to 6.750849927149102e-05.\n",
      "119/343 [=========>....................] - ETA: 3:18 - loss: 0.5696 - acc: 0.7805 - kappa: 0.9265\n",
      "Iteration 000119: OneCycleScheduler setting learning rate to 6.774162214667314e-05.\n",
      "120/343 [=========>....................] - ETA: 3:17 - loss: 0.5680 - acc: 0.7812 - kappa: 0.9271\n",
      "Iteration 000120: OneCycleScheduler setting learning rate to 6.797474502185527e-05.\n",
      "121/343 [=========>....................] - ETA: 3:16 - loss: 0.5669 - acc: 0.7810 - kappa: 0.9274\n",
      "Iteration 000121: OneCycleScheduler setting learning rate to 6.82078678970374e-05.\n",
      "122/343 [=========>....................] - ETA: 3:16 - loss: 0.5664 - acc: 0.7807 - kappa: 0.9274\n",
      "Iteration 000122: OneCycleScheduler setting learning rate to 6.844099077221953e-05.\n",
      "123/343 [=========>....................] - ETA: 3:15 - loss: 0.5686 - acc: 0.7795 - kappa: 0.9270\n",
      "Iteration 000123: OneCycleScheduler setting learning rate to 6.867411364740166e-05.\n",
      "124/343 [=========>....................] - ETA: 3:16 - loss: 0.5727 - acc: 0.7762 - kappa: 0.9245\n",
      "Iteration 000124: OneCycleScheduler setting learning rate to 6.890723652258378e-05.\n",
      "125/343 [=========>....................] - ETA: 3:14 - loss: 0.5736 - acc: 0.7750 - kappa: 0.9236\n",
      "Iteration 000125: OneCycleScheduler setting learning rate to 6.914035939776591e-05.\n",
      "126/343 [==========>...................] - ETA: 3:14 - loss: 0.5730 - acc: 0.7748 - kappa: 0.9239\n",
      "Iteration 000126: OneCycleScheduler setting learning rate to 6.937348227294805e-05.\n",
      "127/343 [==========>...................] - ETA: 3:13 - loss: 0.5734 - acc: 0.7746 - kappa: 0.9243\n",
      "Iteration 000127: OneCycleScheduler setting learning rate to 6.960660514813017e-05.\n",
      "128/343 [==========>...................] - ETA: 3:12 - loss: 0.5726 - acc: 0.7754 - kappa: 0.9239\n",
      "Iteration 000128: OneCycleScheduler setting learning rate to 6.98397280233123e-05.\n",
      "129/343 [==========>...................] - ETA: 3:12 - loss: 0.5714 - acc: 0.7762 - kappa: 0.9242\n",
      "Iteration 000129: OneCycleScheduler setting learning rate to 7.007285089849442e-05.\n",
      "130/343 [==========>...................] - ETA: 3:11 - loss: 0.5739 - acc: 0.7750 - kappa: 0.9233\n",
      "Iteration 000130: OneCycleScheduler setting learning rate to 7.030597377367655e-05.\n",
      "131/343 [==========>...................] - ETA: 3:10 - loss: 0.5734 - acc: 0.7748 - kappa: 0.9237\n",
      "Iteration 000131: OneCycleScheduler setting learning rate to 7.053909664885867e-05.\n",
      "132/343 [==========>...................] - ETA: 3:10 - loss: 0.5747 - acc: 0.7746 - kappa: 0.9240\n",
      "Iteration 000132: OneCycleScheduler setting learning rate to 7.07722195240408e-05.\n",
      "133/343 [==========>...................] - ETA: 3:09 - loss: 0.5718 - acc: 0.7763 - kappa: 0.9246\n",
      "Iteration 000133: OneCycleScheduler setting learning rate to 7.100534239922292e-05.\n",
      "134/343 [==========>...................] - ETA: 3:08 - loss: 0.5714 - acc: 0.7761 - kappa: 0.9249\n",
      "Iteration 000134: OneCycleScheduler setting learning rate to 7.123846527440505e-05.\n",
      "135/343 [==========>...................] - ETA: 3:07 - loss: 0.5686 - acc: 0.7778 - kappa: 0.9255\n",
      "Iteration 000135: OneCycleScheduler setting learning rate to 7.147158814958719e-05.\n",
      "136/343 [==========>...................] - ETA: 3:07 - loss: 0.5697 - acc: 0.7776 - kappa: 0.9258\n",
      "Iteration 000136: OneCycleScheduler setting learning rate to 7.170471102476931e-05.\n",
      "137/343 [==========>...................] - ETA: 3:06 - loss: 0.5748 - acc: 0.7774 - kappa: 0.9254\n",
      "Iteration 000137: OneCycleScheduler setting learning rate to 7.193783389995144e-05.\n",
      "138/343 [===========>..................] - ETA: 3:06 - loss: 0.5768 - acc: 0.7763 - kappa: 0.9250\n",
      "Iteration 000138: OneCycleScheduler setting learning rate to 7.217095677513358e-05.\n",
      "139/343 [===========>..................] - ETA: 3:05 - loss: 0.5778 - acc: 0.7752 - kappa: 0.9247\n",
      "Iteration 000139: OneCycleScheduler setting learning rate to 7.24040796503157e-05.\n",
      "140/343 [===========>..................] - ETA: 3:04 - loss: 0.5745 - acc: 0.7768 - kappa: 0.9252\n",
      "Iteration 000140: OneCycleScheduler setting learning rate to 7.263720252549783e-05.\n",
      "141/343 [===========>..................] - ETA: 3:03 - loss: 0.5734 - acc: 0.7775 - kappa: 0.9257\n",
      "Iteration 000141: OneCycleScheduler setting learning rate to 7.287032540067995e-05.\n",
      "142/343 [===========>..................] - ETA: 3:02 - loss: 0.5717 - acc: 0.7782 - kappa: 0.9262\n",
      "Iteration 000142: OneCycleScheduler setting learning rate to 7.310344827586208e-05.\n",
      "143/343 [===========>..................] - ETA: 3:01 - loss: 0.5695 - acc: 0.7797 - kappa: 0.9267\n",
      "Iteration 000143: OneCycleScheduler setting learning rate to 7.33365711510442e-05.\n",
      "144/343 [===========>..................] - ETA: 3:00 - loss: 0.5698 - acc: 0.7786 - kappa: 0.9263\n",
      "Iteration 000144: OneCycleScheduler setting learning rate to 7.356969402622633e-05.\n",
      "145/343 [===========>..................] - ETA: 2:59 - loss: 0.5698 - acc: 0.7784 - kappa: 0.9263\n",
      "Iteration 000145: OneCycleScheduler setting learning rate to 7.380281690140845e-05.\n",
      "146/343 [===========>..................] - ETA: 2:59 - loss: 0.5694 - acc: 0.7791 - kappa: 0.9266\n",
      "Iteration 000146: OneCycleScheduler setting learning rate to 7.403593977659058e-05.\n",
      "147/343 [===========>..................] - ETA: 2:58 - loss: 0.5679 - acc: 0.7798 - kappa: 0.9271\n",
      "Iteration 000147: OneCycleScheduler setting learning rate to 7.42690626517727e-05.\n",
      "148/343 [===========>..................] - ETA: 2:57 - loss: 0.5692 - acc: 0.7779 - kappa: 0.9263\n",
      "Iteration 000148: OneCycleScheduler setting learning rate to 7.450218552695484e-05.\n",
      "149/343 [============>.................] - ETA: 2:56 - loss: 0.5690 - acc: 0.7785 - kappa: 0.9265\n",
      "Iteration 000149: OneCycleScheduler setting learning rate to 7.473530840213697e-05.\n",
      "150/343 [============>.................] - ETA: 2:55 - loss: 0.5687 - acc: 0.7792 - kappa: 0.9268\n",
      "Iteration 000150: OneCycleScheduler setting learning rate to 7.496843127731909e-05.\n",
      "151/343 [============>.................] - ETA: 2:54 - loss: 0.5688 - acc: 0.7798 - kappa: 0.9273\n",
      "Iteration 000151: OneCycleScheduler setting learning rate to 7.520155415250122e-05.\n",
      "152/343 [============>.................] - ETA: 2:53 - loss: 0.5666 - acc: 0.7812 - kappa: 0.9277\n",
      "Iteration 000152: OneCycleScheduler setting learning rate to 7.543467702768336e-05.\n",
      "153/343 [============>.................] - ETA: 2:52 - loss: 0.5659 - acc: 0.7819 - kappa: 0.9282\n",
      "Iteration 000153: OneCycleScheduler setting learning rate to 7.566779990286548e-05.\n",
      "154/343 [============>.................] - ETA: 2:52 - loss: 0.5772 - acc: 0.7808 - kappa: 0.9261\n",
      "Iteration 000154: OneCycleScheduler setting learning rate to 7.59009227780476e-05.\n",
      "155/343 [============>.................] - ETA: 2:50 - loss: 0.5756 - acc: 0.7815 - kappa: 0.9266\n",
      "Iteration 000155: OneCycleScheduler setting learning rate to 7.613404565322973e-05.\n",
      "156/343 [============>.................] - ETA: 2:49 - loss: 0.5760 - acc: 0.7804 - kappa: 0.9262\n",
      "Iteration 000156: OneCycleScheduler setting learning rate to 7.636716852841186e-05.\n",
      "157/343 [============>.................] - ETA: 2:48 - loss: 0.5762 - acc: 0.7787 - kappa: 0.9255\n",
      "Iteration 000157: OneCycleScheduler setting learning rate to 7.660029140359398e-05.\n",
      "158/343 [============>.................] - ETA: 2:48 - loss: 0.5752 - acc: 0.7793 - kappa: 0.9255\n",
      "Iteration 000158: OneCycleScheduler setting learning rate to 7.683341427877611e-05.\n",
      "159/343 [============>.................] - ETA: 2:47 - loss: 0.5728 - acc: 0.7807 - kappa: 0.9260\n",
      "Iteration 000159: OneCycleScheduler setting learning rate to 7.706653715395823e-05.\n",
      "160/343 [============>.................] - ETA: 2:46 - loss: 0.5732 - acc: 0.7797 - kappa: 0.9256\n",
      "Iteration 000160: OneCycleScheduler setting learning rate to 7.729966002914036e-05.\n",
      "161/343 [=============>................] - ETA: 2:45 - loss: 0.5744 - acc: 0.7795 - kappa: 0.9259\n",
      "Iteration 000161: OneCycleScheduler setting learning rate to 7.753278290432248e-05.\n",
      "162/343 [=============>................] - ETA: 2:44 - loss: 0.5724 - acc: 0.7809 - kappa: 0.9264\n",
      "Iteration 000162: OneCycleScheduler setting learning rate to 7.776590577950462e-05.\n",
      "163/343 [=============>................] - ETA: 2:43 - loss: 0.5701 - acc: 0.7822 - kappa: 0.9268\n",
      "Iteration 000163: OneCycleScheduler setting learning rate to 7.799902865468675e-05.\n",
      "164/343 [=============>................] - ETA: 2:43 - loss: 0.5697 - acc: 0.7820 - kappa: 0.9268\n",
      "Iteration 000164: OneCycleScheduler setting learning rate to 7.823215152986887e-05.\n",
      "165/343 [=============>................] - ETA: 2:42 - loss: 0.5674 - acc: 0.7833 - kappa: 0.9273\n",
      "Iteration 000165: OneCycleScheduler setting learning rate to 7.846527440505101e-05.\n",
      "166/343 [=============>................] - ETA: 2:41 - loss: 0.5665 - acc: 0.7839 - kappa: 0.9275\n",
      "Iteration 000166: OneCycleScheduler setting learning rate to 7.869839728023314e-05.\n",
      "167/343 [=============>................] - ETA: 2:40 - loss: 0.5683 - acc: 0.7829 - kappa: 0.9272\n",
      "Iteration 000167: OneCycleScheduler setting learning rate to 7.893152015541526e-05.\n",
      "168/343 [=============>................] - ETA: 2:40 - loss: 0.5685 - acc: 0.7827 - kappa: 0.9275\n",
      "Iteration 000168: OneCycleScheduler setting learning rate to 7.916464303059739e-05.\n",
      "169/343 [=============>................] - ETA: 2:39 - loss: 0.5705 - acc: 0.7825 - kappa: 0.9277\n",
      "Iteration 000169: OneCycleScheduler setting learning rate to 7.939776590577951e-05.\n",
      "170/343 [=============>................] - ETA: 2:38 - loss: 0.5685 - acc: 0.7838 - kappa: 0.9281\n",
      "Iteration 000170: OneCycleScheduler setting learning rate to 7.963088878096164e-05.\n",
      "171/343 [=============>................] - ETA: 2:37 - loss: 0.5707 - acc: 0.7822 - kappa: 0.9274\n",
      "Iteration 000171: OneCycleScheduler setting learning rate to 7.986401165614376e-05.\n",
      "172/343 [==============>...............] - ETA: 2:36 - loss: 0.5696 - acc: 0.7827 - kappa: 0.9278\n",
      "Iteration 000172: OneCycleScheduler setting learning rate to 8.009713453132589e-05.\n",
      "173/343 [==============>...............] - ETA: 2:35 - loss: 0.5708 - acc: 0.7832 - kappa: 0.9282\n",
      "Iteration 000173: OneCycleScheduler setting learning rate to 8.033025740650801e-05.\n",
      "174/343 [==============>...............] - ETA: 2:34 - loss: 0.5682 - acc: 0.7845 - kappa: 0.9286\n",
      "Iteration 000174: OneCycleScheduler setting learning rate to 8.056338028169014e-05.\n",
      "175/343 [==============>...............] - ETA: 2:33 - loss: 0.5683 - acc: 0.7843 - kappa: 0.9286\n",
      "Iteration 000175: OneCycleScheduler setting learning rate to 8.079650315687228e-05.\n",
      "176/343 [==============>...............] - ETA: 2:32 - loss: 0.5667 - acc: 0.7855 - kappa: 0.9290\n",
      "Iteration 000176: OneCycleScheduler setting learning rate to 8.10296260320544e-05.\n",
      "177/343 [==============>...............] - ETA: 2:31 - loss: 0.5672 - acc: 0.7860 - kappa: 0.9292\n",
      "Iteration 000177: OneCycleScheduler setting learning rate to 8.126274890723653e-05.\n",
      "178/343 [==============>...............] - ETA: 2:31 - loss: 0.5678 - acc: 0.7858 - kappa: 0.9294\n",
      "Iteration 000178: OneCycleScheduler setting learning rate to 8.149587178241867e-05.\n",
      "179/343 [==============>...............] - ETA: 2:30 - loss: 0.5680 - acc: 0.7849 - kappa: 0.9287\n",
      "Iteration 000179: OneCycleScheduler setting learning rate to 8.172899465760079e-05.\n",
      "180/343 [==============>...............] - ETA: 2:29 - loss: 0.5667 - acc: 0.7854 - kappa: 0.9291\n",
      "Iteration 000180: OneCycleScheduler setting learning rate to 8.196211753278292e-05.\n",
      "181/343 [==============>...............] - ETA: 2:28 - loss: 0.5652 - acc: 0.7866 - kappa: 0.9295\n",
      "Iteration 000181: OneCycleScheduler setting learning rate to 8.219524040796504e-05.\n",
      "182/343 [==============>...............] - ETA: 2:27 - loss: 0.5664 - acc: 0.7850 - kappa: 0.9278\n",
      "Iteration 000182: OneCycleScheduler setting learning rate to 8.242836328314717e-05.\n",
      "183/343 [===============>..............] - ETA: 2:27 - loss: 0.5643 - acc: 0.7862 - kappa: 0.9282\n",
      "Iteration 000183: OneCycleScheduler setting learning rate to 8.266148615832929e-05.\n",
      "184/343 [===============>..............] - ETA: 2:26 - loss: 0.5628 - acc: 0.7867 - kappa: 0.9285\n",
      "Iteration 000184: OneCycleScheduler setting learning rate to 8.289460903351142e-05.\n",
      "185/343 [===============>..............] - ETA: 2:25 - loss: 0.5618 - acc: 0.7865 - kappa: 0.9282\n",
      "Iteration 000185: OneCycleScheduler setting learning rate to 8.312773190869354e-05.\n",
      "186/343 [===============>..............] - ETA: 2:24 - loss: 0.5605 - acc: 0.7863 - kappa: 0.9282\n",
      "Iteration 000186: OneCycleScheduler setting learning rate to 8.336085478387567e-05.\n",
      "187/343 [===============>..............] - ETA: 2:23 - loss: 0.5594 - acc: 0.7868 - kappa: 0.9286\n",
      "Iteration 000187: OneCycleScheduler setting learning rate to 8.359397765905779e-05.\n",
      "188/343 [===============>..............] - ETA: 2:22 - loss: 0.5580 - acc: 0.7866 - kappa: 0.9288\n",
      "Iteration 000188: OneCycleScheduler setting learning rate to 8.382710053423993e-05.\n",
      "189/343 [===============>..............] - ETA: 2:21 - loss: 0.5566 - acc: 0.7870 - kappa: 0.9290\n",
      "Iteration 000189: OneCycleScheduler setting learning rate to 8.406022340942206e-05.\n",
      "190/343 [===============>..............] - ETA: 2:20 - loss: 0.5600 - acc: 0.7862 - kappa: 0.9273\n",
      "Iteration 000190: OneCycleScheduler setting learning rate to 8.429334628460418e-05.\n",
      "191/343 [===============>..............] - ETA: 2:19 - loss: 0.5607 - acc: 0.7860 - kappa: 0.9274\n",
      "Iteration 000191: OneCycleScheduler setting learning rate to 8.452646915978631e-05.\n",
      "192/343 [===============>..............] - ETA: 2:19 - loss: 0.5590 - acc: 0.7865 - kappa: 0.9277\n",
      "Iteration 000192: OneCycleScheduler setting learning rate to 8.475959203496845e-05.\n",
      "193/343 [===============>..............] - ETA: 2:18 - loss: 0.5600 - acc: 0.7856 - kappa: 0.9274\n",
      "Iteration 000193: OneCycleScheduler setting learning rate to 8.499271491015057e-05.\n",
      "194/343 [===============>..............] - ETA: 2:17 - loss: 0.5586 - acc: 0.7861 - kappa: 0.9278\n",
      "Iteration 000194: OneCycleScheduler setting learning rate to 8.52258377853327e-05.\n",
      "195/343 [================>.............] - ETA: 2:16 - loss: 0.5564 - acc: 0.7865 - kappa: 0.9281\n",
      "Iteration 000195: OneCycleScheduler setting learning rate to 8.545896066051482e-05.\n",
      "196/343 [================>.............] - ETA: 2:15 - loss: 0.5549 - acc: 0.7870 - kappa: 0.9283\n",
      "Iteration 000196: OneCycleScheduler setting learning rate to 8.569208353569695e-05.\n",
      "197/343 [================>.............] - ETA: 2:14 - loss: 0.5533 - acc: 0.7874 - kappa: 0.9286\n",
      "Iteration 000197: OneCycleScheduler setting learning rate to 8.592520641087907e-05.\n",
      "198/343 [================>.............] - ETA: 2:13 - loss: 0.5510 - acc: 0.7885 - kappa: 0.9290\n",
      "Iteration 000198: OneCycleScheduler setting learning rate to 8.61583292860612e-05.\n",
      "199/343 [================>.............] - ETA: 2:12 - loss: 0.5517 - acc: 0.7877 - kappa: 0.9290\n",
      "Iteration 000199: OneCycleScheduler setting learning rate to 8.639145216124332e-05.\n",
      "200/343 [================>.............] - ETA: 2:11 - loss: 0.5532 - acc: 0.7875 - kappa: 0.9287\n",
      "Iteration 000200: OneCycleScheduler setting learning rate to 8.662457503642545e-05.\n",
      "201/343 [================>.............] - ETA: 2:10 - loss: 0.5547 - acc: 0.7867 - kappa: 0.9284\n",
      "Iteration 000201: OneCycleScheduler setting learning rate to 8.685769791160757e-05.\n",
      "202/343 [================>.............] - ETA: 2:09 - loss: 0.5552 - acc: 0.7859 - kappa: 0.9284\n",
      "Iteration 000202: OneCycleScheduler setting learning rate to 8.709082078678971e-05.\n",
      "203/343 [================>.............] - ETA: 2:08 - loss: 0.5551 - acc: 0.7851 - kappa: 0.9285\n",
      "Iteration 000203: OneCycleScheduler setting learning rate to 8.732394366197184e-05.\n",
      "204/343 [================>.............] - ETA: 2:08 - loss: 0.5568 - acc: 0.7849 - kappa: 0.9287\n",
      "Iteration 000204: OneCycleScheduler setting learning rate to 8.755706653715396e-05.\n",
      "205/343 [================>.............] - ETA: 2:07 - loss: 0.5568 - acc: 0.7854 - kappa: 0.9288\n",
      "Iteration 000205: OneCycleScheduler setting learning rate to 8.77901894123361e-05.\n",
      "206/343 [=================>............] - ETA: 2:06 - loss: 0.5589 - acc: 0.7846 - kappa: 0.9286\n",
      "Iteration 000206: OneCycleScheduler setting learning rate to 8.802331228751823e-05.\n",
      "207/343 [=================>............] - ETA: 2:06 - loss: 0.5619 - acc: 0.7838 - kappa: 0.9276\n",
      "Iteration 000207: OneCycleScheduler setting learning rate to 8.825643516270035e-05.\n",
      "208/343 [=================>............] - ETA: 2:05 - loss: 0.5625 - acc: 0.7837 - kappa: 0.9278\n",
      "Iteration 000208: OneCycleScheduler setting learning rate to 8.848955803788248e-05.\n",
      "209/343 [=================>............] - ETA: 2:03 - loss: 0.5624 - acc: 0.7835 - kappa: 0.9278\n",
      "Iteration 000209: OneCycleScheduler setting learning rate to 8.87226809130646e-05.\n",
      "210/343 [=================>............] - ETA: 2:02 - loss: 0.5627 - acc: 0.7833 - kappa: 0.9280\n",
      "Iteration 000210: OneCycleScheduler setting learning rate to 8.895580378824673e-05.\n",
      "211/343 [=================>............] - ETA: 2:02 - loss: 0.5605 - acc: 0.7844 - kappa: 0.9283\n",
      "Iteration 000211: OneCycleScheduler setting learning rate to 8.918892666342885e-05.\n",
      "212/343 [=================>............] - ETA: 2:01 - loss: 0.5620 - acc: 0.7842 - kappa: 0.9281\n",
      "Iteration 000212: OneCycleScheduler setting learning rate to 8.942204953861098e-05.\n",
      "213/343 [=================>............] - ETA: 2:00 - loss: 0.5607 - acc: 0.7846 - kappa: 0.9284\n",
      "Iteration 000213: OneCycleScheduler setting learning rate to 8.96551724137931e-05.\n",
      "214/343 [=================>............] - ETA: 1:59 - loss: 0.5608 - acc: 0.7845 - kappa: 0.9284\n",
      "Iteration 000214: OneCycleScheduler setting learning rate to 8.988829528897523e-05.\n",
      "215/343 [=================>............] - ETA: 1:58 - loss: 0.5599 - acc: 0.7843 - kappa: 0.9286\n",
      "Iteration 000215: OneCycleScheduler setting learning rate to 9.012141816415737e-05.\n",
      "216/343 [=================>............] - ETA: 1:57 - loss: 0.5611 - acc: 0.7836 - kappa: 0.9283\n",
      "Iteration 000216: OneCycleScheduler setting learning rate to 9.035454103933949e-05.\n",
      "217/343 [=================>............] - ETA: 1:56 - loss: 0.5592 - acc: 0.7846 - kappa: 0.9286\n",
      "Iteration 000217: OneCycleScheduler setting learning rate to 9.058766391452162e-05.\n",
      "218/343 [==================>...........] - ETA: 1:55 - loss: 0.5578 - acc: 0.7856 - kappa: 0.9290\n",
      "Iteration 000218: OneCycleScheduler setting learning rate to 9.082078678970376e-05.\n",
      "219/343 [==================>...........] - ETA: 1:54 - loss: 0.5572 - acc: 0.7860 - kappa: 0.9292\n",
      "Iteration 000219: OneCycleScheduler setting learning rate to 9.105390966488588e-05.\n",
      "220/343 [==================>...........] - ETA: 1:54 - loss: 0.5558 - acc: 0.7864 - kappa: 0.9293\n",
      "Iteration 000220: OneCycleScheduler setting learning rate to 9.1287032540068e-05.\n",
      "221/343 [==================>...........] - ETA: 1:53 - loss: 0.5568 - acc: 0.7862 - kappa: 0.9293\n",
      "Iteration 000221: OneCycleScheduler setting learning rate to 9.152015541525013e-05.\n",
      "222/343 [==================>...........] - ETA: 1:52 - loss: 0.5560 - acc: 0.7866 - kappa: 0.9295\n",
      "Iteration 000222: OneCycleScheduler setting learning rate to 9.175327829043226e-05.\n",
      "223/343 [==================>...........] - ETA: 1:51 - loss: 0.5549 - acc: 0.7870 - kappa: 0.9297\n",
      "Iteration 000223: OneCycleScheduler setting learning rate to 9.198640116561438e-05.\n",
      "224/343 [==================>...........] - ETA: 1:50 - loss: 0.5537 - acc: 0.7879 - kappa: 0.9300\n",
      "Iteration 000224: OneCycleScheduler setting learning rate to 9.221952404079651e-05.\n",
      "225/343 [==================>...........] - ETA: 1:49 - loss: 0.5550 - acc: 0.7872 - kappa: 0.9298\n",
      "Iteration 000225: OneCycleScheduler setting learning rate to 9.245264691597863e-05.\n",
      "226/343 [==================>...........] - ETA: 1:48 - loss: 0.5580 - acc: 0.7865 - kappa: 0.9292\n",
      "Iteration 000226: OneCycleScheduler setting learning rate to 9.268576979116076e-05.\n",
      "227/343 [==================>...........] - ETA: 1:47 - loss: 0.5575 - acc: 0.7869 - kappa: 0.9295\n",
      "Iteration 000227: OneCycleScheduler setting learning rate to 9.291889266634288e-05.\n",
      "228/343 [==================>...........] - ETA: 1:46 - loss: 0.5568 - acc: 0.7873 - kappa: 0.9297\n",
      "Iteration 000228: OneCycleScheduler setting learning rate to 9.315201554152502e-05.\n",
      "229/343 [===================>..........] - ETA: 1:46 - loss: 0.5571 - acc: 0.7877 - kappa: 0.9299\n",
      "Iteration 000229: OneCycleScheduler setting learning rate to 9.338513841670715e-05.\n",
      "230/343 [===================>..........] - ETA: 1:45 - loss: 0.5591 - acc: 0.7870 - kappa: 0.9290\n",
      "Iteration 000230: OneCycleScheduler setting learning rate to 9.361826129188927e-05.\n",
      "231/343 [===================>..........] - ETA: 1:44 - loss: 0.5581 - acc: 0.7873 - kappa: 0.9293\n",
      "Iteration 000231: OneCycleScheduler setting learning rate to 9.38513841670714e-05.\n",
      "232/343 [===================>..........] - ETA: 1:43 - loss: 0.5591 - acc: 0.7872 - kappa: 0.9295\n",
      "Iteration 000232: OneCycleScheduler setting learning rate to 9.408450704225354e-05.\n",
      "233/343 [===================>..........] - ETA: 1:42 - loss: 0.5591 - acc: 0.7876 - kappa: 0.9297\n",
      "Iteration 000233: OneCycleScheduler setting learning rate to 9.431762991743566e-05.\n",
      "234/343 [===================>..........] - ETA: 1:41 - loss: 0.5595 - acc: 0.7874 - kappa: 0.9297\n",
      "Iteration 000234: OneCycleScheduler setting learning rate to 9.455075279261779e-05.\n",
      "235/343 [===================>..........] - ETA: 1:40 - loss: 0.5586 - acc: 0.7878 - kappa: 0.9299\n",
      "Iteration 000235: OneCycleScheduler setting learning rate to 9.478387566779991e-05.\n",
      "236/343 [===================>..........] - ETA: 1:39 - loss: 0.5568 - acc: 0.7887 - kappa: 0.9302\n",
      "Iteration 000236: OneCycleScheduler setting learning rate to 9.501699854298204e-05.\n",
      "237/343 [===================>..........] - ETA: 1:38 - loss: 0.5567 - acc: 0.7885 - kappa: 0.9302\n",
      "Iteration 000237: OneCycleScheduler setting learning rate to 9.525012141816416e-05.\n",
      "238/343 [===================>..........] - ETA: 1:37 - loss: 0.5551 - acc: 0.7889 - kappa: 0.9304\n",
      "Iteration 000238: OneCycleScheduler setting learning rate to 9.548324429334629e-05.\n",
      "239/343 [===================>..........] - ETA: 1:36 - loss: 0.5551 - acc: 0.7887 - kappa: 0.9306\n",
      "Iteration 000239: OneCycleScheduler setting learning rate to 9.571636716852841e-05.\n",
      "240/343 [===================>..........] - ETA: 1:35 - loss: 0.5537 - acc: 0.7896 - kappa: 0.9309\n",
      "Iteration 000240: OneCycleScheduler setting learning rate to 9.594949004371054e-05.\n",
      "241/343 [====================>.........] - ETA: 1:34 - loss: 0.5525 - acc: 0.7899 - kappa: 0.9311\n",
      "Iteration 000241: OneCycleScheduler setting learning rate to 9.618261291889266e-05.\n",
      "242/343 [====================>.........] - ETA: 1:33 - loss: 0.5532 - acc: 0.7893 - kappa: 0.9309\n",
      "Iteration 000242: OneCycleScheduler setting learning rate to 9.64157357940748e-05.\n",
      "243/343 [====================>.........] - ETA: 1:33 - loss: 0.5512 - acc: 0.7901 - kappa: 0.9312\n",
      "Iteration 000243: OneCycleScheduler setting learning rate to 9.664885866925693e-05.\n",
      "244/343 [====================>.........] - ETA: 1:32 - loss: 0.5505 - acc: 0.7910 - kappa: 0.9315\n",
      "Iteration 000244: OneCycleScheduler setting learning rate to 9.688198154443905e-05.\n",
      "245/343 [====================>.........] - ETA: 1:31 - loss: 0.5487 - acc: 0.7918 - kappa: 0.9318\n",
      "Iteration 000245: OneCycleScheduler setting learning rate to 9.711510441962119e-05.\n",
      "246/343 [====================>.........] - ETA: 1:30 - loss: 0.5477 - acc: 0.7922 - kappa: 0.9319\n",
      "Iteration 000246: OneCycleScheduler setting learning rate to 9.734822729480332e-05.\n",
      "247/343 [====================>.........] - ETA: 1:29 - loss: 0.5468 - acc: 0.7925 - kappa: 0.9322\n",
      "Iteration 000247: OneCycleScheduler setting learning rate to 9.758135016998544e-05.\n",
      "248/343 [====================>.........] - ETA: 1:28 - loss: 0.5454 - acc: 0.7928 - kappa: 0.9323\n",
      "Iteration 000248: OneCycleScheduler setting learning rate to 9.781447304516757e-05.\n",
      "249/343 [====================>.........] - ETA: 1:27 - loss: 0.5446 - acc: 0.7937 - kappa: 0.9326\n",
      "Iteration 000249: OneCycleScheduler setting learning rate to 9.804759592034969e-05.\n",
      "250/343 [====================>.........] - ETA: 1:26 - loss: 0.5448 - acc: 0.7930 - kappa: 0.9323\n",
      "Iteration 000250: OneCycleScheduler setting learning rate to 9.828071879553182e-05.\n",
      "251/343 [====================>.........] - ETA: 1:26 - loss: 0.5448 - acc: 0.7928 - kappa: 0.9325\n",
      "Iteration 000251: OneCycleScheduler setting learning rate to 9.851384167071394e-05.\n",
      "252/343 [=====================>........] - ETA: 1:25 - loss: 0.5467 - acc: 0.7927 - kappa: 0.9326\n",
      "Iteration 000252: OneCycleScheduler setting learning rate to 9.874696454589607e-05.\n",
      "253/343 [=====================>........] - ETA: 1:24 - loss: 0.5448 - acc: 0.7935 - kappa: 0.9329\n",
      "Iteration 000253: OneCycleScheduler setting learning rate to 9.89800874210782e-05.\n",
      "254/343 [=====================>........] - ETA: 1:23 - loss: 0.5438 - acc: 0.7933 - kappa: 0.9329\n",
      "Iteration 000254: OneCycleScheduler setting learning rate to 9.921321029626032e-05.\n",
      "255/343 [=====================>........] - ETA: 1:22 - loss: 0.5440 - acc: 0.7936 - kappa: 0.9331\n",
      "Iteration 000255: OneCycleScheduler setting learning rate to 9.944633317144246e-05.\n",
      "256/343 [=====================>........] - ETA: 1:21 - loss: 0.5424 - acc: 0.7944 - kappa: 0.9334\n",
      "Iteration 000256: OneCycleScheduler setting learning rate to 9.967945604662458e-05.\n",
      "257/343 [=====================>........] - ETA: 1:20 - loss: 0.5425 - acc: 0.7943 - kappa: 0.9335\n",
      "Iteration 000257: OneCycleScheduler setting learning rate to 9.991257892180671e-05.\n",
      "258/343 [=====================>........] - ETA: 1:19 - loss: 0.5425 - acc: 0.7941 - kappa: 0.9337\n",
      "Iteration 000258: OneCycleScheduler setting learning rate to 0.00010014570179698885.\n",
      "259/343 [=====================>........] - ETA: 1:18 - loss: 0.5440 - acc: 0.7939 - kappa: 0.9338\n",
      "Iteration 000259: OneCycleScheduler setting learning rate to 0.00010037882467217097.\n",
      "260/343 [=====================>........] - ETA: 1:17 - loss: 0.5427 - acc: 0.7942 - kappa: 0.9340\n",
      "Iteration 000260: OneCycleScheduler setting learning rate to 0.0001006119475473531.\n",
      "261/343 [=====================>........] - ETA: 1:16 - loss: 0.5423 - acc: 0.7945 - kappa: 0.9342\n",
      "Iteration 000261: OneCycleScheduler setting learning rate to 0.00010084507042253522.\n",
      "262/343 [=====================>........] - ETA: 1:15 - loss: 0.5421 - acc: 0.7948 - kappa: 0.9345\n",
      "Iteration 000262: OneCycleScheduler setting learning rate to 0.00010107819329771735.\n",
      "263/343 [======================>.......] - ETA: 1:14 - loss: 0.5437 - acc: 0.7942 - kappa: 0.9342\n",
      "Iteration 000263: OneCycleScheduler setting learning rate to 0.00010131131617289947.\n",
      "264/343 [======================>.......] - ETA: 1:13 - loss: 0.5427 - acc: 0.7945 - kappa: 0.9345\n",
      "Iteration 000264: OneCycleScheduler setting learning rate to 0.0001015444390480816.\n",
      "265/343 [======================>.......] - ETA: 1:12 - loss: 0.5413 - acc: 0.7953 - kappa: 0.9347\n",
      "Iteration 000265: OneCycleScheduler setting learning rate to 0.00010177756192326372.\n",
      "266/343 [======================>.......] - ETA: 1:11 - loss: 0.5403 - acc: 0.7956 - kappa: 0.9349\n",
      "Iteration 000266: OneCycleScheduler setting learning rate to 0.00010201068479844585.\n",
      "267/343 [======================>.......] - ETA: 1:10 - loss: 0.5396 - acc: 0.7959 - kappa: 0.9350\n",
      "Iteration 000267: OneCycleScheduler setting learning rate to 0.00010224380767362797.\n",
      "268/343 [======================>.......] - ETA: 1:10 - loss: 0.5422 - acc: 0.7952 - kappa: 0.9348\n",
      "Iteration 000268: OneCycleScheduler setting learning rate to 0.0001024769305488101.\n",
      "269/343 [======================>.......] - ETA: 1:09 - loss: 0.5433 - acc: 0.7946 - kappa: 0.9343\n",
      "Iteration 000269: OneCycleScheduler setting learning rate to 0.00010271005342399222.\n",
      "270/343 [======================>.......] - ETA: 1:08 - loss: 0.5468 - acc: 0.7940 - kappa: 0.9343\n",
      "Iteration 000270: OneCycleScheduler setting learning rate to 0.00010294317629917438.\n",
      "271/343 [======================>.......] - ETA: 1:07 - loss: 0.5483 - acc: 0.7938 - kappa: 0.9344\n",
      "Iteration 000271: OneCycleScheduler setting learning rate to 0.0001031762991743565.\n",
      "272/343 [======================>.......] - ETA: 1:06 - loss: 0.5470 - acc: 0.7946 - kappa: 0.9347\n",
      "Iteration 000272: OneCycleScheduler setting learning rate to 0.00010340942204953863.\n",
      "273/343 [======================>.......] - ETA: 1:05 - loss: 0.5510 - acc: 0.7944 - kappa: 0.9348\n",
      "Iteration 000273: OneCycleScheduler setting learning rate to 0.00010364254492472075.\n",
      "274/343 [======================>.......] - ETA: 1:04 - loss: 0.5495 - acc: 0.7952 - kappa: 0.9350\n",
      "Iteration 000274: OneCycleScheduler setting learning rate to 0.00010387566779990288.\n",
      "275/343 [=======================>......] - ETA: 1:03 - loss: 0.5479 - acc: 0.7959 - kappa: 0.9353\n",
      "Iteration 000275: OneCycleScheduler setting learning rate to 0.000104108790675085.\n",
      "276/343 [=======================>......] - ETA: 1:02 - loss: 0.5480 - acc: 0.7957 - kappa: 0.9351\n",
      "Iteration 000276: OneCycleScheduler setting learning rate to 0.00010434191355026713.\n",
      "277/343 [=======================>......] - ETA: 1:01 - loss: 0.5478 - acc: 0.7965 - kappa: 0.9353\n",
      "Iteration 000277: OneCycleScheduler setting learning rate to 0.00010457503642544925.\n",
      "278/343 [=======================>......] - ETA: 1:00 - loss: 0.5488 - acc: 0.7968 - kappa: 0.9355\n",
      "Iteration 000278: OneCycleScheduler setting learning rate to 0.00010480815930063138.\n",
      "279/343 [=======================>......] - ETA: 1:00 - loss: 0.5476 - acc: 0.7970 - kappa: 0.9357\n",
      "Iteration 000279: OneCycleScheduler setting learning rate to 0.0001050412821758135.\n",
      "280/343 [=======================>......] - ETA: 59s - loss: 0.5466 - acc: 0.7978 - kappa: 0.9359 \n",
      "Iteration 000280: OneCycleScheduler setting learning rate to 0.00010527440505099563.\n",
      "281/343 [=======================>......] - ETA: 58s - loss: 0.5462 - acc: 0.7976 - kappa: 0.9361\n",
      "Iteration 000281: OneCycleScheduler setting learning rate to 0.00010550752792617775.\n",
      "282/343 [=======================>......] - ETA: 57s - loss: 0.5451 - acc: 0.7983 - kappa: 0.9363\n",
      "Iteration 000282: OneCycleScheduler setting learning rate to 0.00010574065080135988.\n",
      "283/343 [=======================>......] - ETA: 56s - loss: 0.5446 - acc: 0.7981 - kappa: 0.9363\n",
      "Iteration 000283: OneCycleScheduler setting learning rate to 0.00010597377367654203.\n",
      "284/343 [=======================>......] - ETA: 55s - loss: 0.5459 - acc: 0.7975 - kappa: 0.9358\n",
      "Iteration 000284: OneCycleScheduler setting learning rate to 0.00010620689655172416.\n",
      "285/343 [=======================>......] - ETA: 54s - loss: 0.5461 - acc: 0.7974 - kappa: 0.9358\n",
      "Iteration 000285: OneCycleScheduler setting learning rate to 0.00010644001942690628.\n",
      "286/343 [========================>.....] - ETA: 53s - loss: 0.5482 - acc: 0.7955 - kappa: 0.9350\n",
      "Iteration 000286: OneCycleScheduler setting learning rate to 0.00010667314230208841.\n",
      "287/343 [========================>.....] - ETA: 52s - loss: 0.5503 - acc: 0.7949 - kappa: 0.9339\n",
      "Iteration 000287: OneCycleScheduler setting learning rate to 0.00010690626517727053.\n",
      "288/343 [========================>.....] - ETA: 51s - loss: 0.5492 - acc: 0.7951 - kappa: 0.9341\n",
      "Iteration 000288: OneCycleScheduler setting learning rate to 0.00010713938805245266.\n",
      "289/343 [========================>.....] - ETA: 50s - loss: 0.5498 - acc: 0.7946 - kappa: 0.9339\n",
      "Iteration 000289: OneCycleScheduler setting learning rate to 0.00010737251092763478.\n",
      "290/343 [========================>.....] - ETA: 49s - loss: 0.5518 - acc: 0.7944 - kappa: 0.9337\n",
      "Iteration 000290: OneCycleScheduler setting learning rate to 0.00010760563380281691.\n",
      "291/343 [========================>.....] - ETA: 48s - loss: 0.5505 - acc: 0.7951 - kappa: 0.9339\n",
      "Iteration 000291: OneCycleScheduler setting learning rate to 0.00010783875667799903.\n",
      "292/343 [========================>.....] - ETA: 47s - loss: 0.5495 - acc: 0.7954 - kappa: 0.9341\n",
      "Iteration 000292: OneCycleScheduler setting learning rate to 0.00010807187955318116.\n",
      "293/343 [========================>.....] - ETA: 46s - loss: 0.5495 - acc: 0.7948 - kappa: 0.9341\n",
      "Iteration 000293: OneCycleScheduler setting learning rate to 0.00010830500242836328.\n",
      "294/343 [========================>.....] - ETA: 46s - loss: 0.5491 - acc: 0.7946 - kappa: 0.9342\n",
      "Iteration 000294: OneCycleScheduler setting learning rate to 0.00010853812530354541.\n",
      "295/343 [========================>.....] - ETA: 45s - loss: 0.5478 - acc: 0.7953 - kappa: 0.9345\n",
      "Iteration 000295: OneCycleScheduler setting learning rate to 0.00010877124817872753.\n",
      "296/343 [========================>.....] - ETA: 44s - loss: 0.5473 - acc: 0.7952 - kappa: 0.9344\n",
      "Iteration 000296: OneCycleScheduler setting learning rate to 0.00010900437105390969.\n",
      "297/343 [========================>.....] - ETA: 43s - loss: 0.5490 - acc: 0.7942 - kappa: 0.9340\n",
      "Iteration 000297: OneCycleScheduler setting learning rate to 0.00010923749392909181.\n",
      "298/343 [=========================>....] - ETA: 42s - loss: 0.5486 - acc: 0.7945 - kappa: 0.9342\n",
      "Iteration 000298: OneCycleScheduler setting learning rate to 0.00010947061680427394.\n",
      "299/343 [=========================>....] - ETA: 41s - loss: 0.5495 - acc: 0.7939 - kappa: 0.9342\n",
      "Iteration 000299: OneCycleScheduler setting learning rate to 0.00010970373967945606.\n",
      "300/343 [=========================>....] - ETA: 40s - loss: 0.5518 - acc: 0.7925 - kappa: 0.9335\n",
      "Iteration 000300: OneCycleScheduler setting learning rate to 0.00010993686255463819.\n",
      "301/343 [=========================>....] - ETA: 39s - loss: 0.5520 - acc: 0.7924 - kappa: 0.9336\n",
      "Iteration 000301: OneCycleScheduler setting learning rate to 0.00011016998542982031.\n",
      "302/343 [=========================>....] - ETA: 38s - loss: 0.5519 - acc: 0.7922 - kappa: 0.9334\n",
      "Iteration 000302: OneCycleScheduler setting learning rate to 0.00011040310830500244.\n",
      "303/343 [=========================>....] - ETA: 37s - loss: 0.5515 - acc: 0.7925 - kappa: 0.9336\n",
      "Iteration 000303: OneCycleScheduler setting learning rate to 0.00011063623118018456.\n",
      "304/343 [=========================>....] - ETA: 36s - loss: 0.5512 - acc: 0.7924 - kappa: 0.9337\n",
      "Iteration 000304: OneCycleScheduler setting learning rate to 0.00011086935405536669.\n",
      "305/343 [=========================>....] - ETA: 35s - loss: 0.5504 - acc: 0.7926 - kappa: 0.9339\n",
      "Iteration 000305: OneCycleScheduler setting learning rate to 0.00011110247693054881.\n",
      "306/343 [=========================>....] - ETA: 34s - loss: 0.5505 - acc: 0.7925 - kappa: 0.9339\n",
      "Iteration 000306: OneCycleScheduler setting learning rate to 0.00011133559980573094.\n",
      "307/343 [=========================>....] - ETA: 33s - loss: 0.5494 - acc: 0.7932 - kappa: 0.9341\n",
      "Iteration 000307: OneCycleScheduler setting learning rate to 0.00011156872268091306.\n",
      "308/343 [=========================>....] - ETA: 32s - loss: 0.5491 - acc: 0.7938 - kappa: 0.9343\n",
      "Iteration 000308: OneCycleScheduler setting learning rate to 0.00011180184555609519.\n",
      "309/343 [==========================>...] - ETA: 31s - loss: 0.5485 - acc: 0.7937 - kappa: 0.9343\n",
      "Iteration 000309: OneCycleScheduler setting learning rate to 0.00011203496843127731.\n",
      "310/343 [==========================>...] - ETA: 31s - loss: 0.5475 - acc: 0.7944 - kappa: 0.9345\n",
      "Iteration 000310: OneCycleScheduler setting learning rate to 0.00011226809130645947.\n",
      "311/343 [==========================>...] - ETA: 30s - loss: 0.5482 - acc: 0.7942 - kappa: 0.9346\n",
      "Iteration 000311: OneCycleScheduler setting learning rate to 0.00011250121418164159.\n",
      "312/343 [==========================>...] - ETA: 29s - loss: 0.5471 - acc: 0.7949 - kappa: 0.9348\n",
      "Iteration 000312: OneCycleScheduler setting learning rate to 0.00011273433705682372.\n",
      "313/343 [==========================>...] - ETA: 28s - loss: 0.5466 - acc: 0.7947 - kappa: 0.9346\n",
      "Iteration 000313: OneCycleScheduler setting learning rate to 0.00011296745993200584.\n",
      "314/343 [==========================>...] - ETA: 27s - loss: 0.5478 - acc: 0.7938 - kappa: 0.9339\n",
      "Iteration 000314: OneCycleScheduler setting learning rate to 0.00011320058280718797.\n",
      "315/343 [==========================>...] - ETA: 26s - loss: 0.5500 - acc: 0.7929 - kappa: 0.9335\n",
      "Iteration 000315: OneCycleScheduler setting learning rate to 0.00011343370568237009.\n",
      "316/343 [==========================>...] - ETA: 25s - loss: 0.5499 - acc: 0.7927 - kappa: 0.9336\n",
      "Iteration 000316: OneCycleScheduler setting learning rate to 0.00011366682855755222.\n",
      "317/343 [==========================>...] - ETA: 24s - loss: 0.5490 - acc: 0.7930 - kappa: 0.9338\n",
      "Iteration 000317: OneCycleScheduler setting learning rate to 0.00011389995143273434.\n",
      "318/343 [==========================>...] - ETA: 23s - loss: 0.5494 - acc: 0.7928 - kappa: 0.9339\n",
      "Iteration 000318: OneCycleScheduler setting learning rate to 0.00011413307430791647.\n",
      "319/343 [==========================>...] - ETA: 22s - loss: 0.5499 - acc: 0.7927 - kappa: 0.9340\n",
      "Iteration 000319: OneCycleScheduler setting learning rate to 0.0001143661971830986.\n",
      "320/343 [==========================>...] - ETA: 21s - loss: 0.5509 - acc: 0.7926 - kappa: 0.9342\n",
      "Iteration 000320: OneCycleScheduler setting learning rate to 0.00011459932005828072.\n",
      "321/343 [===========================>..] - ETA: 20s - loss: 0.5500 - acc: 0.7932 - kappa: 0.9344\n",
      "Iteration 000321: OneCycleScheduler setting learning rate to 0.00011483244293346284.\n",
      "322/343 [===========================>..] - ETA: 19s - loss: 0.5495 - acc: 0.7939 - kappa: 0.9346\n",
      "Iteration 000322: OneCycleScheduler setting learning rate to 0.00011506556580864497.\n",
      "323/343 [===========================>..] - ETA: 18s - loss: 0.5485 - acc: 0.7941 - kappa: 0.9347\n",
      "Iteration 000323: OneCycleScheduler setting learning rate to 0.00011529868868382712.\n",
      "324/343 [===========================>..] - ETA: 17s - loss: 0.5480 - acc: 0.7944 - kappa: 0.9349\n",
      "Iteration 000324: OneCycleScheduler setting learning rate to 0.00011553181155900925.\n",
      "325/343 [===========================>..] - ETA: 17s - loss: 0.5465 - acc: 0.7950 - kappa: 0.9351\n",
      "Iteration 000325: OneCycleScheduler setting learning rate to 0.00011576493443419137.\n",
      "326/343 [===========================>..] - ETA: 16s - loss: 0.5466 - acc: 0.7945 - kappa: 0.9351\n",
      "Iteration 000326: OneCycleScheduler setting learning rate to 0.0001159980573093735.\n",
      "327/343 [===========================>..] - ETA: 15s - loss: 0.5485 - acc: 0.7936 - kappa: 0.9349\n",
      "Iteration 000327: OneCycleScheduler setting learning rate to 0.00011623118018455562.\n",
      "328/343 [===========================>..] - ETA: 14s - loss: 0.5481 - acc: 0.7938 - kappa: 0.9351\n",
      "Iteration 000328: OneCycleScheduler setting learning rate to 0.00011646430305973775.\n",
      "329/343 [===========================>..] - ETA: 13s - loss: 0.5478 - acc: 0.7937 - kappa: 0.9352\n",
      "Iteration 000329: OneCycleScheduler setting learning rate to 0.00011669742593491987.\n",
      "330/343 [===========================>..] - ETA: 12s - loss: 0.5475 - acc: 0.7939 - kappa: 0.9353\n",
      "Iteration 000330: OneCycleScheduler setting learning rate to 0.000116930548810102.\n",
      "331/343 [===========================>..] - ETA: 11s - loss: 0.5478 - acc: 0.7938 - kappa: 0.9354\n",
      "Iteration 000331: OneCycleScheduler setting learning rate to 0.00011716367168528412.\n",
      "332/343 [============================>.] - ETA: 10s - loss: 0.5479 - acc: 0.7933 - kappa: 0.9354\n",
      "Iteration 000332: OneCycleScheduler setting learning rate to 0.00011739679456046625.\n",
      "333/343 [============================>.] - ETA: 9s - loss: 0.5473 - acc: 0.7935 - kappa: 0.9356 \n",
      "Iteration 000333: OneCycleScheduler setting learning rate to 0.00011762991743564837.\n",
      "334/343 [============================>.] - ETA: 8s - loss: 0.5481 - acc: 0.7930 - kappa: 0.9355\n",
      "Iteration 000334: OneCycleScheduler setting learning rate to 0.0001178630403108305.\n",
      "335/343 [============================>.] - ETA: 7s - loss: 0.5477 - acc: 0.7929 - kappa: 0.9356\n",
      "Iteration 000335: OneCycleScheduler setting learning rate to 0.00011809616318601262.\n",
      "336/343 [============================>.] - ETA: 6s - loss: 0.5467 - acc: 0.7935 - kappa: 0.9358\n",
      "Iteration 000336: OneCycleScheduler setting learning rate to 0.00011832928606119478.\n",
      "337/343 [============================>.] - ETA: 5s - loss: 0.5470 - acc: 0.7934 - kappa: 0.9359\n",
      "Iteration 000337: OneCycleScheduler setting learning rate to 0.0001185624089363769.\n",
      "338/343 [============================>.] - ETA: 4s - loss: 0.5467 - acc: 0.7940 - kappa: 0.9361\n",
      "Iteration 000338: OneCycleScheduler setting learning rate to 0.00011879553181155903.\n",
      "339/343 [============================>.] - ETA: 3s - loss: 0.5465 - acc: 0.7942 - kappa: 0.9363\n",
      "Iteration 000339: OneCycleScheduler setting learning rate to 0.00011902865468674115.\n",
      "340/343 [============================>.] - ETA: 2s - loss: 0.5469 - acc: 0.7941 - kappa: 0.9361\n",
      "Iteration 000340: OneCycleScheduler setting learning rate to 0.00011926177756192328.\n",
      "341/343 [============================>.] - ETA: 1s - loss: 0.5459 - acc: 0.7947 - kappa: 0.9363\n",
      "Iteration 000341: OneCycleScheduler setting learning rate to 0.0001194949004371054.\n",
      "342/343 [============================>.] - ETA: 0s - loss: 0.5473 - acc: 0.7935 - kappa: 0.9356\n",
      "Iteration 000342: OneCycleScheduler setting learning rate to 0.00011972802331228753.\n",
      "343/343 [==============================] - 421s 1s/step - loss: 0.5466 - acc: 0.7937 - kappa: 0.9358 - val_loss: 0.7106 - val_acc: 0.7588 - val_kappa: 0.9016\n",
      "Epoch 5/30\n",
      "\n",
      "Iteration 000000: OneCycleScheduler setting learning rate to 4e-05.\n",
      "  1/343 [..............................] - ETA: 1:05 - loss: 0.5576 - acc: 0.8750 - kappa: 0.9922\n",
      "Iteration 000001: OneCycleScheduler setting learning rate to 4.023312287518213e-05.\n",
      "  2/343 [..............................] - ETA: 59s - loss: 0.5710 - acc: 0.7500 - kappa: 0.9609 \n",
      "Iteration 000002: OneCycleScheduler setting learning rate to 4.046624575036426e-05.\n",
      "  3/343 [..............................] - ETA: 55s - loss: 0.4854 - acc: 0.8333 - kappa: 0.9740\n",
      "Iteration 000003: OneCycleScheduler setting learning rate to 4.0699368625546386e-05.\n",
      "  4/343 [..............................] - ETA: 52s - loss: 0.4695 - acc: 0.8125 - kappa: 0.9727\n",
      "Iteration 000004: OneCycleScheduler setting learning rate to 4.093249150072851e-05.\n",
      "  5/343 [..............................] - ETA: 52s - loss: 0.4880 - acc: 0.7750 - kappa: 0.9531\n",
      "Iteration 000005: OneCycleScheduler setting learning rate to 4.1165614375910636e-05.\n",
      "  6/343 [..............................] - ETA: 51s - loss: 0.4280 - acc: 0.8125 - kappa: 0.9609\n",
      "Iteration 000006: OneCycleScheduler setting learning rate to 4.139873725109277e-05.\n",
      "  7/343 [..............................] - ETA: 49s - loss: 0.5463 - acc: 0.7679 - kappa: 0.9118\n",
      "Iteration 000007: OneCycleScheduler setting learning rate to 4.1631860126274893e-05.\n",
      "  8/343 [..............................] - ETA: 48s - loss: 0.4975 - acc: 0.7812 - kappa: 0.9219\n",
      "Iteration 000008: OneCycleScheduler setting learning rate to 4.186498300145702e-05.\n",
      "  9/343 [..............................] - ETA: 48s - loss: 0.5521 - acc: 0.7639 - kappa: 0.9167\n",
      "Iteration 000009: OneCycleScheduler setting learning rate to 4.209810587663915e-05.\n",
      " 10/343 [..............................] - ETA: 49s - loss: 0.6359 - acc: 0.7250 - kappa: 0.8617\n",
      "Iteration 000010: OneCycleScheduler setting learning rate to 4.2331228751821276e-05.\n",
      " 11/343 [..............................] - ETA: 48s - loss: 0.6050 - acc: 0.7386 - kappa: 0.8736\n",
      "Iteration 000011: OneCycleScheduler setting learning rate to 4.25643516270034e-05.\n",
      " 12/343 [>.............................] - ETA: 54s - loss: 0.5759 - acc: 0.7500 - kappa: 0.8835\n",
      "Iteration 000012: OneCycleScheduler setting learning rate to 4.279747450218553e-05.\n",
      " 13/343 [>.............................] - ETA: 1:20 - loss: 0.5623 - acc: 0.7596 - kappa: 0.8918\n",
      "Iteration 000013: OneCycleScheduler setting learning rate to 4.303059737736766e-05.\n",
      " 14/343 [>.............................] - ETA: 1:41 - loss: 0.5566 - acc: 0.7589 - kappa: 0.8945\n",
      "Iteration 000014: OneCycleScheduler setting learning rate to 4.3263720252549784e-05.\n",
      " 15/343 [>.............................] - ETA: 2:07 - loss: 0.5951 - acc: 0.7583 - kappa: 0.8932\n",
      "Iteration 000015: OneCycleScheduler setting learning rate to 4.3496843127731916e-05.\n",
      " 16/343 [>.............................] - ETA: 2:33 - loss: 0.5799 - acc: 0.7656 - kappa: 0.8994\n",
      "Iteration 000016: OneCycleScheduler setting learning rate to 4.372996600291404e-05.\n",
      " 17/343 [>.............................] - ETA: 2:52 - loss: 0.5674 - acc: 0.7721 - kappa: 0.9049\n",
      "Iteration 000017: OneCycleScheduler setting learning rate to 4.3963088878096166e-05.\n",
      " 18/343 [>.............................] - ETA: 3:06 - loss: 0.5654 - acc: 0.7708 - kappa: 0.9062\n",
      "Iteration 000018: OneCycleScheduler setting learning rate to 4.419621175327829e-05.\n",
      " 19/343 [>.............................] - ETA: 3:17 - loss: 0.5583 - acc: 0.7763 - kappa: 0.9108\n",
      "Iteration 000019: OneCycleScheduler setting learning rate to 4.442933462846042e-05.\n",
      " 20/343 [>.............................] - ETA: 3:33 - loss: 0.5484 - acc: 0.7812 - kappa: 0.9148\n",
      "Iteration 000020: OneCycleScheduler setting learning rate to 4.466245750364255e-05.\n",
      " 21/343 [>.............................] - ETA: 3:41 - loss: 0.5543 - acc: 0.7798 - kappa: 0.9156\n",
      "Iteration 000021: OneCycleScheduler setting learning rate to 4.4895580378824674e-05.\n",
      " 22/343 [>.............................] - ETA: 3:44 - loss: 0.5409 - acc: 0.7841 - kappa: 0.9180\n",
      "Iteration 000022: OneCycleScheduler setting learning rate to 4.5128703254006806e-05.\n",
      " 23/343 [=>............................] - ETA: 3:47 - loss: 0.5319 - acc: 0.7826 - kappa: 0.9185\n",
      "Iteration 000023: OneCycleScheduler setting learning rate to 4.536182612918893e-05.\n",
      " 24/343 [=>............................] - ETA: 3:48 - loss: 0.5240 - acc: 0.7865 - kappa: 0.9215\n",
      "Iteration 000024: OneCycleScheduler setting learning rate to 4.5594949004371056e-05.\n",
      " 25/343 [=>............................] - ETA: 3:52 - loss: 0.5327 - acc: 0.7850 - kappa: 0.9234\n",
      "Iteration 000025: OneCycleScheduler setting learning rate to 4.582807187955318e-05.\n",
      " 26/343 [=>............................] - ETA: 3:55 - loss: 0.5318 - acc: 0.7885 - kappa: 0.9252\n",
      "Iteration 000026: OneCycleScheduler setting learning rate to 4.606119475473531e-05.\n",
      " 27/343 [=>............................] - ETA: 3:58 - loss: 0.5382 - acc: 0.7870 - kappa: 0.9233\n",
      "Iteration 000027: OneCycleScheduler setting learning rate to 4.629431762991744e-05.\n",
      " 28/343 [=>............................] - ETA: 4:00 - loss: 0.5225 - acc: 0.7946 - kappa: 0.9261\n",
      "Iteration 000028: OneCycleScheduler setting learning rate to 4.6527440505099564e-05.\n",
      " 29/343 [=>............................] - ETA: 3:59 - loss: 0.5081 - acc: 0.8017 - kappa: 0.9286\n",
      "Iteration 000029: OneCycleScheduler setting learning rate to 4.6760563380281696e-05.\n",
      " 30/343 [=>............................] - ETA: 3:56 - loss: 0.4975 - acc: 0.8042 - kappa: 0.9307\n",
      "Iteration 000030: OneCycleScheduler setting learning rate to 4.699368625546382e-05.\n",
      " 31/343 [=>............................] - ETA: 3:59 - loss: 0.5069 - acc: 0.7984 - kappa: 0.9289\n",
      "Iteration 000031: OneCycleScheduler setting learning rate to 4.7226809130645946e-05.\n",
      " 32/343 [=>............................] - ETA: 4:02 - loss: 0.5005 - acc: 0.8008 - kappa: 0.9302\n",
      "Iteration 000032: OneCycleScheduler setting learning rate to 4.745993200582808e-05.\n",
      " 33/343 [=>............................] - ETA: 4:03 - loss: 0.4895 - acc: 0.8068 - kappa: 0.9323\n",
      "Iteration 000033: OneCycleScheduler setting learning rate to 4.7693054881010203e-05.\n",
      " 34/343 [=>............................] - ETA: 4:06 - loss: 0.4987 - acc: 0.8015 - kappa: 0.9306\n",
      "Iteration 000034: OneCycleScheduler setting learning rate to 4.792617775619233e-05.\n",
      " 35/343 [==>...........................] - ETA: 4:08 - loss: 0.5036 - acc: 0.8000 - kappa: 0.9290\n",
      "Iteration 000035: OneCycleScheduler setting learning rate to 4.815930063137446e-05.\n",
      " 36/343 [==>...........................] - ETA: 4:06 - loss: 0.5050 - acc: 0.7986 - kappa: 0.9290\n",
      "Iteration 000036: OneCycleScheduler setting learning rate to 4.8392423506556586e-05.\n",
      " 37/343 [==>...........................] - ETA: 4:08 - loss: 0.5097 - acc: 0.8007 - kappa: 0.9301\n",
      "Iteration 000037: OneCycleScheduler setting learning rate to 4.862554638173871e-05.\n",
      " 38/343 [==>...........................] - ETA: 4:11 - loss: 0.5149 - acc: 0.7961 - kappa: 0.9287\n",
      "Iteration 000038: OneCycleScheduler setting learning rate to 4.8858669256920836e-05.\n",
      " 39/343 [==>...........................] - ETA: 4:11 - loss: 0.5030 - acc: 0.8013 - kappa: 0.9305\n",
      "Iteration 000039: OneCycleScheduler setting learning rate to 4.909179213210297e-05.\n",
      " 40/343 [==>...........................] - ETA: 4:10 - loss: 0.5060 - acc: 0.8000 - kappa: 0.9291\n",
      "Iteration 000040: OneCycleScheduler setting learning rate to 4.9324915007285094e-05.\n",
      " 41/343 [==>...........................] - ETA: 4:09 - loss: 0.5017 - acc: 0.8018 - kappa: 0.9306\n",
      "Iteration 000041: OneCycleScheduler setting learning rate to 4.955803788246722e-05.\n",
      " 42/343 [==>...........................] - ETA: 4:09 - loss: 0.5011 - acc: 0.8036 - kappa: 0.9321\n",
      "Iteration 000042: OneCycleScheduler setting learning rate to 4.979116075764935e-05.\n",
      " 43/343 [==>...........................] - ETA: 4:10 - loss: 0.4975 - acc: 0.8052 - kappa: 0.9335\n",
      "Iteration 000043: OneCycleScheduler setting learning rate to 5.0024283632831476e-05.\n",
      " 44/343 [==>...........................] - ETA: 4:11 - loss: 0.4933 - acc: 0.8068 - kappa: 0.9343\n",
      "Iteration 000044: OneCycleScheduler setting learning rate to 5.02574065080136e-05.\n",
      " 45/343 [==>...........................] - ETA: 4:11 - loss: 0.4868 - acc: 0.8111 - kappa: 0.9358\n",
      "Iteration 000045: OneCycleScheduler setting learning rate to 5.0490529383195726e-05.\n",
      " 46/343 [===>..........................] - ETA: 4:09 - loss: 0.4782 - acc: 0.8152 - kappa: 0.9372\n",
      "Iteration 000046: OneCycleScheduler setting learning rate to 5.072365225837786e-05.\n",
      " 47/343 [===>..........................] - ETA: 4:08 - loss: 0.4732 - acc: 0.8165 - kappa: 0.9383\n",
      "Iteration 000047: OneCycleScheduler setting learning rate to 5.0956775133559984e-05.\n",
      " 48/343 [===>..........................] - ETA: 4:07 - loss: 0.4650 - acc: 0.8203 - kappa: 0.9396\n",
      "Iteration 000048: OneCycleScheduler setting learning rate to 5.1189898008742116e-05.\n",
      " 49/343 [===>..........................] - ETA: 4:05 - loss: 0.4667 - acc: 0.8189 - kappa: 0.9402\n",
      "Iteration 000049: OneCycleScheduler setting learning rate to 5.142302088392424e-05.\n",
      " 50/343 [===>..........................] - ETA: 4:04 - loss: 0.4619 - acc: 0.8225 - kappa: 0.9414\n",
      "Iteration 000050: OneCycleScheduler setting learning rate to 5.1656143759106366e-05.\n",
      " 51/343 [===>..........................] - ETA: 4:03 - loss: 0.4596 - acc: 0.8235 - kappa: 0.9424\n",
      "Iteration 000051: OneCycleScheduler setting learning rate to 5.188926663428849e-05.\n",
      " 52/343 [===>..........................] - ETA: 4:04 - loss: 0.4582 - acc: 0.8245 - kappa: 0.9434\n",
      "Iteration 000052: OneCycleScheduler setting learning rate to 5.212238950947062e-05.\n",
      " 53/343 [===>..........................] - ETA: 4:04 - loss: 0.4609 - acc: 0.8255 - kappa: 0.9443\n",
      "Iteration 000053: OneCycleScheduler setting learning rate to 5.235551238465275e-05.\n",
      " 54/343 [===>..........................] - ETA: 4:03 - loss: 0.4587 - acc: 0.8264 - kappa: 0.9452\n",
      "Iteration 000054: OneCycleScheduler setting learning rate to 5.2588635259834874e-05.\n",
      " 55/343 [===>..........................] - ETA: 4:03 - loss: 0.4602 - acc: 0.8250 - kappa: 0.9456\n",
      "Iteration 000055: OneCycleScheduler setting learning rate to 5.2821758135017006e-05.\n",
      " 56/343 [===>..........................] - ETA: 4:03 - loss: 0.4639 - acc: 0.8259 - kappa: 0.9464\n",
      "Iteration 000056: OneCycleScheduler setting learning rate to 5.305488101019913e-05.\n",
      " 57/343 [===>..........................] - ETA: 4:04 - loss: 0.4707 - acc: 0.8246 - kappa: 0.9461\n",
      "Iteration 000057: OneCycleScheduler setting learning rate to 5.3288003885381256e-05.\n",
      " 58/343 [====>.........................] - ETA: 4:04 - loss: 0.4678 - acc: 0.8254 - kappa: 0.9469\n",
      "Iteration 000058: OneCycleScheduler setting learning rate to 5.352112676056338e-05.\n",
      " 59/343 [====>.........................] - ETA: 4:03 - loss: 0.4648 - acc: 0.8263 - kappa: 0.9477\n",
      "Iteration 000059: OneCycleScheduler setting learning rate to 5.3754249635745514e-05.\n",
      " 60/343 [====>.........................] - ETA: 4:04 - loss: 0.4662 - acc: 0.8250 - kappa: 0.9480\n",
      "Iteration 000060: OneCycleScheduler setting learning rate to 5.398737251092764e-05.\n",
      " 61/343 [====>.........................] - ETA: 4:02 - loss: 0.4709 - acc: 0.8197 - kappa: 0.9457\n",
      "Iteration 000061: OneCycleScheduler setting learning rate to 5.4220495386109764e-05.\n",
      " 62/343 [====>.........................] - ETA: 4:02 - loss: 0.4796 - acc: 0.8165 - kappa: 0.9434\n",
      "Iteration 000062: OneCycleScheduler setting learning rate to 5.4453618261291896e-05.\n",
      " 63/343 [====>.........................] - ETA: 4:00 - loss: 0.4769 - acc: 0.8175 - kappa: 0.9442\n",
      "Iteration 000063: OneCycleScheduler setting learning rate to 5.468674113647402e-05.\n",
      " 64/343 [====>.........................] - ETA: 4:00 - loss: 0.4756 - acc: 0.8184 - kappa: 0.9449\n",
      "Iteration 000064: OneCycleScheduler setting learning rate to 5.4919864011656146e-05.\n",
      " 65/343 [====>.........................] - ETA: 3:58 - loss: 0.4731 - acc: 0.8192 - kappa: 0.9453\n",
      "Iteration 000065: OneCycleScheduler setting learning rate to 5.515298688683827e-05.\n",
      " 66/343 [====>.........................] - ETA: 3:59 - loss: 0.4732 - acc: 0.8163 - kappa: 0.9432\n",
      "Iteration 000066: OneCycleScheduler setting learning rate to 5.5386109762020404e-05.\n",
      " 67/343 [====>.........................] - ETA: 4:01 - loss: 0.4773 - acc: 0.8153 - kappa: 0.9436\n",
      "Iteration 000067: OneCycleScheduler setting learning rate to 5.561923263720253e-05.\n",
      " 68/343 [====>.........................] - ETA: 4:01 - loss: 0.4831 - acc: 0.8125 - kappa: 0.9426\n",
      "Iteration 000068: OneCycleScheduler setting learning rate to 5.585235551238466e-05.\n",
      " 69/343 [=====>........................] - ETA: 4:01 - loss: 0.4853 - acc: 0.8116 - kappa: 0.9424\n",
      "Iteration 000069: OneCycleScheduler setting learning rate to 5.6085478387566786e-05.\n",
      " 70/343 [=====>........................] - ETA: 4:00 - loss: 0.4794 - acc: 0.8143 - kappa: 0.9432\n",
      "Iteration 000070: OneCycleScheduler setting learning rate to 5.631860126274891e-05.\n",
      " 71/343 [=====>........................] - ETA: 3:59 - loss: 0.4772 - acc: 0.8151 - kappa: 0.9439\n",
      "Iteration 000071: OneCycleScheduler setting learning rate to 5.6551724137931037e-05.\n",
      " 72/343 [=====>........................] - ETA: 4:00 - loss: 0.4778 - acc: 0.8160 - kappa: 0.9442\n",
      "Iteration 000072: OneCycleScheduler setting learning rate to 5.678484701311316e-05.\n",
      " 73/343 [=====>........................] - ETA: 3:59 - loss: 0.4755 - acc: 0.8168 - kappa: 0.9449\n",
      "Iteration 000073: OneCycleScheduler setting learning rate to 5.7017969888295294e-05.\n",
      " 74/343 [=====>........................] - ETA: 3:58 - loss: 0.4773 - acc: 0.8159 - kappa: 0.9447\n",
      "Iteration 000074: OneCycleScheduler setting learning rate to 5.7251092763477426e-05.\n",
      " 75/343 [=====>........................] - ETA: 3:56 - loss: 0.4745 - acc: 0.8167 - kappa: 0.9453\n",
      "Iteration 000075: OneCycleScheduler setting learning rate to 5.748421563865955e-05.\n",
      " 76/343 [=====>........................] - ETA: 3:56 - loss: 0.4716 - acc: 0.8174 - kappa: 0.9459\n",
      "Iteration 000076: OneCycleScheduler setting learning rate to 5.7717338513841676e-05.\n",
      " 77/343 [=====>........................] - ETA: 3:56 - loss: 0.4734 - acc: 0.8166 - kappa: 0.9462\n",
      "Iteration 000077: OneCycleScheduler setting learning rate to 5.79504613890238e-05.\n",
      " 78/343 [=====>........................] - ETA: 3:54 - loss: 0.4754 - acc: 0.8157 - kappa: 0.9460\n",
      "Iteration 000078: OneCycleScheduler setting learning rate to 5.818358426420593e-05.\n",
      " 79/343 [=====>........................] - ETA: 3:52 - loss: 0.4734 - acc: 0.8149 - kappa: 0.9458\n",
      "Iteration 000079: OneCycleScheduler setting learning rate to 5.841670713938806e-05.\n",
      " 80/343 [=====>........................] - ETA: 3:51 - loss: 0.4694 - acc: 0.8156 - kappa: 0.9461\n",
      "Iteration 000080: OneCycleScheduler setting learning rate to 5.8649830014570184e-05.\n",
      " 81/343 [======>.......................] - ETA: 3:50 - loss: 0.4697 - acc: 0.8148 - kappa: 0.9459\n",
      "Iteration 000081: OneCycleScheduler setting learning rate to 5.8882952889752316e-05.\n",
      " 82/343 [======>.......................] - ETA: 3:50 - loss: 0.4717 - acc: 0.8140 - kappa: 0.9457\n",
      "Iteration 000082: OneCycleScheduler setting learning rate to 5.911607576493444e-05.\n",
      " 83/343 [======>.......................] - ETA: 3:49 - loss: 0.4716 - acc: 0.8133 - kappa: 0.9460\n",
      "Iteration 000083: OneCycleScheduler setting learning rate to 5.9349198640116566e-05.\n",
      " 84/343 [======>.......................] - ETA: 3:48 - loss: 0.4780 - acc: 0.8095 - kappa: 0.9433\n",
      "Iteration 000084: OneCycleScheduler setting learning rate to 5.958232151529869e-05.\n",
      " 85/343 [======>.......................] - ETA: 3:47 - loss: 0.4742 - acc: 0.8118 - kappa: 0.9439\n",
      "Iteration 000085: OneCycleScheduler setting learning rate to 5.981544439048082e-05.\n",
      " 86/343 [======>.......................] - ETA: 3:46 - loss: 0.4749 - acc: 0.8110 - kappa: 0.9431\n",
      "Iteration 000086: OneCycleScheduler setting learning rate to 6.004856726566295e-05.\n",
      " 87/343 [======>.......................] - ETA: 3:46 - loss: 0.4740 - acc: 0.8103 - kappa: 0.9423\n",
      "Iteration 000087: OneCycleScheduler setting learning rate to 6.0281690140845074e-05.\n",
      " 88/343 [======>.......................] - ETA: 3:45 - loss: 0.4751 - acc: 0.8068 - kappa: 0.9408\n",
      "Iteration 000088: OneCycleScheduler setting learning rate to 6.0514813016027206e-05.\n",
      " 89/343 [======>.......................] - ETA: 3:45 - loss: 0.4787 - acc: 0.8062 - kappa: 0.9400\n",
      "Iteration 000089: OneCycleScheduler setting learning rate to 6.074793589120933e-05.\n",
      " 90/343 [======>.......................] - ETA: 3:45 - loss: 0.4778 - acc: 0.8083 - kappa: 0.9407\n",
      "Iteration 000090: OneCycleScheduler setting learning rate to 6.0981058766391456e-05.\n",
      " 91/343 [======>.......................] - ETA: 3:45 - loss: 0.4763 - acc: 0.8091 - kappa: 0.9413\n",
      "Iteration 000091: OneCycleScheduler setting learning rate to 6.121418164157358e-05.\n",
      " 92/343 [=======>......................] - ETA: 3:44 - loss: 0.4793 - acc: 0.8071 - kappa: 0.9398\n",
      "Iteration 000092: OneCycleScheduler setting learning rate to 6.144730451675571e-05.\n",
      " 93/343 [=======>......................] - ETA: 3:43 - loss: 0.4810 - acc: 0.8078 - kappa: 0.9404\n",
      "Iteration 000093: OneCycleScheduler setting learning rate to 6.168042739193783e-05.\n",
      " 94/343 [=======>......................] - ETA: 3:43 - loss: 0.4823 - acc: 0.8072 - kappa: 0.9397\n",
      "Iteration 000094: OneCycleScheduler setting learning rate to 6.191355026711997e-05.\n",
      " 95/343 [=======>......................] - ETA: 3:42 - loss: 0.4805 - acc: 0.8079 - kappa: 0.9402\n",
      "Iteration 000095: OneCycleScheduler setting learning rate to 6.21466731423021e-05.\n",
      " 96/343 [=======>......................] - ETA: 3:41 - loss: 0.4849 - acc: 0.8073 - kappa: 0.9405\n",
      "Iteration 000096: OneCycleScheduler setting learning rate to 6.237979601748422e-05.\n",
      " 97/343 [=======>......................] - ETA: 3:41 - loss: 0.4828 - acc: 0.8080 - kappa: 0.9410\n",
      "Iteration 000097: OneCycleScheduler setting learning rate to 6.261291889266635e-05.\n",
      " 98/343 [=======>......................] - ETA: 3:39 - loss: 0.4800 - acc: 0.8099 - kappa: 0.9416\n",
      "Iteration 000098: OneCycleScheduler setting learning rate to 6.284604176784847e-05.\n",
      " 99/343 [=======>......................] - ETA: 3:39 - loss: 0.4866 - acc: 0.8068 - kappa: 0.9410\n",
      "Iteration 000099: OneCycleScheduler setting learning rate to 6.307916464303061e-05.\n",
      "100/343 [=======>......................] - ETA: 3:38 - loss: 0.4848 - acc: 0.8063 - kappa: 0.9413\n",
      "Iteration 000100: OneCycleScheduler setting learning rate to 6.331228751821274e-05.\n",
      "101/343 [=======>......................] - ETA: 3:37 - loss: 0.4866 - acc: 0.8057 - kappa: 0.9415\n",
      "Iteration 000101: OneCycleScheduler setting learning rate to 6.354541039339486e-05.\n",
      "102/343 [=======>......................] - ETA: 3:36 - loss: 0.4858 - acc: 0.8064 - kappa: 0.9418\n",
      "Iteration 000102: OneCycleScheduler setting learning rate to 6.377853326857699e-05.\n",
      "103/343 [========>.....................] - ETA: 3:35 - loss: 0.4839 - acc: 0.8070 - kappa: 0.9421\n",
      "Iteration 000103: OneCycleScheduler setting learning rate to 6.401165614375911e-05.\n",
      "104/343 [========>.....................] - ETA: 3:33 - loss: 0.4823 - acc: 0.8077 - kappa: 0.9425\n",
      "Iteration 000104: OneCycleScheduler setting learning rate to 6.424477901894124e-05.\n",
      "105/343 [========>.....................] - ETA: 3:32 - loss: 0.4796 - acc: 0.8095 - kappa: 0.9431\n",
      "Iteration 000105: OneCycleScheduler setting learning rate to 6.447790189412336e-05.\n",
      "106/343 [========>.....................] - ETA: 3:31 - loss: 0.4802 - acc: 0.8090 - kappa: 0.9418\n",
      "Iteration 000106: OneCycleScheduler setting learning rate to 6.471102476930549e-05.\n",
      "107/343 [========>.....................] - ETA: 3:30 - loss: 0.4796 - acc: 0.8096 - kappa: 0.9422\n",
      "Iteration 000107: OneCycleScheduler setting learning rate to 6.494414764448761e-05.\n",
      "108/343 [========>.....................] - ETA: 3:30 - loss: 0.4791 - acc: 0.8102 - kappa: 0.9427\n",
      "Iteration 000108: OneCycleScheduler setting learning rate to 6.517727051966975e-05.\n",
      "109/343 [========>.....................] - ETA: 3:30 - loss: 0.4861 - acc: 0.8073 - kappa: 0.9407\n",
      "Iteration 000109: OneCycleScheduler setting learning rate to 6.541039339485188e-05.\n",
      "110/343 [========>.....................] - ETA: 3:29 - loss: 0.4865 - acc: 0.8080 - kappa: 0.9411\n",
      "Iteration 000110: OneCycleScheduler setting learning rate to 6.5643516270034e-05.\n",
      "111/343 [========>.....................] - ETA: 3:28 - loss: 0.4865 - acc: 0.8086 - kappa: 0.9416\n",
      "Iteration 000111: OneCycleScheduler setting learning rate to 6.587663914521613e-05.\n",
      "112/343 [========>.....................] - ETA: 3:27 - loss: 0.4837 - acc: 0.8103 - kappa: 0.9421\n",
      "Iteration 000112: OneCycleScheduler setting learning rate to 6.610976202039825e-05.\n",
      "113/343 [========>.....................] - ETA: 3:26 - loss: 0.4800 - acc: 0.8119 - kappa: 0.9426\n",
      "Iteration 000113: OneCycleScheduler setting learning rate to 6.634288489558039e-05.\n",
      "114/343 [========>.....................] - ETA: 3:25 - loss: 0.4859 - acc: 0.8103 - kappa: 0.9425\n",
      "Iteration 000114: OneCycleScheduler setting learning rate to 6.657600777076252e-05.\n",
      "115/343 [=========>....................] - ETA: 3:24 - loss: 0.4850 - acc: 0.8109 - kappa: 0.9429\n",
      "Iteration 000115: OneCycleScheduler setting learning rate to 6.680913064594464e-05.\n",
      "116/343 [=========>....................] - ETA: 3:24 - loss: 0.4851 - acc: 0.8114 - kappa: 0.9434\n",
      "Iteration 000116: OneCycleScheduler setting learning rate to 6.704225352112677e-05.\n",
      "117/343 [=========>....................] - ETA: 3:23 - loss: 0.4836 - acc: 0.8120 - kappa: 0.9438\n",
      "Iteration 000117: OneCycleScheduler setting learning rate to 6.727537639630889e-05.\n",
      "118/343 [=========>....................] - ETA: 3:22 - loss: 0.4841 - acc: 0.8125 - kappa: 0.9442\n",
      "Iteration 000118: OneCycleScheduler setting learning rate to 6.750849927149102e-05.\n",
      "119/343 [=========>....................] - ETA: 3:20 - loss: 0.4822 - acc: 0.8130 - kappa: 0.9444\n",
      "Iteration 000119: OneCycleScheduler setting learning rate to 6.774162214667314e-05.\n",
      "120/343 [=========>....................] - ETA: 3:20 - loss: 0.4843 - acc: 0.8115 - kappa: 0.9438\n",
      "Iteration 000120: OneCycleScheduler setting learning rate to 6.797474502185527e-05.\n",
      "121/343 [=========>....................] - ETA: 3:20 - loss: 0.4849 - acc: 0.8110 - kappa: 0.9437\n",
      "Iteration 000121: OneCycleScheduler setting learning rate to 6.82078678970374e-05.\n",
      "122/343 [=========>....................] - ETA: 3:20 - loss: 0.4857 - acc: 0.8105 - kappa: 0.9436\n",
      "Iteration 000122: OneCycleScheduler setting learning rate to 6.844099077221953e-05.\n",
      "123/343 [=========>....................] - ETA: 3:19 - loss: 0.4838 - acc: 0.8120 - kappa: 0.9440\n",
      "Iteration 000123: OneCycleScheduler setting learning rate to 6.867411364740166e-05.\n",
      "124/343 [=========>....................] - ETA: 3:18 - loss: 0.4831 - acc: 0.8115 - kappa: 0.9442\n",
      "Iteration 000124: OneCycleScheduler setting learning rate to 6.890723652258378e-05.\n",
      "125/343 [=========>....................] - ETA: 3:17 - loss: 0.4845 - acc: 0.8120 - kappa: 0.9446\n",
      "Iteration 000125: OneCycleScheduler setting learning rate to 6.914035939776591e-05.\n",
      "126/343 [==========>...................] - ETA: 3:17 - loss: 0.4852 - acc: 0.8115 - kappa: 0.9448\n",
      "Iteration 000126: OneCycleScheduler setting learning rate to 6.937348227294805e-05.\n",
      "127/343 [==========>...................] - ETA: 3:16 - loss: 0.4837 - acc: 0.8120 - kappa: 0.9450\n",
      "Iteration 000127: OneCycleScheduler setting learning rate to 6.960660514813017e-05.\n",
      "128/343 [==========>...................] - ETA: 3:15 - loss: 0.4821 - acc: 0.8125 - kappa: 0.9454\n",
      "Iteration 000128: OneCycleScheduler setting learning rate to 6.98397280233123e-05.\n",
      "129/343 [==========>...................] - ETA: 3:15 - loss: 0.4815 - acc: 0.8130 - kappa: 0.9457\n",
      "Iteration 000129: OneCycleScheduler setting learning rate to 7.007285089849442e-05.\n",
      "130/343 [==========>...................] - ETA: 3:13 - loss: 0.4828 - acc: 0.8135 - kappa: 0.9456\n",
      "Iteration 000130: OneCycleScheduler setting learning rate to 7.030597377367655e-05.\n",
      "131/343 [==========>...................] - ETA: 3:13 - loss: 0.4854 - acc: 0.8120 - kappa: 0.9439\n",
      "Iteration 000131: OneCycleScheduler setting learning rate to 7.053909664885867e-05.\n",
      "132/343 [==========>...................] - ETA: 3:12 - loss: 0.4903 - acc: 0.8125 - kappa: 0.9442\n",
      "Iteration 000132: OneCycleScheduler setting learning rate to 7.07722195240408e-05.\n",
      "133/343 [==========>...................] - ETA: 3:11 - loss: 0.4928 - acc: 0.8120 - kappa: 0.9444\n",
      "Iteration 000133: OneCycleScheduler setting learning rate to 7.100534239922292e-05.\n",
      "134/343 [==========>...................] - ETA: 3:11 - loss: 0.4932 - acc: 0.8116 - kappa: 0.9439\n",
      "Iteration 000134: OneCycleScheduler setting learning rate to 7.123846527440505e-05.\n",
      "135/343 [==========>...................] - ETA: 3:10 - loss: 0.4947 - acc: 0.8111 - kappa: 0.9434\n",
      "Iteration 000135: OneCycleScheduler setting learning rate to 7.147158814958719e-05.\n",
      "136/343 [==========>...................] - ETA: 3:09 - loss: 0.4934 - acc: 0.8116 - kappa: 0.9438\n",
      "Iteration 000136: OneCycleScheduler setting learning rate to 7.170471102476931e-05.\n",
      "137/343 [==========>...................] - ETA: 3:08 - loss: 0.4937 - acc: 0.8111 - kappa: 0.9439\n",
      "Iteration 000137: OneCycleScheduler setting learning rate to 7.193783389995144e-05.\n",
      "138/343 [===========>..................] - ETA: 3:08 - loss: 0.4953 - acc: 0.8107 - kappa: 0.9429\n",
      "Iteration 000138: OneCycleScheduler setting learning rate to 7.217095677513358e-05.\n",
      "139/343 [===========>..................] - ETA: 3:07 - loss: 0.4929 - acc: 0.8121 - kappa: 0.9433\n",
      "Iteration 000139: OneCycleScheduler setting learning rate to 7.24040796503157e-05.\n",
      "140/343 [===========>..................] - ETA: 3:06 - loss: 0.4952 - acc: 0.8116 - kappa: 0.9432\n",
      "Iteration 000140: OneCycleScheduler setting learning rate to 7.263720252549783e-05.\n",
      "141/343 [===========>..................] - ETA: 3:06 - loss: 0.4951 - acc: 0.8112 - kappa: 0.9432\n",
      "Iteration 000141: OneCycleScheduler setting learning rate to 7.287032540067995e-05.\n",
      "142/343 [===========>..................] - ETA: 3:04 - loss: 0.4965 - acc: 0.8099 - kappa: 0.9422\n",
      "Iteration 000142: OneCycleScheduler setting learning rate to 7.310344827586208e-05.\n",
      "143/343 [===========>..................] - ETA: 3:04 - loss: 0.4957 - acc: 0.8103 - kappa: 0.9421\n",
      "Iteration 000143: OneCycleScheduler setting learning rate to 7.33365711510442e-05.\n",
      "144/343 [===========>..................] - ETA: 3:03 - loss: 0.4938 - acc: 0.8116 - kappa: 0.9425\n",
      "Iteration 000144: OneCycleScheduler setting learning rate to 7.356969402622633e-05.\n",
      "145/343 [===========>..................] - ETA: 3:02 - loss: 0.4928 - acc: 0.8121 - kappa: 0.9428\n",
      "Iteration 000145: OneCycleScheduler setting learning rate to 7.380281690140845e-05.\n",
      "146/343 [===========>..................] - ETA: 3:01 - loss: 0.4942 - acc: 0.8108 - kappa: 0.9427\n",
      "Iteration 000146: OneCycleScheduler setting learning rate to 7.403593977659058e-05.\n",
      "147/343 [===========>..................] - ETA: 3:00 - loss: 0.4935 - acc: 0.8112 - kappa: 0.9431\n",
      "Iteration 000147: OneCycleScheduler setting learning rate to 7.42690626517727e-05.\n",
      "148/343 [===========>..................] - ETA: 3:00 - loss: 0.4920 - acc: 0.8125 - kappa: 0.9435\n",
      "Iteration 000148: OneCycleScheduler setting learning rate to 7.450218552695484e-05.\n",
      "149/343 [============>.................] - ETA: 2:58 - loss: 0.4932 - acc: 0.8121 - kappa: 0.9436\n",
      "Iteration 000149: OneCycleScheduler setting learning rate to 7.473530840213697e-05.\n",
      "150/343 [============>.................] - ETA: 2:57 - loss: 0.4932 - acc: 0.8117 - kappa: 0.9435\n",
      "Iteration 000150: OneCycleScheduler setting learning rate to 7.496843127731909e-05.\n",
      "151/343 [============>.................] - ETA: 2:57 - loss: 0.4944 - acc: 0.8104 - kappa: 0.9434\n",
      "Iteration 000151: OneCycleScheduler setting learning rate to 7.520155415250122e-05.\n",
      "152/343 [============>.................] - ETA: 2:56 - loss: 0.4943 - acc: 0.8100 - kappa: 0.9436\n",
      "Iteration 000152: OneCycleScheduler setting learning rate to 7.543467702768336e-05.\n",
      "153/343 [============>.................] - ETA: 2:55 - loss: 0.4930 - acc: 0.8105 - kappa: 0.9439\n",
      "Iteration 000153: OneCycleScheduler setting learning rate to 7.566779990286548e-05.\n",
      "154/343 [============>.................] - ETA: 2:54 - loss: 0.4937 - acc: 0.8101 - kappa: 0.9441\n",
      "Iteration 000154: OneCycleScheduler setting learning rate to 7.59009227780476e-05.\n",
      "155/343 [============>.................] - ETA: 2:53 - loss: 0.4911 - acc: 0.8113 - kappa: 0.9445\n",
      "Iteration 000155: OneCycleScheduler setting learning rate to 7.613404565322973e-05.\n",
      "156/343 [============>.................] - ETA: 2:52 - loss: 0.4890 - acc: 0.8125 - kappa: 0.9448\n",
      "Iteration 000156: OneCycleScheduler setting learning rate to 7.636716852841186e-05.\n",
      "157/343 [============>.................] - ETA: 2:51 - loss: 0.4888 - acc: 0.8129 - kappa: 0.9451\n",
      "Iteration 000157: OneCycleScheduler setting learning rate to 7.660029140359398e-05.\n",
      "158/343 [============>.................] - ETA: 2:50 - loss: 0.4887 - acc: 0.8125 - kappa: 0.9453\n",
      "Iteration 000158: OneCycleScheduler setting learning rate to 7.683341427877611e-05.\n",
      "159/343 [============>.................] - ETA: 2:49 - loss: 0.4896 - acc: 0.8121 - kappa: 0.9452\n",
      "Iteration 000159: OneCycleScheduler setting learning rate to 7.706653715395823e-05.\n",
      "160/343 [============>.................] - ETA: 2:48 - loss: 0.4882 - acc: 0.8133 - kappa: 0.9455\n",
      "Iteration 000160: OneCycleScheduler setting learning rate to 7.729966002914036e-05.\n",
      "161/343 [=============>................] - ETA: 2:48 - loss: 0.4892 - acc: 0.8129 - kappa: 0.9454\n",
      "Iteration 000161: OneCycleScheduler setting learning rate to 7.753278290432248e-05.\n",
      "162/343 [=============>................] - ETA: 2:47 - loss: 0.4881 - acc: 0.8133 - kappa: 0.9456\n",
      "Iteration 000162: OneCycleScheduler setting learning rate to 7.776590577950462e-05.\n",
      "163/343 [=============>................] - ETA: 2:46 - loss: 0.4886 - acc: 0.8129 - kappa: 0.9451\n",
      "Iteration 000163: OneCycleScheduler setting learning rate to 7.799902865468675e-05.\n",
      "164/343 [=============>................] - ETA: 2:45 - loss: 0.4888 - acc: 0.8133 - kappa: 0.9453\n",
      "Iteration 000164: OneCycleScheduler setting learning rate to 7.823215152986887e-05.\n",
      "165/343 [=============>................] - ETA: 2:44 - loss: 0.4868 - acc: 0.8144 - kappa: 0.9456\n",
      "Iteration 000165: OneCycleScheduler setting learning rate to 7.846527440505101e-05.\n",
      "166/343 [=============>................] - ETA: 2:42 - loss: 0.4853 - acc: 0.8148 - kappa: 0.9457\n",
      "Iteration 000166: OneCycleScheduler setting learning rate to 7.869839728023314e-05.\n",
      "167/343 [=============>................] - ETA: 2:41 - loss: 0.4882 - acc: 0.8136 - kappa: 0.9453\n",
      "Iteration 000167: OneCycleScheduler setting learning rate to 7.893152015541526e-05.\n",
      "168/343 [=============>................] - ETA: 2:40 - loss: 0.4978 - acc: 0.8125 - kappa: 0.9449\n",
      "Iteration 000168: OneCycleScheduler setting learning rate to 7.916464303059739e-05.\n",
      "169/343 [=============>................] - ETA: 2:39 - loss: 0.4976 - acc: 0.8129 - kappa: 0.9450\n",
      "Iteration 000169: OneCycleScheduler setting learning rate to 7.939776590577951e-05.\n",
      "170/343 [=============>................] - ETA: 2:39 - loss: 0.4966 - acc: 0.8125 - kappa: 0.9452\n",
      "Iteration 000170: OneCycleScheduler setting learning rate to 7.963088878096164e-05.\n",
      "171/343 [=============>................] - ETA: 2:38 - loss: 0.5042 - acc: 0.8114 - kappa: 0.9439\n",
      "Iteration 000171: OneCycleScheduler setting learning rate to 7.986401165614376e-05.\n",
      "172/343 [==============>...............] - ETA: 2:37 - loss: 0.5077 - acc: 0.8118 - kappa: 0.9441\n",
      "Iteration 000172: OneCycleScheduler setting learning rate to 8.009713453132589e-05.\n",
      "173/343 [==============>...............] - ETA: 2:36 - loss: 0.5062 - acc: 0.8121 - kappa: 0.9444\n",
      "Iteration 000173: OneCycleScheduler setting learning rate to 8.033025740650801e-05.\n",
      "174/343 [==============>...............] - ETA: 2:36 - loss: 0.5058 - acc: 0.8125 - kappa: 0.9447\n",
      "Iteration 000174: OneCycleScheduler setting learning rate to 8.056338028169014e-05.\n",
      "175/343 [==============>...............] - ETA: 2:35 - loss: 0.5075 - acc: 0.8114 - kappa: 0.9443\n",
      "Iteration 000175: OneCycleScheduler setting learning rate to 8.079650315687228e-05.\n",
      "176/343 [==============>...............] - ETA: 2:34 - loss: 0.5128 - acc: 0.8097 - kappa: 0.9435\n",
      "Iteration 000176: OneCycleScheduler setting learning rate to 8.10296260320544e-05.\n",
      "177/343 [==============>...............] - ETA: 2:33 - loss: 0.5132 - acc: 0.8093 - kappa: 0.9436\n",
      "Iteration 000177: OneCycleScheduler setting learning rate to 8.126274890723653e-05.\n",
      "178/343 [==============>...............] - ETA: 2:32 - loss: 0.5190 - acc: 0.8090 - kappa: 0.9438\n",
      "Iteration 000178: OneCycleScheduler setting learning rate to 8.149587178241867e-05.\n",
      "179/343 [==============>...............] - ETA: 2:32 - loss: 0.5178 - acc: 0.8094 - kappa: 0.9440\n",
      "Iteration 000179: OneCycleScheduler setting learning rate to 8.172899465760079e-05.\n",
      "180/343 [==============>...............] - ETA: 2:31 - loss: 0.5216 - acc: 0.8076 - kappa: 0.9433\n",
      "Iteration 000180: OneCycleScheduler setting learning rate to 8.196211753278292e-05.\n",
      "181/343 [==============>...............] - ETA: 2:30 - loss: 0.5200 - acc: 0.8087 - kappa: 0.9436\n",
      "Iteration 000181: OneCycleScheduler setting learning rate to 8.219524040796504e-05.\n",
      "182/343 [==============>...............] - ETA: 2:29 - loss: 0.5205 - acc: 0.8084 - kappa: 0.9437\n",
      "Iteration 000182: OneCycleScheduler setting learning rate to 8.242836328314717e-05.\n",
      "183/343 [===============>..............] - ETA: 2:28 - loss: 0.5200 - acc: 0.8087 - kappa: 0.9439\n",
      "Iteration 000183: OneCycleScheduler setting learning rate to 8.266148615832929e-05.\n",
      "184/343 [===============>..............] - ETA: 2:27 - loss: 0.5199 - acc: 0.8091 - kappa: 0.9441\n",
      "Iteration 000184: OneCycleScheduler setting learning rate to 8.289460903351142e-05.\n",
      "185/343 [===============>..............] - ETA: 2:26 - loss: 0.5197 - acc: 0.8095 - kappa: 0.9444\n",
      "Iteration 000185: OneCycleScheduler setting learning rate to 8.312773190869354e-05.\n",
      "186/343 [===============>..............] - ETA: 2:25 - loss: 0.5179 - acc: 0.8105 - kappa: 0.9447\n",
      "Iteration 000186: OneCycleScheduler setting learning rate to 8.336085478387567e-05.\n",
      "187/343 [===============>..............] - ETA: 2:24 - loss: 0.5175 - acc: 0.8102 - kappa: 0.9448\n",
      "Iteration 000187: OneCycleScheduler setting learning rate to 8.359397765905779e-05.\n",
      "188/343 [===============>..............] - ETA: 2:24 - loss: 0.5182 - acc: 0.8105 - kappa: 0.9451\n",
      "Iteration 000188: OneCycleScheduler setting learning rate to 8.382710053423993e-05.\n",
      "189/343 [===============>..............] - ETA: 2:23 - loss: 0.5179 - acc: 0.8108 - kappa: 0.9452\n",
      "Iteration 000189: OneCycleScheduler setting learning rate to 8.406022340942206e-05.\n",
      "190/343 [===============>..............] - ETA: 2:22 - loss: 0.5178 - acc: 0.8112 - kappa: 0.9453\n",
      "Iteration 000190: OneCycleScheduler setting learning rate to 8.429334628460418e-05.\n",
      "191/343 [===============>..............] - ETA: 2:21 - loss: 0.5158 - acc: 0.8122 - kappa: 0.9456\n",
      "Iteration 000191: OneCycleScheduler setting learning rate to 8.452646915978631e-05.\n",
      "192/343 [===============>..............] - ETA: 2:20 - loss: 0.5152 - acc: 0.8118 - kappa: 0.9455\n",
      "Iteration 000192: OneCycleScheduler setting learning rate to 8.475959203496845e-05.\n",
      "193/343 [===============>..............] - ETA: 2:19 - loss: 0.5145 - acc: 0.8115 - kappa: 0.9454\n",
      "Iteration 000193: OneCycleScheduler setting learning rate to 8.499271491015057e-05.\n",
      "194/343 [===============>..............] - ETA: 2:18 - loss: 0.5132 - acc: 0.8119 - kappa: 0.9457\n",
      "Iteration 000194: OneCycleScheduler setting learning rate to 8.52258377853327e-05.\n",
      "195/343 [================>.............] - ETA: 2:17 - loss: 0.5119 - acc: 0.8128 - kappa: 0.9460\n",
      "Iteration 000195: OneCycleScheduler setting learning rate to 8.545896066051482e-05.\n",
      "196/343 [================>.............] - ETA: 2:17 - loss: 0.5105 - acc: 0.8131 - kappa: 0.9462\n",
      "Iteration 000196: OneCycleScheduler setting learning rate to 8.569208353569695e-05.\n",
      "197/343 [================>.............] - ETA: 2:16 - loss: 0.5100 - acc: 0.8128 - kappa: 0.9463\n",
      "Iteration 000197: OneCycleScheduler setting learning rate to 8.592520641087907e-05.\n",
      "198/343 [================>.............] - ETA: 2:15 - loss: 0.5084 - acc: 0.8138 - kappa: 0.9466\n",
      "Iteration 000198: OneCycleScheduler setting learning rate to 8.61583292860612e-05.\n",
      "199/343 [================>.............] - ETA: 2:14 - loss: 0.5083 - acc: 0.8141 - kappa: 0.9468\n",
      "Iteration 000199: OneCycleScheduler setting learning rate to 8.639145216124332e-05.\n",
      "200/343 [================>.............] - ETA: 2:13 - loss: 0.5081 - acc: 0.8137 - kappa: 0.9469\n",
      "Iteration 000200: OneCycleScheduler setting learning rate to 8.662457503642545e-05.\n",
      "201/343 [================>.............] - ETA: 2:12 - loss: 0.5066 - acc: 0.8147 - kappa: 0.9472\n",
      "Iteration 000201: OneCycleScheduler setting learning rate to 8.685769791160757e-05.\n",
      "202/343 [================>.............] - ETA: 2:11 - loss: 0.5060 - acc: 0.8150 - kappa: 0.9474\n",
      "Iteration 000202: OneCycleScheduler setting learning rate to 8.709082078678971e-05.\n",
      "203/343 [================>.............] - ETA: 2:10 - loss: 0.5061 - acc: 0.8153 - kappa: 0.9475\n",
      "Iteration 000203: OneCycleScheduler setting learning rate to 8.732394366197184e-05.\n",
      "204/343 [================>.............] - ETA: 2:10 - loss: 0.5051 - acc: 0.8162 - kappa: 0.9478\n",
      "Iteration 000204: OneCycleScheduler setting learning rate to 8.755706653715396e-05.\n",
      "205/343 [================>.............] - ETA: 2:09 - loss: 0.5056 - acc: 0.8159 - kappa: 0.9477\n",
      "Iteration 000205: OneCycleScheduler setting learning rate to 8.77901894123361e-05.\n",
      "206/343 [=================>............] - ETA: 2:08 - loss: 0.5037 - acc: 0.8167 - kappa: 0.9479\n",
      "Iteration 000206: OneCycleScheduler setting learning rate to 8.802331228751823e-05.\n",
      "207/343 [=================>............] - ETA: 2:07 - loss: 0.5018 - acc: 0.8176 - kappa: 0.9482\n",
      "Iteration 000207: OneCycleScheduler setting learning rate to 8.825643516270035e-05.\n",
      "208/343 [=================>............] - ETA: 2:06 - loss: 0.5026 - acc: 0.8173 - kappa: 0.9481\n",
      "Iteration 000208: OneCycleScheduler setting learning rate to 8.848955803788248e-05.\n",
      "209/343 [=================>............] - ETA: 2:05 - loss: 0.5068 - acc: 0.8158 - kappa: 0.9470\n",
      "Iteration 000209: OneCycleScheduler setting learning rate to 8.87226809130646e-05.\n",
      "210/343 [=================>............] - ETA: 2:04 - loss: 0.5053 - acc: 0.8167 - kappa: 0.9472\n",
      "Iteration 000210: OneCycleScheduler setting learning rate to 8.895580378824673e-05.\n",
      "211/343 [=================>............] - ETA: 2:04 - loss: 0.5048 - acc: 0.8164 - kappa: 0.9472\n",
      "Iteration 000211: OneCycleScheduler setting learning rate to 8.918892666342885e-05.\n",
      "212/343 [=================>............] - ETA: 2:03 - loss: 0.5049 - acc: 0.8166 - kappa: 0.9474\n",
      "Iteration 000212: OneCycleScheduler setting learning rate to 8.942204953861098e-05.\n",
      "213/343 [=================>............] - ETA: 2:02 - loss: 0.5030 - acc: 0.8175 - kappa: 0.9476\n",
      "Iteration 000213: OneCycleScheduler setting learning rate to 8.96551724137931e-05.\n",
      "214/343 [=================>............] - ETA: 2:01 - loss: 0.5015 - acc: 0.8183 - kappa: 0.9479\n",
      "Iteration 000214: OneCycleScheduler setting learning rate to 8.988829528897523e-05.\n",
      "215/343 [=================>............] - ETA: 2:00 - loss: 0.5023 - acc: 0.8174 - kappa: 0.9478\n",
      "Iteration 000215: OneCycleScheduler setting learning rate to 9.012141816415737e-05.\n",
      "216/343 [=================>............] - ETA: 1:59 - loss: 0.5005 - acc: 0.8183 - kappa: 0.9480\n",
      "Iteration 000216: OneCycleScheduler setting learning rate to 9.035454103933949e-05.\n",
      "217/343 [=================>............] - ETA: 1:58 - loss: 0.5005 - acc: 0.8180 - kappa: 0.9479\n",
      "Iteration 000217: OneCycleScheduler setting learning rate to 9.058766391452162e-05.\n",
      "218/343 [==================>...........] - ETA: 1:57 - loss: 0.4995 - acc: 0.8182 - kappa: 0.9480\n",
      "Iteration 000218: OneCycleScheduler setting learning rate to 9.082078678970376e-05.\n",
      "219/343 [==================>...........] - ETA: 1:56 - loss: 0.4995 - acc: 0.8179 - kappa: 0.9481\n",
      "Iteration 000219: OneCycleScheduler setting learning rate to 9.105390966488588e-05.\n",
      "220/343 [==================>...........] - ETA: 1:55 - loss: 0.5000 - acc: 0.8176 - kappa: 0.9482\n",
      "Iteration 000220: OneCycleScheduler setting learning rate to 9.1287032540068e-05.\n",
      "221/343 [==================>...........] - ETA: 1:54 - loss: 0.4992 - acc: 0.8179 - kappa: 0.9483\n",
      "Iteration 000221: OneCycleScheduler setting learning rate to 9.152015541525013e-05.\n",
      "222/343 [==================>...........] - ETA: 1:54 - loss: 0.4995 - acc: 0.8181 - kappa: 0.9485\n",
      "Iteration 000222: OneCycleScheduler setting learning rate to 9.175327829043226e-05.\n",
      "223/343 [==================>...........] - ETA: 1:52 - loss: 0.4986 - acc: 0.8184 - kappa: 0.9486\n",
      "Iteration 000223: OneCycleScheduler setting learning rate to 9.198640116561438e-05.\n",
      "224/343 [==================>...........] - ETA: 1:52 - loss: 0.4970 - acc: 0.8192 - kappa: 0.9488\n",
      "Iteration 000224: OneCycleScheduler setting learning rate to 9.221952404079651e-05.\n",
      "225/343 [==================>...........] - ETA: 1:51 - loss: 0.4981 - acc: 0.8194 - kappa: 0.9489\n",
      "Iteration 000225: OneCycleScheduler setting learning rate to 9.245264691597863e-05.\n",
      "226/343 [==================>...........] - ETA: 1:50 - loss: 0.4985 - acc: 0.8191 - kappa: 0.9490\n",
      "Iteration 000226: OneCycleScheduler setting learning rate to 9.268576979116076e-05.\n",
      "227/343 [==================>...........] - ETA: 1:49 - loss: 0.4976 - acc: 0.8194 - kappa: 0.9492\n",
      "Iteration 000227: OneCycleScheduler setting learning rate to 9.291889266634288e-05.\n",
      "228/343 [==================>...........] - ETA: 1:48 - loss: 0.4976 - acc: 0.8196 - kappa: 0.9494\n",
      "Iteration 000228: OneCycleScheduler setting learning rate to 9.315201554152502e-05.\n",
      "229/343 [===================>..........] - ETA: 1:47 - loss: 0.4986 - acc: 0.8193 - kappa: 0.9493\n",
      "Iteration 000229: OneCycleScheduler setting learning rate to 9.338513841670715e-05.\n",
      "230/343 [===================>..........] - ETA: 1:46 - loss: 0.5008 - acc: 0.8185 - kappa: 0.9492\n",
      "Iteration 000230: OneCycleScheduler setting learning rate to 9.361826129188927e-05.\n",
      "231/343 [===================>..........] - ETA: 1:45 - loss: 0.5026 - acc: 0.8182 - kappa: 0.9491\n",
      "Iteration 000231: OneCycleScheduler setting learning rate to 9.38513841670714e-05.\n",
      "232/343 [===================>..........] - ETA: 1:44 - loss: 0.5034 - acc: 0.8173 - kappa: 0.9491\n",
      "Iteration 000232: OneCycleScheduler setting learning rate to 9.408450704225354e-05.\n",
      "233/343 [===================>..........] - ETA: 1:43 - loss: 0.5026 - acc: 0.8176 - kappa: 0.9492\n",
      "Iteration 000233: OneCycleScheduler setting learning rate to 9.431762991743566e-05.\n",
      "234/343 [===================>..........] - ETA: 1:42 - loss: 0.5008 - acc: 0.8184 - kappa: 0.9495\n",
      "Iteration 000234: OneCycleScheduler setting learning rate to 9.455075279261779e-05.\n",
      "235/343 [===================>..........] - ETA: 1:42 - loss: 0.4999 - acc: 0.8186 - kappa: 0.9496\n",
      "Iteration 000235: OneCycleScheduler setting learning rate to 9.478387566779991e-05.\n",
      "236/343 [===================>..........] - ETA: 1:41 - loss: 0.5013 - acc: 0.8178 - kappa: 0.9487\n",
      "Iteration 000236: OneCycleScheduler setting learning rate to 9.501699854298204e-05.\n",
      "237/343 [===================>..........] - ETA: 1:40 - loss: 0.5008 - acc: 0.8175 - kappa: 0.9483\n",
      "Iteration 000237: OneCycleScheduler setting learning rate to 9.525012141816416e-05.\n",
      "238/343 [===================>..........] - ETA: 1:39 - loss: 0.4990 - acc: 0.8183 - kappa: 0.9486\n",
      "Iteration 000238: OneCycleScheduler setting learning rate to 9.548324429334629e-05.\n",
      "239/343 [===================>..........] - ETA: 1:38 - loss: 0.4997 - acc: 0.8185 - kappa: 0.9486\n",
      "Iteration 000239: OneCycleScheduler setting learning rate to 9.571636716852841e-05.\n",
      "240/343 [===================>..........] - ETA: 1:37 - loss: 0.4999 - acc: 0.8182 - kappa: 0.9486\n",
      "Iteration 000240: OneCycleScheduler setting learning rate to 9.594949004371054e-05.\n",
      "241/343 [====================>.........] - ETA: 1:36 - loss: 0.5014 - acc: 0.8179 - kappa: 0.9485\n",
      "Iteration 000241: OneCycleScheduler setting learning rate to 9.618261291889266e-05.\n",
      "242/343 [====================>.........] - ETA: 1:35 - loss: 0.5014 - acc: 0.8177 - kappa: 0.9486\n",
      "Iteration 000242: OneCycleScheduler setting learning rate to 9.64157357940748e-05.\n",
      "243/343 [====================>.........] - ETA: 1:34 - loss: 0.5024 - acc: 0.8179 - kappa: 0.9488\n",
      "Iteration 000243: OneCycleScheduler setting learning rate to 9.664885866925693e-05.\n",
      "244/343 [====================>.........] - ETA: 1:33 - loss: 0.5035 - acc: 0.8166 - kappa: 0.9482\n",
      "Iteration 000244: OneCycleScheduler setting learning rate to 9.688198154443905e-05.\n",
      "245/343 [====================>.........] - ETA: 1:32 - loss: 0.5035 - acc: 0.8163 - kappa: 0.9482\n",
      "Iteration 000245: OneCycleScheduler setting learning rate to 9.711510441962119e-05.\n",
      "246/343 [====================>.........] - ETA: 1:31 - loss: 0.5034 - acc: 0.8166 - kappa: 0.9483\n",
      "Iteration 000246: OneCycleScheduler setting learning rate to 9.734822729480332e-05.\n",
      "247/343 [====================>.........] - ETA: 1:30 - loss: 0.5047 - acc: 0.8158 - kappa: 0.9480\n",
      "Iteration 000247: OneCycleScheduler setting learning rate to 9.758135016998544e-05.\n",
      "248/343 [====================>.........] - ETA: 1:29 - loss: 0.5036 - acc: 0.8160 - kappa: 0.9482\n",
      "Iteration 000248: OneCycleScheduler setting learning rate to 9.781447304516757e-05.\n",
      "249/343 [====================>.........] - ETA: 1:28 - loss: 0.5060 - acc: 0.8158 - kappa: 0.9481\n",
      "Iteration 000249: OneCycleScheduler setting learning rate to 9.804759592034969e-05.\n",
      "250/343 [====================>.........] - ETA: 1:27 - loss: 0.5058 - acc: 0.8155 - kappa: 0.9482\n",
      "Iteration 000250: OneCycleScheduler setting learning rate to 9.828071879553182e-05.\n",
      "251/343 [====================>.........] - ETA: 1:26 - loss: 0.5056 - acc: 0.8152 - kappa: 0.9483\n",
      "Iteration 000251: OneCycleScheduler setting learning rate to 9.851384167071394e-05.\n",
      "252/343 [=====================>........] - ETA: 1:26 - loss: 0.5044 - acc: 0.8160 - kappa: 0.9485\n",
      "Iteration 000252: OneCycleScheduler setting learning rate to 9.874696454589607e-05.\n",
      "253/343 [=====================>........] - ETA: 1:25 - loss: 0.5054 - acc: 0.8152 - kappa: 0.9482\n",
      "Iteration 000253: OneCycleScheduler setting learning rate to 9.89800874210782e-05.\n",
      "254/343 [=====================>........] - ETA: 1:24 - loss: 0.5040 - acc: 0.8159 - kappa: 0.9484\n",
      "Iteration 000254: OneCycleScheduler setting learning rate to 9.921321029626032e-05.\n",
      "255/343 [=====================>........] - ETA: 1:23 - loss: 0.5045 - acc: 0.8162 - kappa: 0.9486\n",
      "Iteration 000255: OneCycleScheduler setting learning rate to 9.944633317144246e-05.\n",
      "256/343 [=====================>........] - ETA: 1:22 - loss: 0.5039 - acc: 0.8164 - kappa: 0.9485\n",
      "Iteration 000256: OneCycleScheduler setting learning rate to 9.967945604662458e-05.\n",
      "257/343 [=====================>........] - ETA: 1:21 - loss: 0.5037 - acc: 0.8161 - kappa: 0.9484\n",
      "Iteration 000257: OneCycleScheduler setting learning rate to 9.991257892180671e-05.\n",
      "258/343 [=====================>........] - ETA: 1:20 - loss: 0.5046 - acc: 0.8154 - kappa: 0.9482\n",
      "Iteration 000258: OneCycleScheduler setting learning rate to 0.00010014570179698885.\n",
      "259/343 [=====================>........] - ETA: 1:19 - loss: 0.5051 - acc: 0.8152 - kappa: 0.9481\n",
      "Iteration 000259: OneCycleScheduler setting learning rate to 0.00010037882467217097.\n",
      "260/343 [=====================>........] - ETA: 1:18 - loss: 0.5077 - acc: 0.8144 - kappa: 0.9475\n",
      "Iteration 000260: OneCycleScheduler setting learning rate to 0.0001006119475473531.\n",
      "261/343 [=====================>........] - ETA: 1:17 - loss: 0.5066 - acc: 0.8147 - kappa: 0.9477\n",
      "Iteration 000261: OneCycleScheduler setting learning rate to 0.00010084507042253522.\n",
      "262/343 [=====================>........] - ETA: 1:16 - loss: 0.5069 - acc: 0.8149 - kappa: 0.9478\n",
      "Iteration 000262: OneCycleScheduler setting learning rate to 0.00010107819329771735.\n",
      "263/343 [======================>.......] - ETA: 1:15 - loss: 0.5066 - acc: 0.8146 - kappa: 0.9477\n",
      "Iteration 000263: OneCycleScheduler setting learning rate to 0.00010131131617289947.\n",
      "264/343 [======================>.......] - ETA: 1:14 - loss: 0.5057 - acc: 0.8149 - kappa: 0.9479\n",
      "Iteration 000264: OneCycleScheduler setting learning rate to 0.0001015444390480816.\n",
      "265/343 [======================>.......] - ETA: 1:13 - loss: 0.5061 - acc: 0.8146 - kappa: 0.9480\n",
      "Iteration 000265: OneCycleScheduler setting learning rate to 0.00010177756192326372.\n",
      "266/343 [======================>.......] - ETA: 1:12 - loss: 0.5066 - acc: 0.8139 - kappa: 0.9477\n",
      "Iteration 000266: OneCycleScheduler setting learning rate to 0.00010201068479844585.\n",
      "267/343 [======================>.......] - ETA: 1:11 - loss: 0.5083 - acc: 0.8132 - kappa: 0.9468\n",
      "Iteration 000267: OneCycleScheduler setting learning rate to 0.00010224380767362797.\n",
      "268/343 [======================>.......] - ETA: 1:10 - loss: 0.5073 - acc: 0.8134 - kappa: 0.9469\n",
      "Iteration 000268: OneCycleScheduler setting learning rate to 0.0001024769305488101.\n",
      "269/343 [======================>.......] - ETA: 1:09 - loss: 0.5074 - acc: 0.8123 - kappa: 0.9464\n",
      "Iteration 000269: OneCycleScheduler setting learning rate to 0.00010271005342399222.\n",
      "270/343 [======================>.......] - ETA: 1:08 - loss: 0.5072 - acc: 0.8125 - kappa: 0.9465\n",
      "Iteration 000270: OneCycleScheduler setting learning rate to 0.00010294317629917438.\n",
      "271/343 [======================>.......] - ETA: 1:08 - loss: 0.5076 - acc: 0.8118 - kappa: 0.9464\n",
      "Iteration 000271: OneCycleScheduler setting learning rate to 0.0001031762991743565.\n",
      "272/343 [======================>.......] - ETA: 1:07 - loss: 0.5073 - acc: 0.8120 - kappa: 0.9465\n",
      "Iteration 000272: OneCycleScheduler setting learning rate to 0.00010340942204953863.\n",
      "273/343 [======================>.......] - ETA: 1:06 - loss: 0.5075 - acc: 0.8118 - kappa: 0.9466\n",
      "Iteration 000273: OneCycleScheduler setting learning rate to 0.00010364254492472075.\n",
      "274/343 [======================>.......] - ETA: 1:05 - loss: 0.5084 - acc: 0.8111 - kappa: 0.9465\n",
      "Iteration 000274: OneCycleScheduler setting learning rate to 0.00010387566779990288.\n",
      "275/343 [=======================>......] - ETA: 1:04 - loss: 0.5093 - acc: 0.8105 - kappa: 0.9457\n",
      "Iteration 000275: OneCycleScheduler setting learning rate to 0.000104108790675085.\n",
      "276/343 [=======================>......] - ETA: 1:03 - loss: 0.5098 - acc: 0.8102 - kappa: 0.9456\n",
      "Iteration 000276: OneCycleScheduler setting learning rate to 0.00010434191355026713.\n",
      "277/343 [=======================>......] - ETA: 1:02 - loss: 0.5096 - acc: 0.8100 - kappa: 0.9457\n",
      "Iteration 000277: OneCycleScheduler setting learning rate to 0.00010457503642544925.\n",
      "278/343 [=======================>......] - ETA: 1:01 - loss: 0.5110 - acc: 0.8089 - kappa: 0.9455\n",
      "Iteration 000278: OneCycleScheduler setting learning rate to 0.00010480815930063138.\n",
      "279/343 [=======================>......] - ETA: 1:00 - loss: 0.5105 - acc: 0.8091 - kappa: 0.9456\n",
      "Iteration 000279: OneCycleScheduler setting learning rate to 0.0001050412821758135.\n",
      "280/343 [=======================>......] - ETA: 59s - loss: 0.5100 - acc: 0.8089 - kappa: 0.9457 \n",
      "Iteration 000280: OneCycleScheduler setting learning rate to 0.00010527440505099563.\n",
      "281/343 [=======================>......] - ETA: 58s - loss: 0.5096 - acc: 0.8087 - kappa: 0.9456\n",
      "Iteration 000281: OneCycleScheduler setting learning rate to 0.00010550752792617775.\n",
      "282/343 [=======================>......] - ETA: 57s - loss: 0.5093 - acc: 0.8090 - kappa: 0.9457\n",
      "Iteration 000282: OneCycleScheduler setting learning rate to 0.00010574065080135988.\n",
      "283/343 [=======================>......] - ETA: 56s - loss: 0.5091 - acc: 0.8087 - kappa: 0.9458\n",
      "Iteration 000283: OneCycleScheduler setting learning rate to 0.00010597377367654203.\n",
      "284/343 [=======================>......] - ETA: 55s - loss: 0.5097 - acc: 0.8085 - kappa: 0.9459\n",
      "Iteration 000284: OneCycleScheduler setting learning rate to 0.00010620689655172416.\n",
      "285/343 [=======================>......] - ETA: 54s - loss: 0.5088 - acc: 0.8092 - kappa: 0.9461\n",
      "Iteration 000285: OneCycleScheduler setting learning rate to 0.00010644001942690628.\n",
      "286/343 [========================>.....] - ETA: 54s - loss: 0.5111 - acc: 0.8081 - kappa: 0.9458\n",
      "Iteration 000286: OneCycleScheduler setting learning rate to 0.00010667314230208841.\n",
      "287/343 [========================>.....] - ETA: 53s - loss: 0.5164 - acc: 0.8071 - kappa: 0.9456\n",
      "Iteration 000287: OneCycleScheduler setting learning rate to 0.00010690626517727053.\n",
      "288/343 [========================>.....] - ETA: 52s - loss: 0.5151 - acc: 0.8077 - kappa: 0.9458\n",
      "Iteration 000288: OneCycleScheduler setting learning rate to 0.00010713938805245266.\n",
      "289/343 [========================>.....] - ETA: 51s - loss: 0.5147 - acc: 0.8080 - kappa: 0.9459\n",
      "Iteration 000289: OneCycleScheduler setting learning rate to 0.00010737251092763478.\n",
      "290/343 [========================>.....] - ETA: 50s - loss: 0.5150 - acc: 0.8082 - kappa: 0.9460\n",
      "Iteration 000290: OneCycleScheduler setting learning rate to 0.00010760563380281691.\n",
      "291/343 [========================>.....] - ETA: 49s - loss: 0.5170 - acc: 0.8080 - kappa: 0.9461\n",
      "Iteration 000291: OneCycleScheduler setting learning rate to 0.00010783875667799903.\n",
      "292/343 [========================>.....] - ETA: 48s - loss: 0.5166 - acc: 0.8082 - kappa: 0.9462\n",
      "Iteration 000292: OneCycleScheduler setting learning rate to 0.00010807187955318116.\n",
      "293/343 [========================>.....] - ETA: 47s - loss: 0.5156 - acc: 0.8084 - kappa: 0.9464\n",
      "Iteration 000293: OneCycleScheduler setting learning rate to 0.00010830500242836328.\n",
      "294/343 [========================>.....] - ETA: 46s - loss: 0.5151 - acc: 0.8087 - kappa: 0.9465\n",
      "Iteration 000294: OneCycleScheduler setting learning rate to 0.00010853812530354541.\n",
      "295/343 [========================>.....] - ETA: 45s - loss: 0.5164 - acc: 0.8085 - kappa: 0.9464\n",
      "Iteration 000295: OneCycleScheduler setting learning rate to 0.00010877124817872753.\n",
      "296/343 [========================>.....] - ETA: 44s - loss: 0.5172 - acc: 0.8079 - kappa: 0.9464\n",
      "Iteration 000296: OneCycleScheduler setting learning rate to 0.00010900437105390969.\n",
      "297/343 [========================>.....] - ETA: 43s - loss: 0.5173 - acc: 0.8081 - kappa: 0.9465\n",
      "Iteration 000297: OneCycleScheduler setting learning rate to 0.00010923749392909181.\n",
      "298/343 [=========================>....] - ETA: 42s - loss: 0.5164 - acc: 0.8083 - kappa: 0.9467\n",
      "Iteration 000298: OneCycleScheduler setting learning rate to 0.00010947061680427394.\n",
      "299/343 [=========================>....] - ETA: 41s - loss: 0.5160 - acc: 0.8081 - kappa: 0.9467\n",
      "Iteration 000299: OneCycleScheduler setting learning rate to 0.00010970373967945606.\n",
      "300/343 [=========================>....] - ETA: 40s - loss: 0.5159 - acc: 0.8083 - kappa: 0.9468\n",
      "Iteration 000300: OneCycleScheduler setting learning rate to 0.00010993686255463819.\n",
      "301/343 [=========================>....] - ETA: 39s - loss: 0.5151 - acc: 0.8090 - kappa: 0.9470\n",
      "Iteration 000301: OneCycleScheduler setting learning rate to 0.00011016998542982031.\n",
      "302/343 [=========================>....] - ETA: 39s - loss: 0.5151 - acc: 0.8088 - kappa: 0.9471\n",
      "Iteration 000302: OneCycleScheduler setting learning rate to 0.00011040310830500244.\n",
      "303/343 [=========================>....] - ETA: 38s - loss: 0.5141 - acc: 0.8094 - kappa: 0.9472\n",
      "Iteration 000303: OneCycleScheduler setting learning rate to 0.00011063623118018456.\n",
      "304/343 [=========================>....] - ETA: 37s - loss: 0.5133 - acc: 0.8096 - kappa: 0.9474\n",
      "Iteration 000304: OneCycleScheduler setting learning rate to 0.00011086935405536669.\n",
      "305/343 [=========================>....] - ETA: 36s - loss: 0.5130 - acc: 0.8094 - kappa: 0.9475\n",
      "Iteration 000305: OneCycleScheduler setting learning rate to 0.00011110247693054881.\n",
      "306/343 [=========================>....] - ETA: 35s - loss: 0.5124 - acc: 0.8096 - kappa: 0.9476\n",
      "Iteration 000306: OneCycleScheduler setting learning rate to 0.00011133559980573094.\n",
      "307/343 [=========================>....] - ETA: 34s - loss: 0.5122 - acc: 0.8099 - kappa: 0.9478\n",
      "Iteration 000307: OneCycleScheduler setting learning rate to 0.00011156872268091306.\n",
      "308/343 [=========================>....] - ETA: 33s - loss: 0.5117 - acc: 0.8101 - kappa: 0.9479\n",
      "Iteration 000308: OneCycleScheduler setting learning rate to 0.00011180184555609519.\n",
      "309/343 [==========================>...] - ETA: 32s - loss: 0.5109 - acc: 0.8107 - kappa: 0.9481\n",
      "Iteration 000309: OneCycleScheduler setting learning rate to 0.00011203496843127731.\n",
      "310/343 [==========================>...] - ETA: 31s - loss: 0.5101 - acc: 0.8109 - kappa: 0.9482\n",
      "Iteration 000310: OneCycleScheduler setting learning rate to 0.00011226809130645947.\n",
      "311/343 [==========================>...] - ETA: 30s - loss: 0.5109 - acc: 0.8103 - kappa: 0.9477\n",
      "Iteration 000311: OneCycleScheduler setting learning rate to 0.00011250121418164159.\n",
      "312/343 [==========================>...] - ETA: 29s - loss: 0.5096 - acc: 0.8109 - kappa: 0.9479\n",
      "Iteration 000312: OneCycleScheduler setting learning rate to 0.00011273433705682372.\n",
      "313/343 [==========================>...] - ETA: 28s - loss: 0.5082 - acc: 0.8115 - kappa: 0.9481\n",
      "Iteration 000313: OneCycleScheduler setting learning rate to 0.00011296745993200584.\n",
      "314/343 [==========================>...] - ETA: 27s - loss: 0.5100 - acc: 0.8109 - kappa: 0.9474\n",
      "Iteration 000314: OneCycleScheduler setting learning rate to 0.00011320058280718797.\n",
      "315/343 [==========================>...] - ETA: 26s - loss: 0.5108 - acc: 0.8107 - kappa: 0.9474\n",
      "Iteration 000315: OneCycleScheduler setting learning rate to 0.00011343370568237009.\n",
      "316/343 [==========================>...] - ETA: 25s - loss: 0.5111 - acc: 0.8105 - kappa: 0.9475\n",
      "Iteration 000316: OneCycleScheduler setting learning rate to 0.00011366682855755222.\n",
      "317/343 [==========================>...] - ETA: 24s - loss: 0.5145 - acc: 0.8095 - kappa: 0.9470\n",
      "Iteration 000317: OneCycleScheduler setting learning rate to 0.00011389995143273434.\n",
      "318/343 [==========================>...] - ETA: 23s - loss: 0.5136 - acc: 0.8097 - kappa: 0.9472\n",
      "Iteration 000318: OneCycleScheduler setting learning rate to 0.00011413307430791647.\n",
      "319/343 [==========================>...] - ETA: 22s - loss: 0.5138 - acc: 0.8096 - kappa: 0.9472\n",
      "Iteration 000319: OneCycleScheduler setting learning rate to 0.0001143661971830986.\n",
      "320/343 [==========================>...] - ETA: 21s - loss: 0.5143 - acc: 0.8090 - kappa: 0.9470\n",
      "Iteration 000320: OneCycleScheduler setting learning rate to 0.00011459932005828072.\n",
      "321/343 [===========================>..] - ETA: 20s - loss: 0.5134 - acc: 0.8096 - kappa: 0.9472\n",
      "Iteration 000321: OneCycleScheduler setting learning rate to 0.00011483244293346284.\n",
      "322/343 [===========================>..] - ETA: 20s - loss: 0.5129 - acc: 0.8094 - kappa: 0.9473\n",
      "Iteration 000322: OneCycleScheduler setting learning rate to 0.00011506556580864497.\n",
      "323/343 [===========================>..] - ETA: 19s - loss: 0.5157 - acc: 0.8092 - kappa: 0.9470\n",
      "Iteration 000323: OneCycleScheduler setting learning rate to 0.00011529868868382712.\n",
      "324/343 [===========================>..] - ETA: 18s - loss: 0.5154 - acc: 0.8094 - kappa: 0.9472\n",
      "Iteration 000324: OneCycleScheduler setting learning rate to 0.00011553181155900925.\n",
      "325/343 [===========================>..] - ETA: 17s - loss: 0.5155 - acc: 0.8092 - kappa: 0.9471\n",
      "Iteration 000325: OneCycleScheduler setting learning rate to 0.00011576493443419137.\n",
      "326/343 [===========================>..] - ETA: 16s - loss: 0.5164 - acc: 0.8087 - kappa: 0.9471\n",
      "Iteration 000326: OneCycleScheduler setting learning rate to 0.0001159980573093735.\n",
      "327/343 [===========================>..] - ETA: 15s - loss: 0.5170 - acc: 0.8085 - kappa: 0.9470\n",
      "Iteration 000327: OneCycleScheduler setting learning rate to 0.00011623118018455562.\n",
      "328/343 [===========================>..] - ETA: 14s - loss: 0.5170 - acc: 0.8087 - kappa: 0.9471\n",
      "Iteration 000328: OneCycleScheduler setting learning rate to 0.00011646430305973775.\n",
      "329/343 [===========================>..] - ETA: 13s - loss: 0.5165 - acc: 0.8085 - kappa: 0.9470\n",
      "Iteration 000329: OneCycleScheduler setting learning rate to 0.00011669742593491987.\n",
      "330/343 [===========================>..] - ETA: 12s - loss: 0.5158 - acc: 0.8091 - kappa: 0.9472\n",
      "Iteration 000330: OneCycleScheduler setting learning rate to 0.000116930548810102.\n",
      "331/343 [===========================>..] - ETA: 11s - loss: 0.5154 - acc: 0.8089 - kappa: 0.9472\n",
      "Iteration 000331: OneCycleScheduler setting learning rate to 0.00011716367168528412.\n",
      "332/343 [============================>.] - ETA: 10s - loss: 0.5163 - acc: 0.8087 - kappa: 0.9473\n",
      "Iteration 000332: OneCycleScheduler setting learning rate to 0.00011739679456046625.\n",
      "333/343 [============================>.] - ETA: 9s - loss: 0.5166 - acc: 0.8082 - kappa: 0.9471 \n",
      "Iteration 000333: OneCycleScheduler setting learning rate to 0.00011762991743564837.\n",
      "334/343 [============================>.] - ETA: 8s - loss: 0.5175 - acc: 0.8084 - kappa: 0.9470\n",
      "Iteration 000334: OneCycleScheduler setting learning rate to 0.0001178630403108305.\n",
      "335/343 [============================>.] - ETA: 7s - loss: 0.5171 - acc: 0.8086 - kappa: 0.9472\n",
      "Iteration 000335: OneCycleScheduler setting learning rate to 0.00011809616318601262.\n",
      "336/343 [============================>.] - ETA: 6s - loss: 0.5161 - acc: 0.8088 - kappa: 0.9472\n",
      "Iteration 000336: OneCycleScheduler setting learning rate to 0.00011832928606119478.\n",
      "337/343 [============================>.] - ETA: 5s - loss: 0.5150 - acc: 0.8093 - kappa: 0.9474\n",
      "Iteration 000337: OneCycleScheduler setting learning rate to 0.0001185624089363769.\n",
      "338/343 [============================>.] - ETA: 4s - loss: 0.5143 - acc: 0.8095 - kappa: 0.9475\n",
      "Iteration 000338: OneCycleScheduler setting learning rate to 0.00011879553181155903.\n",
      "339/343 [============================>.] - ETA: 3s - loss: 0.5145 - acc: 0.8101 - kappa: 0.9476\n",
      "Iteration 000339: OneCycleScheduler setting learning rate to 0.00011902865468674115.\n",
      "340/343 [============================>.] - ETA: 2s - loss: 0.5146 - acc: 0.8103 - kappa: 0.9477\n",
      "Iteration 000340: OneCycleScheduler setting learning rate to 0.00011926177756192328.\n",
      "341/343 [============================>.] - ETA: 1s - loss: 0.5148 - acc: 0.8101 - kappa: 0.9477\n",
      "Iteration 000341: OneCycleScheduler setting learning rate to 0.0001194949004371054.\n",
      "342/343 [============================>.] - ETA: 0s - loss: 0.5145 - acc: 0.8107 - kappa: 0.9479\n",
      "Iteration 000342: OneCycleScheduler setting learning rate to 0.00011972802331228753.\n",
      "343/343 [==============================] - 420s 1s/step - loss: 0.5159 - acc: 0.8101 - kappa: 0.9478 - val_loss: 0.7014 - val_acc: 0.8018 - val_kappa: 0.9278\n",
      "Epoch 6/30\n",
      "\n",
      "Iteration 000000: OneCycleScheduler setting learning rate to 4e-05.\n",
      "  1/343 [..............................] - ETA: 45s - loss: 0.6390 - acc: 0.8750 - kappa: 0.9922\n",
      "Iteration 000001: OneCycleScheduler setting learning rate to 4.023312287518213e-05.\n",
      "  2/343 [..............................] - ETA: 44s - loss: 0.5229 - acc: 0.8750 - kappa: 0.9922\n",
      "Iteration 000002: OneCycleScheduler setting learning rate to 4.046624575036426e-05.\n",
      "  3/343 [..............................] - ETA: 44s - loss: 0.4329 - acc: 0.9167 - kappa: 0.9948\n",
      "Iteration 000003: OneCycleScheduler setting learning rate to 4.0699368625546386e-05.\n",
      "  4/343 [..............................] - ETA: 44s - loss: 0.4266 - acc: 0.8750 - kappa: 0.9785\n",
      "Iteration 000004: OneCycleScheduler setting learning rate to 4.093249150072851e-05.\n",
      "  5/343 [..............................] - ETA: 46s - loss: 0.3997 - acc: 0.9000 - kappa: 0.9828\n",
      "Iteration 000005: OneCycleScheduler setting learning rate to 4.1165614375910636e-05.\n",
      "  6/343 [..............................] - ETA: 45s - loss: 0.4101 - acc: 0.8958 - kappa: 0.9844\n",
      "Iteration 000006: OneCycleScheduler setting learning rate to 4.139873725109277e-05.\n",
      "  7/343 [..............................] - ETA: 44s - loss: 0.3678 - acc: 0.9107 - kappa: 0.9866\n",
      "Iteration 000007: OneCycleScheduler setting learning rate to 4.1631860126274893e-05.\n",
      "  8/343 [..............................] - ETA: 44s - loss: 0.3755 - acc: 0.8906 - kappa: 0.9844\n",
      "Iteration 000008: OneCycleScheduler setting learning rate to 4.186498300145702e-05.\n",
      "  9/343 [..............................] - ETA: 44s - loss: 0.3536 - acc: 0.9028 - kappa: 0.9861\n",
      "Iteration 000009: OneCycleScheduler setting learning rate to 4.209810587663915e-05.\n",
      " 10/343 [..............................] - ETA: 44s - loss: 0.3390 - acc: 0.9125 - kappa: 0.9875\n",
      "Iteration 000010: OneCycleScheduler setting learning rate to 4.2331228751821276e-05.\n",
      " 11/343 [..............................] - ETA: 44s - loss: 0.3813 - acc: 0.8864 - kappa: 0.9773\n",
      "Iteration 000011: OneCycleScheduler setting learning rate to 4.25643516270034e-05.\n",
      " 12/343 [>.............................] - ETA: 51s - loss: 0.4647 - acc: 0.8646 - kappa: 0.9688\n",
      "Iteration 000012: OneCycleScheduler setting learning rate to 4.279747450218553e-05.\n",
      " 13/343 [>.............................] - ETA: 1:22 - loss: 0.4438 - acc: 0.8750 - kappa: 0.9712\n",
      "Iteration 000013: OneCycleScheduler setting learning rate to 4.303059737736766e-05.\n",
      " 14/343 [>.............................] - ETA: 1:54 - loss: 0.4482 - acc: 0.8750 - kappa: 0.9710\n",
      "Iteration 000014: OneCycleScheduler setting learning rate to 4.3263720252549784e-05.\n",
      " 15/343 [>.............................] - ETA: 2:10 - loss: 0.4617 - acc: 0.8583 - kappa: 0.9682\n",
      "Iteration 000015: OneCycleScheduler setting learning rate to 4.3496843127731916e-05.\n",
      " 16/343 [>.............................] - ETA: 2:29 - loss: 0.4469 - acc: 0.8594 - kappa: 0.9697\n",
      "Iteration 000016: OneCycleScheduler setting learning rate to 4.372996600291404e-05.\n",
      " 17/343 [>.............................] - ETA: 2:44 - loss: 0.4449 - acc: 0.8529 - kappa: 0.9697\n",
      "Iteration 000017: OneCycleScheduler setting learning rate to 4.3963088878096166e-05.\n",
      " 18/343 [>.............................] - ETA: 2:54 - loss: 0.4403 - acc: 0.8542 - kappa: 0.9696\n",
      "Iteration 000018: OneCycleScheduler setting learning rate to 4.419621175327829e-05.\n",
      " 19/343 [>.............................] - ETA: 3:09 - loss: 0.4399 - acc: 0.8553 - kappa: 0.9708\n",
      "Iteration 000019: OneCycleScheduler setting learning rate to 4.442933462846042e-05.\n",
      " 20/343 [>.............................] - ETA: 3:31 - loss: 0.4436 - acc: 0.8500 - kappa: 0.9707\n",
      "Iteration 000020: OneCycleScheduler setting learning rate to 4.466245750364255e-05.\n",
      " 21/343 [>.............................] - ETA: 3:34 - loss: 0.4511 - acc: 0.8452 - kappa: 0.9688\n",
      "Iteration 000021: OneCycleScheduler setting learning rate to 4.4895580378824674e-05.\n",
      " 22/343 [>.............................] - ETA: 3:38 - loss: 0.4830 - acc: 0.8352 - kappa: 0.9670\n",
      "Iteration 000022: OneCycleScheduler setting learning rate to 4.5128703254006806e-05.\n",
      " 23/343 [=>............................] - ETA: 3:40 - loss: 0.4683 - acc: 0.8424 - kappa: 0.9684\n",
      "Iteration 000023: OneCycleScheduler setting learning rate to 4.536182612918893e-05.\n",
      " 24/343 [=>............................] - ETA: 3:42 - loss: 0.4767 - acc: 0.8333 - kappa: 0.9668\n",
      "Iteration 000024: OneCycleScheduler setting learning rate to 4.5594949004371056e-05.\n",
      " 25/343 [=>............................] - ETA: 3:44 - loss: 0.4698 - acc: 0.8350 - kappa: 0.9678\n",
      "Iteration 000025: OneCycleScheduler setting learning rate to 4.582807187955318e-05.\n",
      " 26/343 [=>............................] - ETA: 3:46 - loss: 0.4658 - acc: 0.8317 - kappa: 0.9678\n",
      "Iteration 000026: OneCycleScheduler setting learning rate to 4.606119475473531e-05.\n",
      " 27/343 [=>............................] - ETA: 3:50 - loss: 0.4633 - acc: 0.8333 - kappa: 0.9679\n",
      "Iteration 000027: OneCycleScheduler setting learning rate to 4.629431762991744e-05.\n",
      " 28/343 [=>............................] - ETA: 3:57 - loss: 0.4652 - acc: 0.8348 - kappa: 0.9688\n",
      "Iteration 000028: OneCycleScheduler setting learning rate to 4.6527440505099564e-05.\n",
      " 29/343 [=>............................] - ETA: 3:56 - loss: 0.4615 - acc: 0.8362 - kappa: 0.9696\n",
      "Iteration 000029: OneCycleScheduler setting learning rate to 4.6760563380281696e-05.\n",
      " 30/343 [=>............................] - ETA: 3:59 - loss: 0.4617 - acc: 0.8333 - kappa: 0.9695\n",
      "Iteration 000030: OneCycleScheduler setting learning rate to 4.699368625546382e-05.\n",
      " 31/343 [=>............................] - ETA: 4:00 - loss: 0.4556 - acc: 0.8347 - kappa: 0.9703\n",
      "Iteration 000031: OneCycleScheduler setting learning rate to 4.7226809130645946e-05.\n",
      " 32/343 [=>............................] - ETA: 4:03 - loss: 0.4463 - acc: 0.8398 - kappa: 0.9712\n",
      "Iteration 000032: OneCycleScheduler setting learning rate to 4.745993200582808e-05.\n",
      " 33/343 [=>............................] - ETA: 4:08 - loss: 0.4410 - acc: 0.8447 - kappa: 0.9721\n",
      "Iteration 000033: OneCycleScheduler setting learning rate to 4.7693054881010203e-05.\n",
      " 34/343 [=>............................] - ETA: 4:12 - loss: 0.4642 - acc: 0.8382 - kappa: 0.9692\n",
      "Iteration 000034: OneCycleScheduler setting learning rate to 4.792617775619233e-05.\n",
      " 35/343 [==>...........................] - ETA: 4:11 - loss: 0.4611 - acc: 0.8393 - kappa: 0.9699\n",
      "Iteration 000035: OneCycleScheduler setting learning rate to 4.815930063137446e-05.\n",
      " 36/343 [==>...........................] - ETA: 4:08 - loss: 0.4618 - acc: 0.8403 - kappa: 0.9698\n",
      "Iteration 000036: OneCycleScheduler setting learning rate to 4.8392423506556586e-05.\n",
      " 37/343 [==>...........................] - ETA: 4:07 - loss: 0.4524 - acc: 0.8446 - kappa: 0.9707\n",
      "Iteration 000037: OneCycleScheduler setting learning rate to 4.862554638173871e-05.\n",
      " 38/343 [==>...........................] - ETA: 4:10 - loss: 0.4497 - acc: 0.8454 - kappa: 0.9706\n",
      "Iteration 000038: OneCycleScheduler setting learning rate to 4.8858669256920836e-05.\n",
      " 39/343 [==>...........................] - ETA: 4:10 - loss: 0.4449 - acc: 0.8462 - kappa: 0.9712\n",
      "Iteration 000039: OneCycleScheduler setting learning rate to 4.909179213210297e-05.\n",
      " 40/343 [==>...........................] - ETA: 4:07 - loss: 0.4368 - acc: 0.8500 - kappa: 0.9719\n",
      "Iteration 000040: OneCycleScheduler setting learning rate to 4.9324915007285094e-05.\n",
      " 41/343 [==>...........................] - ETA: 4:10 - loss: 0.4451 - acc: 0.8476 - kappa: 0.9695\n",
      "Iteration 000041: OneCycleScheduler setting learning rate to 4.955803788246722e-05.\n",
      " 42/343 [==>...........................] - ETA: 4:09 - loss: 0.4466 - acc: 0.8452 - kappa: 0.9673\n",
      "Iteration 000042: OneCycleScheduler setting learning rate to 4.979116075764935e-05.\n",
      " 43/343 [==>...........................] - ETA: 4:08 - loss: 0.4397 - acc: 0.8459 - kappa: 0.9678\n",
      "Iteration 000043: OneCycleScheduler setting learning rate to 5.0024283632831476e-05.\n",
      " 44/343 [==>...........................] - ETA: 4:07 - loss: 0.4330 - acc: 0.8494 - kappa: 0.9686\n",
      "Iteration 000044: OneCycleScheduler setting learning rate to 5.02574065080136e-05.\n",
      " 45/343 [==>...........................] - ETA: 4:08 - loss: 0.4299 - acc: 0.8528 - kappa: 0.9693\n",
      "Iteration 000045: OneCycleScheduler setting learning rate to 5.0490529383195726e-05.\n",
      " 46/343 [===>..........................] - ETA: 4:08 - loss: 0.4258 - acc: 0.8560 - kappa: 0.9699\n",
      "Iteration 000046: OneCycleScheduler setting learning rate to 5.072365225837786e-05.\n",
      " 47/343 [===>..........................] - ETA: 4:07 - loss: 0.4198 - acc: 0.8590 - kappa: 0.9706\n",
      "Iteration 000047: OneCycleScheduler setting learning rate to 5.0956775133559984e-05.\n",
      " 48/343 [===>..........................] - ETA: 4:07 - loss: 0.4189 - acc: 0.8594 - kappa: 0.9705\n",
      "Iteration 000048: OneCycleScheduler setting learning rate to 5.1189898008742116e-05.\n",
      " 49/343 [===>..........................] - ETA: 4:07 - loss: 0.4194 - acc: 0.8546 - kappa: 0.9697\n",
      "Iteration 000049: OneCycleScheduler setting learning rate to 5.142302088392424e-05.\n",
      " 50/343 [===>..........................] - ETA: 4:08 - loss: 0.4333 - acc: 0.8525 - kappa: 0.9664\n",
      "Iteration 000050: OneCycleScheduler setting learning rate to 5.1656143759106366e-05.\n",
      " 51/343 [===>..........................] - ETA: 4:07 - loss: 0.4294 - acc: 0.8554 - kappa: 0.9671\n",
      "Iteration 000051: OneCycleScheduler setting learning rate to 5.188926663428849e-05.\n",
      " 52/343 [===>..........................] - ETA: 4:07 - loss: 0.4289 - acc: 0.8558 - kappa: 0.9675\n",
      "Iteration 000052: OneCycleScheduler setting learning rate to 5.212238950947062e-05.\n",
      " 53/343 [===>..........................] - ETA: 4:08 - loss: 0.4312 - acc: 0.8561 - kappa: 0.9680\n",
      "Iteration 000053: OneCycleScheduler setting learning rate to 5.235551238465275e-05.\n",
      " 54/343 [===>..........................] - ETA: 4:08 - loss: 0.4365 - acc: 0.8542 - kappa: 0.9680\n",
      "Iteration 000054: OneCycleScheduler setting learning rate to 5.2588635259834874e-05.\n",
      " 55/343 [===>..........................] - ETA: 4:09 - loss: 0.4363 - acc: 0.8545 - kappa: 0.9680\n",
      "Iteration 000055: OneCycleScheduler setting learning rate to 5.2821758135017006e-05.\n",
      " 56/343 [===>..........................] - ETA: 4:09 - loss: 0.4317 - acc: 0.8571 - kappa: 0.9686\n",
      "Iteration 000056: OneCycleScheduler setting learning rate to 5.305488101019913e-05.\n",
      " 57/343 [===>..........................] - ETA: 4:08 - loss: 0.4393 - acc: 0.8509 - kappa: 0.9670\n",
      "Iteration 000057: OneCycleScheduler setting learning rate to 5.3288003885381256e-05.\n",
      " 58/343 [====>.........................] - ETA: 4:06 - loss: 0.4393 - acc: 0.8513 - kappa: 0.9674\n",
      "Iteration 000058: OneCycleScheduler setting learning rate to 5.352112676056338e-05.\n",
      " 59/343 [====>.........................] - ETA: 4:06 - loss: 0.4381 - acc: 0.8538 - kappa: 0.9680\n",
      "Iteration 000059: OneCycleScheduler setting learning rate to 5.3754249635745514e-05.\n",
      " 60/343 [====>.........................] - ETA: 4:04 - loss: 0.4354 - acc: 0.8542 - kappa: 0.9684\n",
      "Iteration 000060: OneCycleScheduler setting learning rate to 5.398737251092764e-05.\n",
      " 61/343 [====>.........................] - ETA: 4:04 - loss: 0.4320 - acc: 0.8545 - kappa: 0.9688\n",
      "Iteration 000061: OneCycleScheduler setting learning rate to 5.4220495386109764e-05.\n",
      " 62/343 [====>.........................] - ETA: 4:03 - loss: 0.4363 - acc: 0.8528 - kappa: 0.9681\n",
      "Iteration 000062: OneCycleScheduler setting learning rate to 5.4453618261291896e-05.\n",
      " 63/343 [====>.........................] - ETA: 4:04 - loss: 0.4409 - acc: 0.8512 - kappa: 0.9675\n",
      "Iteration 000063: OneCycleScheduler setting learning rate to 5.468674113647402e-05.\n",
      " 64/343 [====>.........................] - ETA: 4:03 - loss: 0.4385 - acc: 0.8516 - kappa: 0.9679\n",
      "Iteration 000064: OneCycleScheduler setting learning rate to 5.4919864011656146e-05.\n",
      " 65/343 [====>.........................] - ETA: 4:02 - loss: 0.4358 - acc: 0.8519 - kappa: 0.9683\n",
      "Iteration 000065: OneCycleScheduler setting learning rate to 5.515298688683827e-05.\n",
      " 66/343 [====>.........................] - ETA: 4:01 - loss: 0.4336 - acc: 0.8523 - kappa: 0.9686\n",
      "Iteration 000066: OneCycleScheduler setting learning rate to 5.5386109762020404e-05.\n",
      " 67/343 [====>.........................] - ETA: 4:01 - loss: 0.4659 - acc: 0.8470 - kappa: 0.9649\n",
      "Iteration 000067: OneCycleScheduler setting learning rate to 5.561923263720253e-05.\n",
      " 68/343 [====>.........................] - ETA: 3:59 - loss: 0.4616 - acc: 0.8474 - kappa: 0.9653\n",
      "Iteration 000068: OneCycleScheduler setting learning rate to 5.585235551238466e-05.\n",
      " 69/343 [=====>........................] - ETA: 3:59 - loss: 0.4595 - acc: 0.8460 - kappa: 0.9654\n",
      "Iteration 000069: OneCycleScheduler setting learning rate to 5.6085478387566786e-05.\n",
      " 70/343 [=====>........................] - ETA: 4:00 - loss: 0.4732 - acc: 0.8393 - kappa: 0.9618\n",
      "Iteration 000070: OneCycleScheduler setting learning rate to 5.631860126274891e-05.\n",
      " 71/343 [=====>........................] - ETA: 3:57 - loss: 0.4709 - acc: 0.8398 - kappa: 0.9623\n",
      "Iteration 000071: OneCycleScheduler setting learning rate to 5.6551724137931037e-05.\n",
      " 72/343 [=====>........................] - ETA: 3:58 - loss: 0.4728 - acc: 0.8385 - kappa: 0.9618\n",
      "Iteration 000072: OneCycleScheduler setting learning rate to 5.678484701311316e-05.\n",
      " 73/343 [=====>........................] - ETA: 3:57 - loss: 0.4793 - acc: 0.8373 - kappa: 0.9606\n",
      "Iteration 000073: OneCycleScheduler setting learning rate to 5.7017969888295294e-05.\n",
      " 74/343 [=====>........................] - ETA: 3:58 - loss: 0.4942 - acc: 0.8328 - kappa: 0.9585\n",
      "Iteration 000074: OneCycleScheduler setting learning rate to 5.7251092763477426e-05.\n",
      " 75/343 [=====>........................] - ETA: 3:57 - loss: 0.4908 - acc: 0.8350 - kappa: 0.9591\n",
      "Iteration 000075: OneCycleScheduler setting learning rate to 5.748421563865955e-05.\n",
      " 76/343 [=====>........................] - ETA: 3:57 - loss: 0.4915 - acc: 0.8339 - kappa: 0.9587\n",
      "Iteration 000076: OneCycleScheduler setting learning rate to 5.7717338513841676e-05.\n",
      " 77/343 [=====>........................] - ETA: 3:56 - loss: 0.4907 - acc: 0.8328 - kappa: 0.9588\n",
      "Iteration 000077: OneCycleScheduler setting learning rate to 5.79504613890238e-05.\n",
      " 78/343 [=====>........................] - ETA: 3:56 - loss: 0.4957 - acc: 0.8317 - kappa: 0.9584\n",
      "Iteration 000078: OneCycleScheduler setting learning rate to 5.818358426420593e-05.\n",
      " 79/343 [=====>........................] - ETA: 3:55 - loss: 0.4986 - acc: 0.8291 - kappa: 0.9581\n",
      "Iteration 000079: OneCycleScheduler setting learning rate to 5.841670713938806e-05.\n",
      " 80/343 [=====>........................] - ETA: 3:55 - loss: 0.4965 - acc: 0.8281 - kappa: 0.9582\n",
      "Iteration 000080: OneCycleScheduler setting learning rate to 5.8649830014570184e-05.\n",
      " 81/343 [======>.......................] - ETA: 3:54 - loss: 0.4973 - acc: 0.8272 - kappa: 0.9572\n",
      "Iteration 000081: OneCycleScheduler setting learning rate to 5.8882952889752316e-05.\n",
      " 82/343 [======>.......................] - ETA: 3:53 - loss: 0.4951 - acc: 0.8293 - kappa: 0.9577\n",
      "Iteration 000082: OneCycleScheduler setting learning rate to 5.911607576493444e-05.\n",
      " 83/343 [======>.......................] - ETA: 3:52 - loss: 0.4980 - acc: 0.8268 - kappa: 0.9567\n",
      "Iteration 000083: OneCycleScheduler setting learning rate to 5.9349198640116566e-05.\n",
      " 84/343 [======>.......................] - ETA: 3:52 - loss: 0.5006 - acc: 0.8259 - kappa: 0.9568\n",
      "Iteration 000084: OneCycleScheduler setting learning rate to 5.958232151529869e-05.\n",
      " 85/343 [======>.......................] - ETA: 3:52 - loss: 0.4970 - acc: 0.8265 - kappa: 0.9573\n",
      "Iteration 000085: OneCycleScheduler setting learning rate to 5.981544439048082e-05.\n",
      " 86/343 [======>.......................] - ETA: 3:50 - loss: 0.5001 - acc: 0.8241 - kappa: 0.9563\n",
      "Iteration 000086: OneCycleScheduler setting learning rate to 6.004856726566295e-05.\n",
      " 87/343 [======>.......................] - ETA: 3:49 - loss: 0.4990 - acc: 0.8233 - kappa: 0.9564\n",
      "Iteration 000087: OneCycleScheduler setting learning rate to 6.0281690140845074e-05.\n",
      " 88/343 [======>.......................] - ETA: 3:48 - loss: 0.4954 - acc: 0.8253 - kappa: 0.9569\n",
      "Iteration 000088: OneCycleScheduler setting learning rate to 6.0514813016027206e-05.\n",
      " 89/343 [======>.......................] - ETA: 3:46 - loss: 0.4911 - acc: 0.8272 - kappa: 0.9574\n",
      "Iteration 000089: OneCycleScheduler setting learning rate to 6.074793589120933e-05.\n",
      " 90/343 [======>.......................] - ETA: 3:45 - loss: 0.4909 - acc: 0.8278 - kappa: 0.9576\n",
      "Iteration 000090: OneCycleScheduler setting learning rate to 6.0981058766391456e-05.\n",
      " 91/343 [======>.......................] - ETA: 3:44 - loss: 0.4883 - acc: 0.8297 - kappa: 0.9580\n",
      "Iteration 000091: OneCycleScheduler setting learning rate to 6.121418164157358e-05.\n",
      " 92/343 [=======>......................] - ETA: 3:43 - loss: 0.4858 - acc: 0.8315 - kappa: 0.9585\n",
      "Iteration 000092: OneCycleScheduler setting learning rate to 6.144730451675571e-05.\n",
      " 93/343 [=======>......................] - ETA: 3:42 - loss: 0.4851 - acc: 0.8320 - kappa: 0.9586\n",
      "Iteration 000093: OneCycleScheduler setting learning rate to 6.168042739193783e-05.\n",
      " 94/343 [=======>......................] - ETA: 3:42 - loss: 0.4836 - acc: 0.8324 - kappa: 0.9587\n",
      "Iteration 000094: OneCycleScheduler setting learning rate to 6.191355026711997e-05.\n",
      " 95/343 [=======>......................] - ETA: 3:41 - loss: 0.4868 - acc: 0.8316 - kappa: 0.9584\n",
      "Iteration 000095: OneCycleScheduler setting learning rate to 6.21466731423021e-05.\n",
      " 96/343 [=======>......................] - ETA: 3:40 - loss: 0.4910 - acc: 0.8294 - kappa: 0.9568\n",
      "Iteration 000096: OneCycleScheduler setting learning rate to 6.237979601748422e-05.\n",
      " 97/343 [=======>......................] - ETA: 3:40 - loss: 0.4883 - acc: 0.8299 - kappa: 0.9572\n",
      "Iteration 000097: OneCycleScheduler setting learning rate to 6.261291889266635e-05.\n",
      " 98/343 [=======>......................] - ETA: 3:38 - loss: 0.4889 - acc: 0.8291 - kappa: 0.9573\n",
      "Iteration 000098: OneCycleScheduler setting learning rate to 6.284604176784847e-05.\n",
      " 99/343 [=======>......................] - ETA: 3:38 - loss: 0.4928 - acc: 0.8283 - kappa: 0.9574\n",
      "Iteration 000099: OneCycleScheduler setting learning rate to 6.307916464303061e-05.\n",
      "100/343 [=======>......................] - ETA: 3:37 - loss: 0.4902 - acc: 0.8287 - kappa: 0.9577\n",
      "Iteration 000100: OneCycleScheduler setting learning rate to 6.331228751821274e-05.\n",
      "101/343 [=======>......................] - ETA: 3:36 - loss: 0.4872 - acc: 0.8304 - kappa: 0.9582\n",
      "Iteration 000101: OneCycleScheduler setting learning rate to 6.354541039339486e-05.\n",
      "102/343 [=======>......................] - ETA: 3:35 - loss: 0.4851 - acc: 0.8321 - kappa: 0.9586\n",
      "Iteration 000102: OneCycleScheduler setting learning rate to 6.377853326857699e-05.\n",
      "103/343 [========>.....................] - ETA: 3:34 - loss: 0.4898 - acc: 0.8301 - kappa: 0.9583\n",
      "Iteration 000103: OneCycleScheduler setting learning rate to 6.401165614375911e-05.\n",
      "104/343 [========>.....................] - ETA: 3:33 - loss: 0.4879 - acc: 0.8305 - kappa: 0.9586\n",
      "Iteration 000104: OneCycleScheduler setting learning rate to 6.424477901894124e-05.\n",
      "105/343 [========>.....................] - ETA: 3:31 - loss: 0.4858 - acc: 0.8310 - kappa: 0.9589\n",
      "Iteration 000105: OneCycleScheduler setting learning rate to 6.447790189412336e-05.\n",
      "106/343 [========>.....................] - ETA: 3:31 - loss: 0.4862 - acc: 0.8302 - kappa: 0.9587\n",
      "Iteration 000106: OneCycleScheduler setting learning rate to 6.471102476930549e-05.\n",
      "107/343 [========>.....................] - ETA: 3:30 - loss: 0.4831 - acc: 0.8318 - kappa: 0.9590\n",
      "Iteration 000107: OneCycleScheduler setting learning rate to 6.494414764448761e-05.\n",
      "108/343 [========>.....................] - ETA: 3:29 - loss: 0.4807 - acc: 0.8333 - kappa: 0.9594\n",
      "Iteration 000108: OneCycleScheduler setting learning rate to 6.517727051966975e-05.\n",
      "109/343 [========>.....................] - ETA: 3:29 - loss: 0.4802 - acc: 0.8326 - kappa: 0.9595\n",
      "Iteration 000109: OneCycleScheduler setting learning rate to 6.541039339485188e-05.\n",
      "110/343 [========>.....................] - ETA: 3:29 - loss: 0.4806 - acc: 0.8318 - kappa: 0.9596\n",
      "Iteration 000110: OneCycleScheduler setting learning rate to 6.5643516270034e-05.\n",
      "111/343 [========>.....................] - ETA: 3:28 - loss: 0.4791 - acc: 0.8333 - kappa: 0.9600\n",
      "Iteration 000111: OneCycleScheduler setting learning rate to 6.587663914521613e-05.\n",
      "112/343 [========>.....................] - ETA: 3:28 - loss: 0.4780 - acc: 0.8326 - kappa: 0.9600\n",
      "Iteration 000112: OneCycleScheduler setting learning rate to 6.610976202039825e-05.\n",
      "113/343 [========>.....................] - ETA: 3:27 - loss: 0.4780 - acc: 0.8330 - kappa: 0.9603\n",
      "Iteration 000113: OneCycleScheduler setting learning rate to 6.634288489558039e-05.\n",
      "114/343 [========>.....................] - ETA: 3:27 - loss: 0.4764 - acc: 0.8344 - kappa: 0.9607\n",
      "Iteration 000114: OneCycleScheduler setting learning rate to 6.657600777076252e-05.\n",
      "115/343 [=========>....................] - ETA: 3:26 - loss: 0.4804 - acc: 0.8337 - kappa: 0.9604\n",
      "Iteration 000115: OneCycleScheduler setting learning rate to 6.680913064594464e-05.\n",
      "116/343 [=========>....................] - ETA: 3:25 - loss: 0.4795 - acc: 0.8341 - kappa: 0.9607\n",
      "Iteration 000116: OneCycleScheduler setting learning rate to 6.704225352112677e-05.\n",
      "117/343 [=========>....................] - ETA: 3:24 - loss: 0.4780 - acc: 0.8355 - kappa: 0.9610\n",
      "Iteration 000117: OneCycleScheduler setting learning rate to 6.727537639630889e-05.\n",
      "118/343 [=========>....................] - ETA: 3:24 - loss: 0.4789 - acc: 0.8358 - kappa: 0.9613\n",
      "Iteration 000118: OneCycleScheduler setting learning rate to 6.750849927149102e-05.\n",
      "119/343 [=========>....................] - ETA: 3:23 - loss: 0.4816 - acc: 0.8351 - kappa: 0.9610\n",
      "Iteration 000119: OneCycleScheduler setting learning rate to 6.774162214667314e-05.\n",
      "120/343 [=========>....................] - ETA: 3:22 - loss: 0.4848 - acc: 0.8344 - kappa: 0.9607\n",
      "Iteration 000120: OneCycleScheduler setting learning rate to 6.797474502185527e-05.\n",
      "121/343 [=========>....................] - ETA: 3:21 - loss: 0.4825 - acc: 0.8347 - kappa: 0.9610\n",
      "Iteration 000121: OneCycleScheduler setting learning rate to 6.82078678970374e-05.\n",
      "122/343 [=========>....................] - ETA: 3:20 - loss: 0.4841 - acc: 0.8340 - kappa: 0.9611\n",
      "Iteration 000122: OneCycleScheduler setting learning rate to 6.844099077221953e-05.\n",
      "123/343 [=========>....................] - ETA: 3:20 - loss: 0.4830 - acc: 0.8343 - kappa: 0.9613\n",
      "Iteration 000123: OneCycleScheduler setting learning rate to 6.867411364740166e-05.\n",
      "124/343 [=========>....................] - ETA: 3:19 - loss: 0.4840 - acc: 0.8337 - kappa: 0.9614\n",
      "Iteration 000124: OneCycleScheduler setting learning rate to 6.890723652258378e-05.\n",
      "125/343 [=========>....................] - ETA: 3:18 - loss: 0.4839 - acc: 0.8330 - kappa: 0.9614\n",
      "Iteration 000125: OneCycleScheduler setting learning rate to 6.914035939776591e-05.\n",
      "126/343 [==========>...................] - ETA: 3:17 - loss: 0.4854 - acc: 0.8313 - kappa: 0.9612\n",
      "Iteration 000126: OneCycleScheduler setting learning rate to 6.937348227294805e-05.\n",
      "127/343 [==========>...................] - ETA: 3:17 - loss: 0.4904 - acc: 0.8317 - kappa: 0.9609\n",
      "Iteration 000127: OneCycleScheduler setting learning rate to 6.960660514813017e-05.\n",
      "128/343 [==========>...................] - ETA: 3:16 - loss: 0.4901 - acc: 0.8320 - kappa: 0.9610\n",
      "Iteration 000128: OneCycleScheduler setting learning rate to 6.98397280233123e-05.\n",
      "129/343 [==========>...................] - ETA: 3:16 - loss: 0.4915 - acc: 0.8314 - kappa: 0.9608\n",
      "Iteration 000129: OneCycleScheduler setting learning rate to 7.007285089849442e-05.\n",
      "130/343 [==========>...................] - ETA: 3:15 - loss: 0.4913 - acc: 0.8317 - kappa: 0.9608\n",
      "Iteration 000130: OneCycleScheduler setting learning rate to 7.030597377367655e-05.\n",
      "131/343 [==========>...................] - ETA: 3:14 - loss: 0.4894 - acc: 0.8321 - kappa: 0.9611\n",
      "Iteration 000131: OneCycleScheduler setting learning rate to 7.053909664885867e-05.\n",
      "132/343 [==========>...................] - ETA: 3:13 - loss: 0.4926 - acc: 0.8305 - kappa: 0.9599\n",
      "Iteration 000132: OneCycleScheduler setting learning rate to 7.07722195240408e-05.\n",
      "133/343 [==========>...................] - ETA: 3:13 - loss: 0.4963 - acc: 0.8299 - kappa: 0.9592\n",
      "Iteration 000133: OneCycleScheduler setting learning rate to 7.100534239922292e-05.\n",
      "134/343 [==========>...................] - ETA: 3:12 - loss: 0.4987 - acc: 0.8284 - kappa: 0.9581\n",
      "Iteration 000134: OneCycleScheduler setting learning rate to 7.123846527440505e-05.\n",
      "135/343 [==========>...................] - ETA: 3:12 - loss: 0.4979 - acc: 0.8287 - kappa: 0.9583\n",
      "Iteration 000135: OneCycleScheduler setting learning rate to 7.147158814958719e-05.\n",
      "136/343 [==========>...................] - ETA: 3:11 - loss: 0.4982 - acc: 0.8281 - kappa: 0.9581\n",
      "Iteration 000136: OneCycleScheduler setting learning rate to 7.170471102476931e-05.\n",
      "137/343 [==========>...................] - ETA: 3:10 - loss: 0.4967 - acc: 0.8285 - kappa: 0.9584\n",
      "Iteration 000137: OneCycleScheduler setting learning rate to 7.193783389995144e-05.\n",
      "138/343 [===========>..................] - ETA: 3:09 - loss: 0.4969 - acc: 0.8279 - kappa: 0.9584\n",
      "Iteration 000138: OneCycleScheduler setting learning rate to 7.217095677513358e-05.\n",
      "139/343 [===========>..................] - ETA: 3:09 - loss: 0.4972 - acc: 0.8273 - kappa: 0.9585\n",
      "Iteration 000139: OneCycleScheduler setting learning rate to 7.24040796503157e-05.\n",
      "140/343 [===========>..................] - ETA: 3:07 - loss: 0.4955 - acc: 0.8277 - kappa: 0.9586\n",
      "Iteration 000140: OneCycleScheduler setting learning rate to 7.263720252549783e-05.\n",
      "141/343 [===========>..................] - ETA: 3:06 - loss: 0.4952 - acc: 0.8271 - kappa: 0.9587\n",
      "Iteration 000141: OneCycleScheduler setting learning rate to 7.287032540067995e-05.\n",
      "142/343 [===========>..................] - ETA: 3:05 - loss: 0.4928 - acc: 0.8283 - kappa: 0.9590\n",
      "Iteration 000142: OneCycleScheduler setting learning rate to 7.310344827586208e-05.\n",
      "143/343 [===========>..................] - ETA: 3:04 - loss: 0.4913 - acc: 0.8278 - kappa: 0.9590\n",
      "Iteration 000143: OneCycleScheduler setting learning rate to 7.33365711510442e-05.\n",
      "144/343 [===========>..................] - ETA: 3:04 - loss: 0.4901 - acc: 0.8281 - kappa: 0.9593\n",
      "Iteration 000144: OneCycleScheduler setting learning rate to 7.356969402622633e-05.\n",
      "145/343 [===========>..................] - ETA: 3:03 - loss: 0.4893 - acc: 0.8284 - kappa: 0.9595\n",
      "Iteration 000145: OneCycleScheduler setting learning rate to 7.380281690140845e-05.\n",
      "146/343 [===========>..................] - ETA: 3:02 - loss: 0.4906 - acc: 0.8271 - kappa: 0.9589\n",
      "Iteration 000146: OneCycleScheduler setting learning rate to 7.403593977659058e-05.\n",
      "147/343 [===========>..................] - ETA: 3:02 - loss: 0.4889 - acc: 0.8282 - kappa: 0.9592\n",
      "Iteration 000147: OneCycleScheduler setting learning rate to 7.42690626517727e-05.\n",
      "148/343 [===========>..................] - ETA: 3:01 - loss: 0.4873 - acc: 0.8285 - kappa: 0.9594\n",
      "Iteration 000148: OneCycleScheduler setting learning rate to 7.450218552695484e-05.\n",
      "149/343 [============>.................] - ETA: 2:59 - loss: 0.4870 - acc: 0.8289 - kappa: 0.9595\n",
      "Iteration 000149: OneCycleScheduler setting learning rate to 7.473530840213697e-05.\n",
      "150/343 [============>.................] - ETA: 2:58 - loss: 0.4859 - acc: 0.8292 - kappa: 0.9597\n",
      "Iteration 000150: OneCycleScheduler setting learning rate to 7.496843127731909e-05.\n",
      "151/343 [============>.................] - ETA: 2:57 - loss: 0.4856 - acc: 0.8286 - kappa: 0.9597\n",
      "Iteration 000151: OneCycleScheduler setting learning rate to 7.520155415250122e-05.\n",
      "152/343 [============>.................] - ETA: 2:56 - loss: 0.4836 - acc: 0.8298 - kappa: 0.9600\n",
      "Iteration 000152: OneCycleScheduler setting learning rate to 7.543467702768336e-05.\n",
      "153/343 [============>.................] - ETA: 2:55 - loss: 0.4842 - acc: 0.8292 - kappa: 0.9598\n",
      "Iteration 000153: OneCycleScheduler setting learning rate to 7.566779990286548e-05.\n",
      "154/343 [============>.................] - ETA: 2:54 - loss: 0.4860 - acc: 0.8287 - kappa: 0.9593\n",
      "Iteration 000154: OneCycleScheduler setting learning rate to 7.59009227780476e-05.\n",
      "155/343 [============>.................] - ETA: 2:53 - loss: 0.4853 - acc: 0.8290 - kappa: 0.9595\n",
      "Iteration 000155: OneCycleScheduler setting learning rate to 7.613404565322973e-05.\n",
      "156/343 [============>.................] - ETA: 2:52 - loss: 0.4912 - acc: 0.8277 - kappa: 0.9585\n",
      "Iteration 000156: OneCycleScheduler setting learning rate to 7.636716852841186e-05.\n",
      "157/343 [============>.................] - ETA: 2:51 - loss: 0.4890 - acc: 0.8288 - kappa: 0.9587\n",
      "Iteration 000157: OneCycleScheduler setting learning rate to 7.660029140359398e-05.\n",
      "158/343 [============>.................] - ETA: 2:50 - loss: 0.4901 - acc: 0.8275 - kappa: 0.9578\n",
      "Iteration 000158: OneCycleScheduler setting learning rate to 7.683341427877611e-05.\n",
      "159/343 [============>.................] - ETA: 2:49 - loss: 0.4897 - acc: 0.8270 - kappa: 0.9578\n",
      "Iteration 000159: OneCycleScheduler setting learning rate to 7.706653715395823e-05.\n",
      "160/343 [============>.................] - ETA: 2:48 - loss: 0.4898 - acc: 0.8266 - kappa: 0.9577\n",
      "Iteration 000160: OneCycleScheduler setting learning rate to 7.729966002914036e-05.\n",
      "161/343 [=============>................] - ETA: 2:47 - loss: 0.4920 - acc: 0.8269 - kappa: 0.9579\n",
      "Iteration 000161: OneCycleScheduler setting learning rate to 7.753278290432248e-05.\n",
      "162/343 [=============>................] - ETA: 2:46 - loss: 0.4938 - acc: 0.8256 - kappa: 0.9569\n",
      "Iteration 000162: OneCycleScheduler setting learning rate to 7.776590577950462e-05.\n",
      "163/343 [=============>................] - ETA: 2:45 - loss: 0.4949 - acc: 0.8252 - kappa: 0.9568\n",
      "Iteration 000163: OneCycleScheduler setting learning rate to 7.799902865468675e-05.\n",
      "164/343 [=============>................] - ETA: 2:45 - loss: 0.4956 - acc: 0.8239 - kappa: 0.9563\n",
      "Iteration 000164: OneCycleScheduler setting learning rate to 7.823215152986887e-05.\n",
      "165/343 [=============>................] - ETA: 2:44 - loss: 0.4969 - acc: 0.8235 - kappa: 0.9558\n",
      "Iteration 000165: OneCycleScheduler setting learning rate to 7.846527440505101e-05.\n",
      "166/343 [=============>................] - ETA: 2:43 - loss: 0.4963 - acc: 0.8238 - kappa: 0.9560\n",
      "Iteration 000166: OneCycleScheduler setting learning rate to 7.869839728023314e-05.\n",
      "167/343 [=============>................] - ETA: 2:42 - loss: 0.4998 - acc: 0.8219 - kappa: 0.9546\n",
      "Iteration 000167: OneCycleScheduler setting learning rate to 7.893152015541526e-05.\n",
      "168/343 [=============>................] - ETA: 2:42 - loss: 0.4994 - acc: 0.8214 - kappa: 0.9547\n",
      "Iteration 000168: OneCycleScheduler setting learning rate to 7.916464303059739e-05.\n",
      "169/343 [=============>................] - ETA: 2:41 - loss: 0.4995 - acc: 0.8203 - kappa: 0.9542\n",
      "Iteration 000169: OneCycleScheduler setting learning rate to 7.939776590577951e-05.\n",
      "170/343 [=============>................] - ETA: 2:40 - loss: 0.5018 - acc: 0.8199 - kappa: 0.9537\n",
      "Iteration 000170: OneCycleScheduler setting learning rate to 7.963088878096164e-05.\n",
      "171/343 [=============>................] - ETA: 2:39 - loss: 0.4999 - acc: 0.8209 - kappa: 0.9540\n",
      "Iteration 000171: OneCycleScheduler setting learning rate to 7.986401165614376e-05.\n",
      "172/343 [==============>...............] - ETA: 2:39 - loss: 0.5015 - acc: 0.8212 - kappa: 0.9542\n",
      "Iteration 000172: OneCycleScheduler setting learning rate to 8.009713453132589e-05.\n",
      "173/343 [==============>...............] - ETA: 2:38 - loss: 0.5029 - acc: 0.8215 - kappa: 0.9543\n",
      "Iteration 000173: OneCycleScheduler setting learning rate to 8.033025740650801e-05.\n",
      "174/343 [==============>...............] - ETA: 2:37 - loss: 0.5032 - acc: 0.8204 - kappa: 0.9542\n",
      "Iteration 000174: OneCycleScheduler setting learning rate to 8.056338028169014e-05.\n",
      "175/343 [==============>...............] - ETA: 2:37 - loss: 0.5028 - acc: 0.8207 - kappa: 0.9544\n",
      "Iteration 000175: OneCycleScheduler setting learning rate to 8.079650315687228e-05.\n",
      "176/343 [==============>...............] - ETA: 2:36 - loss: 0.5014 - acc: 0.8210 - kappa: 0.9545\n",
      "Iteration 000176: OneCycleScheduler setting learning rate to 8.10296260320544e-05.\n",
      "177/343 [==============>...............] - ETA: 2:35 - loss: 0.5011 - acc: 0.8199 - kappa: 0.9540\n",
      "Iteration 000177: OneCycleScheduler setting learning rate to 8.126274890723653e-05.\n",
      "178/343 [==============>...............] - ETA: 2:34 - loss: 0.4995 - acc: 0.8209 - kappa: 0.9543\n",
      "Iteration 000178: OneCycleScheduler setting learning rate to 8.149587178241867e-05.\n",
      "179/343 [==============>...............] - ETA: 2:34 - loss: 0.4984 - acc: 0.8219 - kappa: 0.9545\n",
      "Iteration 000179: OneCycleScheduler setting learning rate to 8.172899465760079e-05.\n",
      "180/343 [==============>...............] - ETA: 2:33 - loss: 0.5009 - acc: 0.8208 - kappa: 0.9544\n",
      "Iteration 000180: OneCycleScheduler setting learning rate to 8.196211753278292e-05.\n",
      "181/343 [==============>...............] - ETA: 2:32 - loss: 0.5027 - acc: 0.8204 - kappa: 0.9545\n",
      "Iteration 000181: OneCycleScheduler setting learning rate to 8.219524040796504e-05.\n",
      "182/343 [==============>...............] - ETA: 2:31 - loss: 0.5018 - acc: 0.8201 - kappa: 0.9545\n",
      "Iteration 000182: OneCycleScheduler setting learning rate to 8.242836328314717e-05.\n",
      "183/343 [===============>..............] - ETA: 2:30 - loss: 0.5036 - acc: 0.8183 - kappa: 0.9541\n",
      "Iteration 000183: OneCycleScheduler setting learning rate to 8.266148615832929e-05.\n",
      "184/343 [===============>..............] - ETA: 2:29 - loss: 0.5054 - acc: 0.8173 - kappa: 0.9533\n",
      "Iteration 000184: OneCycleScheduler setting learning rate to 8.289460903351142e-05.\n",
      "185/343 [===============>..............] - ETA: 2:28 - loss: 0.5042 - acc: 0.8176 - kappa: 0.9535\n",
      "Iteration 000185: OneCycleScheduler setting learning rate to 8.312773190869354e-05.\n",
      "186/343 [===============>..............] - ETA: 2:27 - loss: 0.5055 - acc: 0.8165 - kappa: 0.9531\n",
      "Iteration 000186: OneCycleScheduler setting learning rate to 8.336085478387567e-05.\n",
      "187/343 [===============>..............] - ETA: 2:26 - loss: 0.5072 - acc: 0.8162 - kappa: 0.9532\n",
      "Iteration 000187: OneCycleScheduler setting learning rate to 8.359397765905779e-05.\n",
      "188/343 [===============>..............] - ETA: 2:26 - loss: 0.5056 - acc: 0.8172 - kappa: 0.9534\n",
      "Iteration 000188: OneCycleScheduler setting learning rate to 8.382710053423993e-05.\n",
      "189/343 [===============>..............] - ETA: 2:25 - loss: 0.5069 - acc: 0.8161 - kappa: 0.9526\n",
      "Iteration 000189: OneCycleScheduler setting learning rate to 8.406022340942206e-05.\n",
      "190/343 [===============>..............] - ETA: 2:24 - loss: 0.5054 - acc: 0.8171 - kappa: 0.9529\n",
      "Iteration 000190: OneCycleScheduler setting learning rate to 8.429334628460418e-05.\n",
      "191/343 [===============>..............] - ETA: 2:23 - loss: 0.5045 - acc: 0.8174 - kappa: 0.9531\n",
      "Iteration 000191: OneCycleScheduler setting learning rate to 8.452646915978631e-05.\n",
      "192/343 [===============>..............] - ETA: 2:22 - loss: 0.5051 - acc: 0.8171 - kappa: 0.9532\n",
      "Iteration 000192: OneCycleScheduler setting learning rate to 8.475959203496845e-05.\n",
      "193/343 [===============>..............] - ETA: 2:21 - loss: 0.5045 - acc: 0.8174 - kappa: 0.9532\n",
      "Iteration 000193: OneCycleScheduler setting learning rate to 8.499271491015057e-05.\n",
      "194/343 [===============>..............] - ETA: 2:20 - loss: 0.5034 - acc: 0.8177 - kappa: 0.9534\n",
      "Iteration 000194: OneCycleScheduler setting learning rate to 8.52258377853327e-05.\n",
      "195/343 [================>.............] - ETA: 2:19 - loss: 0.5022 - acc: 0.8179 - kappa: 0.9535\n",
      "Iteration 000195: OneCycleScheduler setting learning rate to 8.545896066051482e-05.\n",
      "196/343 [================>.............] - ETA: 2:18 - loss: 0.5009 - acc: 0.8182 - kappa: 0.9537\n",
      "Iteration 000196: OneCycleScheduler setting learning rate to 8.569208353569695e-05.\n",
      "197/343 [================>.............] - ETA: 2:17 - loss: 0.4998 - acc: 0.8185 - kappa: 0.9538\n",
      "Iteration 000197: OneCycleScheduler setting learning rate to 8.592520641087907e-05.\n",
      "198/343 [================>.............] - ETA: 2:16 - loss: 0.4982 - acc: 0.8188 - kappa: 0.9540\n",
      "Iteration 000198: OneCycleScheduler setting learning rate to 8.61583292860612e-05.\n",
      "199/343 [================>.............] - ETA: 2:15 - loss: 0.4985 - acc: 0.8185 - kappa: 0.9541\n",
      "Iteration 000199: OneCycleScheduler setting learning rate to 8.639145216124332e-05.\n",
      "200/343 [================>.............] - ETA: 2:14 - loss: 0.5001 - acc: 0.8175 - kappa: 0.9539\n",
      "Iteration 000200: OneCycleScheduler setting learning rate to 8.662457503642545e-05.\n",
      "201/343 [================>.............] - ETA: 2:13 - loss: 0.4988 - acc: 0.8184 - kappa: 0.9542\n",
      "Iteration 000201: OneCycleScheduler setting learning rate to 8.685769791160757e-05.\n",
      "202/343 [================>.............] - ETA: 2:13 - loss: 0.4981 - acc: 0.8181 - kappa: 0.9541\n",
      "Iteration 000202: OneCycleScheduler setting learning rate to 8.709082078678971e-05.\n",
      "203/343 [================>.............] - ETA: 2:12 - loss: 0.4970 - acc: 0.8183 - kappa: 0.9542\n",
      "Iteration 000203: OneCycleScheduler setting learning rate to 8.732394366197184e-05.\n",
      "204/343 [================>.............] - ETA: 2:11 - loss: 0.4956 - acc: 0.8192 - kappa: 0.9545\n",
      "Iteration 000204: OneCycleScheduler setting learning rate to 8.755706653715396e-05.\n",
      "205/343 [================>.............] - ETA: 2:10 - loss: 0.4989 - acc: 0.8177 - kappa: 0.9533\n",
      "Iteration 000205: OneCycleScheduler setting learning rate to 8.77901894123361e-05.\n",
      "206/343 [=================>............] - ETA: 2:09 - loss: 0.4973 - acc: 0.8186 - kappa: 0.9535\n",
      "Iteration 000206: OneCycleScheduler setting learning rate to 8.802331228751823e-05.\n",
      "207/343 [=================>............] - ETA: 2:08 - loss: 0.4978 - acc: 0.8188 - kappa: 0.9534\n",
      "Iteration 000207: OneCycleScheduler setting learning rate to 8.825643516270035e-05.\n",
      "208/343 [=================>............] - ETA: 2:07 - loss: 0.4973 - acc: 0.8191 - kappa: 0.9535\n",
      "Iteration 000208: OneCycleScheduler setting learning rate to 8.848955803788248e-05.\n",
      "209/343 [=================>............] - ETA: 2:07 - loss: 0.4977 - acc: 0.8188 - kappa: 0.9536\n",
      "Iteration 000209: OneCycleScheduler setting learning rate to 8.87226809130646e-05.\n",
      "210/343 [=================>............] - ETA: 2:06 - loss: 0.4970 - acc: 0.8190 - kappa: 0.9536\n",
      "Iteration 000210: OneCycleScheduler setting learning rate to 8.895580378824673e-05.\n",
      "211/343 [=================>............] - ETA: 2:05 - loss: 0.4974 - acc: 0.8181 - kappa: 0.9525\n",
      "Iteration 000211: OneCycleScheduler setting learning rate to 8.918892666342885e-05.\n",
      "212/343 [=================>............] - ETA: 2:04 - loss: 0.4958 - acc: 0.8190 - kappa: 0.9528\n",
      "Iteration 000212: OneCycleScheduler setting learning rate to 8.942204953861098e-05.\n",
      "213/343 [=================>............] - ETA: 2:03 - loss: 0.4939 - acc: 0.8198 - kappa: 0.9530\n",
      "Iteration 000213: OneCycleScheduler setting learning rate to 8.96551724137931e-05.\n",
      "214/343 [=================>............] - ETA: 2:02 - loss: 0.4927 - acc: 0.8207 - kappa: 0.9532\n",
      "Iteration 000214: OneCycleScheduler setting learning rate to 8.988829528897523e-05.\n",
      "215/343 [=================>............] - ETA: 2:01 - loss: 0.4914 - acc: 0.8215 - kappa: 0.9534\n",
      "Iteration 000215: OneCycleScheduler setting learning rate to 9.012141816415737e-05.\n",
      "216/343 [=================>............] - ETA: 2:00 - loss: 0.4928 - acc: 0.8212 - kappa: 0.9527\n",
      "Iteration 000216: OneCycleScheduler setting learning rate to 9.035454103933949e-05.\n",
      "217/343 [=================>............] - ETA: 1:58 - loss: 0.4915 - acc: 0.8214 - kappa: 0.9528\n",
      "Iteration 000217: OneCycleScheduler setting learning rate to 9.058766391452162e-05.\n",
      "218/343 [==================>...........] - ETA: 1:57 - loss: 0.4904 - acc: 0.8217 - kappa: 0.9529\n",
      "Iteration 000218: OneCycleScheduler setting learning rate to 9.082078678970376e-05.\n",
      "219/343 [==================>...........] - ETA: 1:57 - loss: 0.4917 - acc: 0.8219 - kappa: 0.9531\n",
      "Iteration 000219: OneCycleScheduler setting learning rate to 9.105390966488588e-05.\n",
      "220/343 [==================>...........] - ETA: 1:56 - loss: 0.4937 - acc: 0.8216 - kappa: 0.9531\n",
      "Iteration 000220: OneCycleScheduler setting learning rate to 9.1287032540068e-05.\n",
      "221/343 [==================>...........] - ETA: 1:55 - loss: 0.4950 - acc: 0.8213 - kappa: 0.9532\n",
      "Iteration 000221: OneCycleScheduler setting learning rate to 9.152015541525013e-05.\n",
      "222/343 [==================>...........] - ETA: 1:54 - loss: 0.4948 - acc: 0.8209 - kappa: 0.9531\n",
      "Iteration 000222: OneCycleScheduler setting learning rate to 9.175327829043226e-05.\n",
      "223/343 [==================>...........] - ETA: 1:53 - loss: 0.4936 - acc: 0.8212 - kappa: 0.9533\n",
      "Iteration 000223: OneCycleScheduler setting learning rate to 9.198640116561438e-05.\n",
      "224/343 [==================>...........] - ETA: 1:52 - loss: 0.4936 - acc: 0.8214 - kappa: 0.9533\n",
      "Iteration 000224: OneCycleScheduler setting learning rate to 9.221952404079651e-05.\n",
      "225/343 [==================>...........] - ETA: 1:51 - loss: 0.4934 - acc: 0.8217 - kappa: 0.9535\n",
      "Iteration 000225: OneCycleScheduler setting learning rate to 9.245264691597863e-05.\n",
      "226/343 [==================>...........] - ETA: 1:50 - loss: 0.4959 - acc: 0.8208 - kappa: 0.9534\n",
      "Iteration 000226: OneCycleScheduler setting learning rate to 9.268576979116076e-05.\n",
      "227/343 [==================>...........] - ETA: 1:49 - loss: 0.4954 - acc: 0.8210 - kappa: 0.9536\n",
      "Iteration 000227: OneCycleScheduler setting learning rate to 9.291889266634288e-05.\n",
      "228/343 [==================>...........] - ETA: 1:48 - loss: 0.4946 - acc: 0.8207 - kappa: 0.9536\n",
      "Iteration 000228: OneCycleScheduler setting learning rate to 9.315201554152502e-05.\n",
      "229/343 [===================>..........] - ETA: 1:47 - loss: 0.4949 - acc: 0.8199 - kappa: 0.9535\n",
      "Iteration 000229: OneCycleScheduler setting learning rate to 9.338513841670715e-05.\n",
      "230/343 [===================>..........] - ETA: 1:46 - loss: 0.4971 - acc: 0.8190 - kappa: 0.9534\n",
      "Iteration 000230: OneCycleScheduler setting learning rate to 9.361826129188927e-05.\n",
      "231/343 [===================>..........] - ETA: 1:46 - loss: 0.4969 - acc: 0.8193 - kappa: 0.9535\n",
      "Iteration 000231: OneCycleScheduler setting learning rate to 9.38513841670714e-05.\n",
      "232/343 [===================>..........] - ETA: 1:45 - loss: 0.4957 - acc: 0.8195 - kappa: 0.9536\n",
      "Iteration 000232: OneCycleScheduler setting learning rate to 9.408450704225354e-05.\n",
      "233/343 [===================>..........] - ETA: 1:44 - loss: 0.4977 - acc: 0.8181 - kappa: 0.9526\n",
      "Iteration 000233: OneCycleScheduler setting learning rate to 9.431762991743566e-05.\n",
      "234/343 [===================>..........] - ETA: 1:43 - loss: 0.4969 - acc: 0.8178 - kappa: 0.9526\n",
      "Iteration 000234: OneCycleScheduler setting learning rate to 9.455075279261779e-05.\n",
      "235/343 [===================>..........] - ETA: 1:42 - loss: 0.4972 - acc: 0.8176 - kappa: 0.9525\n",
      "Iteration 000235: OneCycleScheduler setting learning rate to 9.478387566779991e-05.\n",
      "236/343 [===================>..........] - ETA: 1:41 - loss: 0.4994 - acc: 0.8173 - kappa: 0.9522\n",
      "Iteration 000236: OneCycleScheduler setting learning rate to 9.501699854298204e-05.\n",
      "237/343 [===================>..........] - ETA: 1:40 - loss: 0.5012 - acc: 0.8165 - kappa: 0.9519\n",
      "Iteration 000237: OneCycleScheduler setting learning rate to 9.525012141816416e-05.\n",
      "238/343 [===================>..........] - ETA: 1:39 - loss: 0.5000 - acc: 0.8172 - kappa: 0.9521\n",
      "Iteration 000238: OneCycleScheduler setting learning rate to 9.548324429334629e-05.\n",
      "239/343 [===================>..........] - ETA: 1:38 - loss: 0.5027 - acc: 0.8169 - kappa: 0.9521\n",
      "Iteration 000239: OneCycleScheduler setting learning rate to 9.571636716852841e-05.\n",
      "240/343 [===================>..........] - ETA: 1:37 - loss: 0.5051 - acc: 0.8161 - kappa: 0.9515\n",
      "Iteration 000240: OneCycleScheduler setting learning rate to 9.594949004371054e-05.\n",
      "241/343 [====================>.........] - ETA: 1:36 - loss: 0.5058 - acc: 0.8164 - kappa: 0.9516\n",
      "Iteration 000241: OneCycleScheduler setting learning rate to 9.618261291889266e-05.\n",
      "242/343 [====================>.........] - ETA: 1:35 - loss: 0.5057 - acc: 0.8166 - kappa: 0.9515\n",
      "Iteration 000242: OneCycleScheduler setting learning rate to 9.64157357940748e-05.\n",
      "243/343 [====================>.........] - ETA: 1:34 - loss: 0.5046 - acc: 0.8174 - kappa: 0.9517\n",
      "Iteration 000243: OneCycleScheduler setting learning rate to 9.664885866925693e-05.\n",
      "244/343 [====================>.........] - ETA: 1:33 - loss: 0.5033 - acc: 0.8181 - kappa: 0.9519\n",
      "Iteration 000244: OneCycleScheduler setting learning rate to 9.688198154443905e-05.\n",
      "245/343 [====================>.........] - ETA: 1:33 - loss: 0.5027 - acc: 0.8184 - kappa: 0.9521\n",
      "Iteration 000245: OneCycleScheduler setting learning rate to 9.711510441962119e-05.\n",
      "246/343 [====================>.........] - ETA: 1:32 - loss: 0.5016 - acc: 0.8186 - kappa: 0.9521\n",
      "Iteration 000246: OneCycleScheduler setting learning rate to 9.734822729480332e-05.\n",
      "247/343 [====================>.........] - ETA: 1:31 - loss: 0.5019 - acc: 0.8183 - kappa: 0.9520\n",
      "Iteration 000247: OneCycleScheduler setting learning rate to 9.758135016998544e-05.\n",
      "248/343 [====================>.........] - ETA: 1:30 - loss: 0.5016 - acc: 0.8185 - kappa: 0.9521\n",
      "Iteration 000248: OneCycleScheduler setting learning rate to 9.781447304516757e-05.\n",
      "249/343 [====================>.........] - ETA: 1:29 - loss: 0.5012 - acc: 0.8188 - kappa: 0.9523\n",
      "Iteration 000249: OneCycleScheduler setting learning rate to 9.804759592034969e-05.\n",
      "250/343 [====================>.........] - ETA: 1:28 - loss: 0.5011 - acc: 0.8185 - kappa: 0.9522\n",
      "Iteration 000250: OneCycleScheduler setting learning rate to 9.828071879553182e-05.\n",
      "251/343 [====================>.........] - ETA: 1:27 - loss: 0.5002 - acc: 0.8187 - kappa: 0.9523\n",
      "Iteration 000251: OneCycleScheduler setting learning rate to 9.851384167071394e-05.\n",
      "252/343 [=====================>........] - ETA: 1:26 - loss: 0.4995 - acc: 0.8189 - kappa: 0.9525\n",
      "Iteration 000252: OneCycleScheduler setting learning rate to 9.874696454589607e-05.\n",
      "253/343 [=====================>........] - ETA: 1:25 - loss: 0.5006 - acc: 0.8187 - kappa: 0.9524\n",
      "Iteration 000253: OneCycleScheduler setting learning rate to 9.89800874210782e-05.\n",
      "254/343 [=====================>........] - ETA: 1:24 - loss: 0.5007 - acc: 0.8189 - kappa: 0.9523\n",
      "Iteration 000254: OneCycleScheduler setting learning rate to 9.921321029626032e-05.\n",
      "255/343 [=====================>........] - ETA: 1:23 - loss: 0.5004 - acc: 0.8191 - kappa: 0.9524\n",
      "Iteration 000255: OneCycleScheduler setting learning rate to 9.944633317144246e-05.\n",
      "256/343 [=====================>........] - ETA: 1:22 - loss: 0.5015 - acc: 0.8179 - kappa: 0.9518\n",
      "Iteration 000256: OneCycleScheduler setting learning rate to 9.967945604662458e-05.\n",
      "257/343 [=====================>........] - ETA: 1:21 - loss: 0.5020 - acc: 0.8176 - kappa: 0.9519\n",
      "Iteration 000257: OneCycleScheduler setting learning rate to 9.991257892180671e-05.\n",
      "258/343 [=====================>........] - ETA: 1:20 - loss: 0.5017 - acc: 0.8178 - kappa: 0.9520\n",
      "Iteration 000258: OneCycleScheduler setting learning rate to 0.00010014570179698885.\n",
      "259/343 [=====================>........] - ETA: 1:20 - loss: 0.5046 - acc: 0.8171 - kappa: 0.9519\n",
      "Iteration 000259: OneCycleScheduler setting learning rate to 0.00010037882467217097.\n",
      "260/343 [=====================>........] - ETA: 1:19 - loss: 0.5047 - acc: 0.8173 - kappa: 0.9520\n",
      "Iteration 000260: OneCycleScheduler setting learning rate to 0.0001006119475473531.\n",
      "261/343 [=====================>........] - ETA: 1:18 - loss: 0.5050 - acc: 0.8170 - kappa: 0.9521\n",
      "Iteration 000261: OneCycleScheduler setting learning rate to 0.00010084507042253522.\n",
      "262/343 [=====================>........] - ETA: 1:17 - loss: 0.5038 - acc: 0.8177 - kappa: 0.9523\n",
      "Iteration 000262: OneCycleScheduler setting learning rate to 0.00010107819329771735.\n",
      "263/343 [======================>.......] - ETA: 1:16 - loss: 0.5035 - acc: 0.8180 - kappa: 0.9523\n",
      "Iteration 000263: OneCycleScheduler setting learning rate to 0.00010131131617289947.\n",
      "264/343 [======================>.......] - ETA: 1:15 - loss: 0.5043 - acc: 0.8177 - kappa: 0.9520\n",
      "Iteration 000264: OneCycleScheduler setting learning rate to 0.0001015444390480816.\n",
      "265/343 [======================>.......] - ETA: 1:14 - loss: 0.5033 - acc: 0.8179 - kappa: 0.9522\n",
      "Iteration 000265: OneCycleScheduler setting learning rate to 0.00010177756192326372.\n",
      "266/343 [======================>.......] - ETA: 1:13 - loss: 0.5022 - acc: 0.8181 - kappa: 0.9523\n",
      "Iteration 000266: OneCycleScheduler setting learning rate to 0.00010201068479844585.\n",
      "267/343 [======================>.......] - ETA: 1:12 - loss: 0.5016 - acc: 0.8184 - kappa: 0.9525\n",
      "Iteration 000267: OneCycleScheduler setting learning rate to 0.00010224380767362797.\n",
      "268/343 [======================>.......] - ETA: 1:11 - loss: 0.5015 - acc: 0.8181 - kappa: 0.9525\n",
      "Iteration 000268: OneCycleScheduler setting learning rate to 0.0001024769305488101.\n",
      "269/343 [======================>.......] - ETA: 1:10 - loss: 0.5004 - acc: 0.8188 - kappa: 0.9527\n",
      "Iteration 000269: OneCycleScheduler setting learning rate to 0.00010271005342399222.\n",
      "270/343 [======================>.......] - ETA: 1:09 - loss: 0.5008 - acc: 0.8185 - kappa: 0.9528\n",
      "Iteration 000270: OneCycleScheduler setting learning rate to 0.00010294317629917438.\n",
      "271/343 [======================>.......] - ETA: 1:08 - loss: 0.5003 - acc: 0.8187 - kappa: 0.9528\n",
      "Iteration 000271: OneCycleScheduler setting learning rate to 0.0001031762991743565.\n",
      "272/343 [======================>.......] - ETA: 1:07 - loss: 0.4993 - acc: 0.8194 - kappa: 0.9530\n",
      "Iteration 000272: OneCycleScheduler setting learning rate to 0.00010340942204953863.\n",
      "273/343 [======================>.......] - ETA: 1:06 - loss: 0.5001 - acc: 0.8187 - kappa: 0.9525\n",
      "Iteration 000273: OneCycleScheduler setting learning rate to 0.00010364254492472075.\n",
      "274/343 [======================>.......] - ETA: 1:05 - loss: 0.4990 - acc: 0.8189 - kappa: 0.9525\n",
      "Iteration 000274: OneCycleScheduler setting learning rate to 0.00010387566779990288.\n",
      "275/343 [=======================>......] - ETA: 1:04 - loss: 0.4982 - acc: 0.8195 - kappa: 0.9527\n",
      "Iteration 000275: OneCycleScheduler setting learning rate to 0.000104108790675085.\n",
      "276/343 [=======================>......] - ETA: 1:03 - loss: 0.4976 - acc: 0.8197 - kappa: 0.9528\n",
      "Iteration 000276: OneCycleScheduler setting learning rate to 0.00010434191355026713.\n",
      "277/343 [=======================>......] - ETA: 1:03 - loss: 0.4976 - acc: 0.8195 - kappa: 0.9528\n",
      "Iteration 000277: OneCycleScheduler setting learning rate to 0.00010457503642544925.\n",
      "278/343 [=======================>......] - ETA: 1:02 - loss: 0.4985 - acc: 0.8197 - kappa: 0.9529\n",
      "Iteration 000278: OneCycleScheduler setting learning rate to 0.00010480815930063138.\n",
      "279/343 [=======================>......] - ETA: 1:01 - loss: 0.4973 - acc: 0.8203 - kappa: 0.9530\n",
      "Iteration 000279: OneCycleScheduler setting learning rate to 0.0001050412821758135.\n",
      "280/343 [=======================>......] - ETA: 1:00 - loss: 0.4973 - acc: 0.8205 - kappa: 0.9532\n",
      "Iteration 000280: OneCycleScheduler setting learning rate to 0.00010527440505099563.\n",
      "281/343 [=======================>......] - ETA: 59s - loss: 0.4972 - acc: 0.8203 - kappa: 0.9532 \n",
      "Iteration 000281: OneCycleScheduler setting learning rate to 0.00010550752792617775.\n",
      "282/343 [=======================>......] - ETA: 58s - loss: 0.4978 - acc: 0.8196 - kappa: 0.9530\n",
      "Iteration 000282: OneCycleScheduler setting learning rate to 0.00010574065080135988.\n",
      "283/343 [=======================>......] - ETA: 57s - loss: 0.5017 - acc: 0.8185 - kappa: 0.9524\n",
      "Iteration 000283: OneCycleScheduler setting learning rate to 0.00010597377367654203.\n",
      "284/343 [=======================>......] - ETA: 56s - loss: 0.5029 - acc: 0.8178 - kappa: 0.9524\n",
      "Iteration 000284: OneCycleScheduler setting learning rate to 0.00010620689655172416.\n",
      "285/343 [=======================>......] - ETA: 55s - loss: 0.5021 - acc: 0.8180 - kappa: 0.9524\n",
      "Iteration 000285: OneCycleScheduler setting learning rate to 0.00010644001942690628.\n",
      "286/343 [========================>.....] - ETA: 54s - loss: 0.5029 - acc: 0.8182 - kappa: 0.9526\n",
      "Iteration 000286: OneCycleScheduler setting learning rate to 0.00010667314230208841.\n",
      "287/343 [========================>.....] - ETA: 53s - loss: 0.5049 - acc: 0.8175 - kappa: 0.9520\n",
      "Iteration 000287: OneCycleScheduler setting learning rate to 0.00010690626517727053.\n",
      "288/343 [========================>.....] - ETA: 52s - loss: 0.5038 - acc: 0.8181 - kappa: 0.9522\n",
      "Iteration 000288: OneCycleScheduler setting learning rate to 0.00010713938805245266.\n",
      "289/343 [========================>.....] - ETA: 51s - loss: 0.5043 - acc: 0.8175 - kappa: 0.9521\n",
      "Iteration 000289: OneCycleScheduler setting learning rate to 0.00010737251092763478.\n",
      "290/343 [========================>.....] - ETA: 50s - loss: 0.5043 - acc: 0.8172 - kappa: 0.9522\n",
      "Iteration 000290: OneCycleScheduler setting learning rate to 0.00010760563380281691.\n",
      "291/343 [========================>.....] - ETA: 49s - loss: 0.5038 - acc: 0.8174 - kappa: 0.9522\n",
      "Iteration 000291: OneCycleScheduler setting learning rate to 0.00010783875667799903.\n",
      "292/343 [========================>.....] - ETA: 48s - loss: 0.5037 - acc: 0.8168 - kappa: 0.9520\n",
      "Iteration 000292: OneCycleScheduler setting learning rate to 0.00010807187955318116.\n",
      "293/343 [========================>.....] - ETA: 47s - loss: 0.5046 - acc: 0.8170 - kappa: 0.9521\n",
      "Iteration 000293: OneCycleScheduler setting learning rate to 0.00010830500242836328.\n",
      "294/343 [========================>.....] - ETA: 46s - loss: 0.5043 - acc: 0.8172 - kappa: 0.9522\n",
      "Iteration 000294: OneCycleScheduler setting learning rate to 0.00010853812530354541.\n",
      "295/343 [========================>.....] - ETA: 45s - loss: 0.5038 - acc: 0.8174 - kappa: 0.9524\n",
      "Iteration 000295: OneCycleScheduler setting learning rate to 0.00010877124817872753.\n",
      "296/343 [========================>.....] - ETA: 44s - loss: 0.5040 - acc: 0.8176 - kappa: 0.9525\n",
      "Iteration 000296: OneCycleScheduler setting learning rate to 0.00010900437105390969.\n",
      "297/343 [========================>.....] - ETA: 44s - loss: 0.5042 - acc: 0.8173 - kappa: 0.9524\n",
      "Iteration 000297: OneCycleScheduler setting learning rate to 0.00010923749392909181.\n",
      "298/343 [=========================>....] - ETA: 43s - loss: 0.5046 - acc: 0.8171 - kappa: 0.9524\n",
      "Iteration 000298: OneCycleScheduler setting learning rate to 0.00010947061680427394.\n",
      "299/343 [=========================>....] - ETA: 42s - loss: 0.5052 - acc: 0.8169 - kappa: 0.9524\n",
      "Iteration 000299: OneCycleScheduler setting learning rate to 0.00010970373967945606.\n",
      "300/343 [=========================>....] - ETA: 41s - loss: 0.5047 - acc: 0.8171 - kappa: 0.9526\n",
      "Iteration 000300: OneCycleScheduler setting learning rate to 0.00010993686255463819.\n",
      "301/343 [=========================>....] - ETA: 40s - loss: 0.5045 - acc: 0.8169 - kappa: 0.9526\n",
      "Iteration 000301: OneCycleScheduler setting learning rate to 0.00011016998542982031.\n",
      "302/343 [=========================>....] - ETA: 39s - loss: 0.5035 - acc: 0.8175 - kappa: 0.9528\n",
      "Iteration 000302: OneCycleScheduler setting learning rate to 0.00011040310830500244.\n",
      "303/343 [=========================>....] - ETA: 38s - loss: 0.5035 - acc: 0.8172 - kappa: 0.9528\n",
      "Iteration 000303: OneCycleScheduler setting learning rate to 0.00011063623118018456.\n",
      "304/343 [=========================>....] - ETA: 37s - loss: 0.5042 - acc: 0.8170 - kappa: 0.9529\n",
      "Iteration 000304: OneCycleScheduler setting learning rate to 0.00011086935405536669.\n",
      "305/343 [=========================>....] - ETA: 36s - loss: 0.5052 - acc: 0.8164 - kappa: 0.9524\n",
      "Iteration 000305: OneCycleScheduler setting learning rate to 0.00011110247693054881.\n",
      "306/343 [=========================>....] - ETA: 35s - loss: 0.5055 - acc: 0.8162 - kappa: 0.9524\n",
      "Iteration 000306: OneCycleScheduler setting learning rate to 0.00011133559980573094.\n",
      "307/343 [=========================>....] - ETA: 34s - loss: 0.5052 - acc: 0.8160 - kappa: 0.9524\n",
      "Iteration 000307: OneCycleScheduler setting learning rate to 0.00011156872268091306.\n",
      "308/343 [=========================>....] - ETA: 33s - loss: 0.5058 - acc: 0.8162 - kappa: 0.9525\n",
      "Iteration 000308: OneCycleScheduler setting learning rate to 0.00011180184555609519.\n",
      "309/343 [==========================>...] - ETA: 32s - loss: 0.5052 - acc: 0.8159 - kappa: 0.9524\n",
      "Iteration 000309: OneCycleScheduler setting learning rate to 0.00011203496843127731.\n",
      "310/343 [==========================>...] - ETA: 31s - loss: 0.5060 - acc: 0.8161 - kappa: 0.9525\n",
      "Iteration 000310: OneCycleScheduler setting learning rate to 0.00011226809130645947.\n",
      "311/343 [==========================>...] - ETA: 30s - loss: 0.5065 - acc: 0.8163 - kappa: 0.9527\n",
      "Iteration 000311: OneCycleScheduler setting learning rate to 0.00011250121418164159.\n",
      "312/343 [==========================>...] - ETA: 29s - loss: 0.5068 - acc: 0.8161 - kappa: 0.9527\n",
      "Iteration 000312: OneCycleScheduler setting learning rate to 0.00011273433705682372.\n",
      "313/343 [==========================>...] - ETA: 28s - loss: 0.5105 - acc: 0.8147 - kappa: 0.9517\n",
      "Iteration 000313: OneCycleScheduler setting learning rate to 0.00011296745993200584.\n",
      "314/343 [==========================>...] - ETA: 27s - loss: 0.5105 - acc: 0.8141 - kappa: 0.9514\n",
      "Iteration 000314: OneCycleScheduler setting learning rate to 0.00011320058280718797.\n",
      "315/343 [==========================>...] - ETA: 26s - loss: 0.5104 - acc: 0.8139 - kappa: 0.9515\n",
      "Iteration 000315: OneCycleScheduler setting learning rate to 0.00011343370568237009.\n",
      "316/343 [==========================>...] - ETA: 25s - loss: 0.5096 - acc: 0.8145 - kappa: 0.9516\n",
      "Iteration 000316: OneCycleScheduler setting learning rate to 0.00011366682855755222.\n",
      "317/343 [==========================>...] - ETA: 24s - loss: 0.5118 - acc: 0.8135 - kappa: 0.9512\n",
      "Iteration 000317: OneCycleScheduler setting learning rate to 0.00011389995143273434.\n",
      "318/343 [==========================>...] - ETA: 23s - loss: 0.5107 - acc: 0.8141 - kappa: 0.9513\n",
      "Iteration 000318: OneCycleScheduler setting learning rate to 0.00011413307430791647.\n",
      "319/343 [==========================>...] - ETA: 22s - loss: 0.5119 - acc: 0.8131 - kappa: 0.9508\n",
      "Iteration 000319: OneCycleScheduler setting learning rate to 0.0001143661971830986.\n",
      "320/343 [==========================>...] - ETA: 21s - loss: 0.5110 - acc: 0.8133 - kappa: 0.9509\n",
      "Iteration 000320: OneCycleScheduler setting learning rate to 0.00011459932005828072.\n",
      "321/343 [===========================>..] - ETA: 21s - loss: 0.5115 - acc: 0.8135 - kappa: 0.9510\n",
      "Iteration 000321: OneCycleScheduler setting learning rate to 0.00011483244293346284.\n",
      "322/343 [===========================>..] - ETA: 20s - loss: 0.5106 - acc: 0.8141 - kappa: 0.9511\n",
      "Iteration 000322: OneCycleScheduler setting learning rate to 0.00011506556580864497.\n",
      "323/343 [===========================>..] - ETA: 19s - loss: 0.5119 - acc: 0.8139 - kappa: 0.9510\n",
      "Iteration 000323: OneCycleScheduler setting learning rate to 0.00011529868868382712.\n",
      "324/343 [===========================>..] - ETA: 18s - loss: 0.5108 - acc: 0.8144 - kappa: 0.9512\n",
      "Iteration 000324: OneCycleScheduler setting learning rate to 0.00011553181155900925.\n",
      "325/343 [===========================>..] - ETA: 17s - loss: 0.5109 - acc: 0.8146 - kappa: 0.9513\n",
      "Iteration 000325: OneCycleScheduler setting learning rate to 0.00011576493443419137.\n",
      "326/343 [===========================>..] - ETA: 16s - loss: 0.5102 - acc: 0.8148 - kappa: 0.9514\n",
      "Iteration 000326: OneCycleScheduler setting learning rate to 0.0001159980573093735.\n",
      "327/343 [===========================>..] - ETA: 15s - loss: 0.5096 - acc: 0.8150 - kappa: 0.9514\n",
      "Iteration 000327: OneCycleScheduler setting learning rate to 0.00011623118018455562.\n",
      "328/343 [===========================>..] - ETA: 14s - loss: 0.5095 - acc: 0.8148 - kappa: 0.9515\n",
      "Iteration 000328: OneCycleScheduler setting learning rate to 0.00011646430305973775.\n",
      "329/343 [===========================>..] - ETA: 13s - loss: 0.5088 - acc: 0.8153 - kappa: 0.9516\n",
      "Iteration 000329: OneCycleScheduler setting learning rate to 0.00011669742593491987.\n",
      "330/343 [===========================>..] - ETA: 12s - loss: 0.5111 - acc: 0.8148 - kappa: 0.9514\n",
      "Iteration 000330: OneCycleScheduler setting learning rate to 0.000116930548810102.\n",
      "331/343 [===========================>..] - ETA: 11s - loss: 0.5114 - acc: 0.8146 - kappa: 0.9514\n",
      "Iteration 000331: OneCycleScheduler setting learning rate to 0.00011716367168528412.\n",
      "332/343 [============================>.] - ETA: 10s - loss: 0.5109 - acc: 0.8148 - kappa: 0.9516\n",
      "Iteration 000332: OneCycleScheduler setting learning rate to 0.00011739679456046625.\n",
      "333/343 [============================>.] - ETA: 9s - loss: 0.5118 - acc: 0.8146 - kappa: 0.9516 \n",
      "Iteration 000333: OneCycleScheduler setting learning rate to 0.00011762991743564837.\n",
      "334/343 [============================>.] - ETA: 8s - loss: 0.5129 - acc: 0.8136 - kappa: 0.9509\n",
      "Iteration 000334: OneCycleScheduler setting learning rate to 0.0001178630403108305.\n",
      "335/343 [============================>.] - ETA: 7s - loss: 0.5128 - acc: 0.8138 - kappa: 0.9507\n",
      "Iteration 000335: OneCycleScheduler setting learning rate to 0.00011809616318601262.\n",
      "336/343 [============================>.] - ETA: 6s - loss: 0.5130 - acc: 0.8140 - kappa: 0.9508\n",
      "Iteration 000336: OneCycleScheduler setting learning rate to 0.00011832928606119478.\n",
      "337/343 [============================>.] - ETA: 5s - loss: 0.5119 - acc: 0.8145 - kappa: 0.9510\n",
      "Iteration 000337: OneCycleScheduler setting learning rate to 0.0001185624089363769.\n",
      "338/343 [============================>.] - ETA: 4s - loss: 0.5129 - acc: 0.8140 - kappa: 0.9509\n",
      "Iteration 000338: OneCycleScheduler setting learning rate to 0.00011879553181155903.\n",
      "339/343 [============================>.] - ETA: 3s - loss: 0.5124 - acc: 0.8138 - kappa: 0.9510\n",
      "Iteration 000339: OneCycleScheduler setting learning rate to 0.00011902865468674115.\n",
      "340/343 [============================>.] - ETA: 2s - loss: 0.5132 - acc: 0.8129 - kappa: 0.9507\n",
      "Iteration 000340: OneCycleScheduler setting learning rate to 0.00011926177756192328.\n",
      "341/343 [============================>.] - ETA: 1s - loss: 0.5142 - acc: 0.8123 - kappa: 0.9505\n",
      "Iteration 000341: OneCycleScheduler setting learning rate to 0.0001194949004371054.\n",
      "342/343 [============================>.] - ETA: 0s - loss: 0.5150 - acc: 0.8118 - kappa: 0.9501\n",
      "Iteration 000342: OneCycleScheduler setting learning rate to 0.00011972802331228753.\n",
      "343/343 [==============================] - 422s 1s/step - loss: 0.5151 - acc: 0.8116 - kappa: 0.9500 - val_loss: 0.9814 - val_acc: 0.7456 - val_kappa: 0.9028\n",
      "Epoch 7/30\n",
      "\n",
      "Iteration 000000: OneCycleScheduler setting learning rate to 4e-05.\n",
      "  1/343 [..............................] - ETA: 57s - loss: 1.0101 - acc: 0.6250 - kappa: 0.8047\n",
      "Iteration 000001: OneCycleScheduler setting learning rate to 4.023312287518213e-05.\n",
      "  2/343 [..............................] - ETA: 54s - loss: 0.8578 - acc: 0.6875 - kappa: 0.8398\n",
      "Iteration 000002: OneCycleScheduler setting learning rate to 4.046624575036426e-05.\n",
      "  3/343 [..............................] - ETA: 50s - loss: 0.7594 - acc: 0.7083 - kappa: 0.8698\n",
      "Iteration 000003: OneCycleScheduler setting learning rate to 4.0699368625546386e-05.\n",
      "  4/343 [..............................] - ETA: 47s - loss: 0.6741 - acc: 0.7500 - kappa: 0.9004\n",
      "Iteration 000004: OneCycleScheduler setting learning rate to 4.093249150072851e-05.\n",
      "  5/343 [..............................] - ETA: 46s - loss: 0.6256 - acc: 0.7750 - kappa: 0.9062\n",
      "Iteration 000005: OneCycleScheduler setting learning rate to 4.1165614375910636e-05.\n",
      "  6/343 [..............................] - ETA: 45s - loss: 0.5420 - acc: 0.8125 - kappa: 0.9219\n",
      "Iteration 000006: OneCycleScheduler setting learning rate to 4.139873725109277e-05.\n",
      "  7/343 [..............................] - ETA: 44s - loss: 0.5181 - acc: 0.8393 - kappa: 0.9330\n",
      "Iteration 000007: OneCycleScheduler setting learning rate to 4.1631860126274893e-05.\n",
      "  8/343 [..............................] - ETA: 44s - loss: 0.4798 - acc: 0.8438 - kappa: 0.9404\n",
      "Iteration 000008: OneCycleScheduler setting learning rate to 4.186498300145702e-05.\n",
      "  9/343 [..............................] - ETA: 43s - loss: 0.5083 - acc: 0.8194 - kappa: 0.9392\n",
      "Iteration 000009: OneCycleScheduler setting learning rate to 4.209810587663915e-05.\n",
      " 10/343 [..............................] - ETA: 45s - loss: 0.5411 - acc: 0.8000 - kappa: 0.9383\n",
      "Iteration 000010: OneCycleScheduler setting learning rate to 4.2331228751821276e-05.\n",
      " 11/343 [..............................] - ETA: 45s - loss: 0.5379 - acc: 0.7955 - kappa: 0.9411\n",
      "Iteration 000011: OneCycleScheduler setting learning rate to 4.25643516270034e-05.\n",
      " 12/343 [>.............................] - ETA: 47s - loss: 0.5056 - acc: 0.8125 - kappa: 0.9460\n",
      "Iteration 000012: OneCycleScheduler setting learning rate to 4.279747450218553e-05.\n",
      " 13/343 [>.............................] - ETA: 1:20 - loss: 0.5342 - acc: 0.7981 - kappa: 0.9405\n",
      "Iteration 000013: OneCycleScheduler setting learning rate to 4.303059737736766e-05.\n",
      " 14/343 [>.............................] - ETA: 1:41 - loss: 0.5078 - acc: 0.8125 - kappa: 0.9448\n",
      "Iteration 000014: OneCycleScheduler setting learning rate to 4.3263720252549784e-05.\n",
      " 15/343 [>.............................] - ETA: 1:58 - loss: 0.4915 - acc: 0.8167 - kappa: 0.9479\n",
      "Iteration 000015: OneCycleScheduler setting learning rate to 4.3496843127731916e-05.\n",
      " 16/343 [>.............................] - ETA: 2:37 - loss: 0.5176 - acc: 0.8047 - kappa: 0.9434\n",
      "Iteration 000016: OneCycleScheduler setting learning rate to 4.372996600291404e-05.\n",
      " 17/343 [>.............................] - ETA: 3:01 - loss: 0.5759 - acc: 0.8015 - kappa: 0.9449\n",
      "Iteration 000017: OneCycleScheduler setting learning rate to 4.3963088878096166e-05.\n",
      " 18/343 [>.............................] - ETA: 3:10 - loss: 0.5670 - acc: 0.8056 - kappa: 0.9440\n",
      "Iteration 000018: OneCycleScheduler setting learning rate to 4.419621175327829e-05.\n",
      " 19/343 [>.............................] - ETA: 3:18 - loss: 0.5629 - acc: 0.8092 - kappa: 0.9465\n",
      "Iteration 000019: OneCycleScheduler setting learning rate to 4.442933462846042e-05.\n",
      " 20/343 [>.............................] - ETA: 3:37 - loss: 0.5515 - acc: 0.8187 - kappa: 0.9492\n",
      "Iteration 000020: OneCycleScheduler setting learning rate to 4.466245750364255e-05.\n",
      " 21/343 [>.............................] - ETA: 3:50 - loss: 0.5641 - acc: 0.8155 - kappa: 0.9423\n",
      "Iteration 000021: OneCycleScheduler setting learning rate to 4.4895580378824674e-05.\n",
      " 22/343 [>.............................] - ETA: 3:53 - loss: 0.5574 - acc: 0.8239 - kappa: 0.9450\n",
      "Iteration 000022: OneCycleScheduler setting learning rate to 4.5128703254006806e-05.\n",
      " 23/343 [=>............................] - ETA: 3:55 - loss: 0.5512 - acc: 0.8261 - kappa: 0.9470\n",
      "Iteration 000023: OneCycleScheduler setting learning rate to 4.536182612918893e-05.\n",
      " 24/343 [=>............................] - ETA: 4:00 - loss: 0.5459 - acc: 0.8333 - kappa: 0.9492\n",
      "Iteration 000024: OneCycleScheduler setting learning rate to 4.5594949004371056e-05.\n",
      " 25/343 [=>............................] - ETA: 4:02 - loss: 0.5396 - acc: 0.8300 - kappa: 0.9484\n",
      "Iteration 000025: OneCycleScheduler setting learning rate to 4.582807187955318e-05.\n",
      " 26/343 [=>............................] - ETA: 4:05 - loss: 0.5355 - acc: 0.8317 - kappa: 0.9492\n",
      "Iteration 000026: OneCycleScheduler setting learning rate to 4.606119475473531e-05.\n",
      " 27/343 [=>............................] - ETA: 4:04 - loss: 0.5387 - acc: 0.8287 - kappa: 0.9499\n",
      "Iteration 000027: OneCycleScheduler setting learning rate to 4.629431762991744e-05.\n",
      " 28/343 [=>............................] - ETA: 4:04 - loss: 0.5504 - acc: 0.8170 - kappa: 0.9417\n",
      "Iteration 000028: OneCycleScheduler setting learning rate to 4.6527440505099564e-05.\n",
      " 29/343 [=>............................] - ETA: 4:06 - loss: 0.5376 - acc: 0.8233 - kappa: 0.9437\n",
      "Iteration 000029: OneCycleScheduler setting learning rate to 4.6760563380281696e-05.\n",
      " 30/343 [=>............................] - ETA: 4:04 - loss: 0.5441 - acc: 0.8208 - kappa: 0.9414\n",
      "Iteration 000030: OneCycleScheduler setting learning rate to 4.699368625546382e-05.\n",
      " 31/343 [=>............................] - ETA: 4:06 - loss: 0.5441 - acc: 0.8185 - kappa: 0.9410\n",
      "Iteration 000031: OneCycleScheduler setting learning rate to 4.7226809130645946e-05.\n",
      " 32/343 [=>............................] - ETA: 4:07 - loss: 0.5409 - acc: 0.8164 - kappa: 0.9407\n",
      "Iteration 000032: OneCycleScheduler setting learning rate to 4.745993200582808e-05.\n",
      " 33/343 [=>............................] - ETA: 4:06 - loss: 0.5456 - acc: 0.8144 - kappa: 0.9415\n",
      "Iteration 000033: OneCycleScheduler setting learning rate to 4.7693054881010203e-05.\n",
      " 34/343 [=>............................] - ETA: 4:08 - loss: 0.5534 - acc: 0.8088 - kappa: 0.9375\n",
      "Iteration 000034: OneCycleScheduler setting learning rate to 4.792617775619233e-05.\n",
      " 35/343 [==>...........................] - ETA: 4:06 - loss: 0.5574 - acc: 0.8036 - kappa: 0.9373\n",
      "Iteration 000035: OneCycleScheduler setting learning rate to 4.815930063137446e-05.\n",
      " 36/343 [==>...........................] - ETA: 4:08 - loss: 0.5577 - acc: 0.7986 - kappa: 0.9355\n",
      "Iteration 000036: OneCycleScheduler setting learning rate to 4.8392423506556586e-05.\n",
      " 37/343 [==>...........................] - ETA: 4:10 - loss: 0.5485 - acc: 0.8041 - kappa: 0.9373\n",
      "Iteration 000037: OneCycleScheduler setting learning rate to 4.862554638173871e-05.\n",
      " 38/343 [==>...........................] - ETA: 4:12 - loss: 0.5415 - acc: 0.8092 - kappa: 0.9389\n",
      "Iteration 000038: OneCycleScheduler setting learning rate to 4.8858669256920836e-05.\n",
      " 39/343 [==>...........................] - ETA: 4:12 - loss: 0.5500 - acc: 0.8045 - kappa: 0.9373\n",
      "Iteration 000039: OneCycleScheduler setting learning rate to 4.909179213210297e-05.\n",
      " 40/343 [==>...........................] - ETA: 4:11 - loss: 0.5450 - acc: 0.8063 - kappa: 0.9381\n",
      "Iteration 000040: OneCycleScheduler setting learning rate to 4.9324915007285094e-05.\n",
      " 41/343 [==>...........................] - ETA: 4:09 - loss: 0.5362 - acc: 0.8110 - kappa: 0.9396\n",
      "Iteration 000041: OneCycleScheduler setting learning rate to 4.955803788246722e-05.\n",
      " 42/343 [==>...........................] - ETA: 4:08 - loss: 0.5421 - acc: 0.8095 - kappa: 0.9394\n",
      "Iteration 000042: OneCycleScheduler setting learning rate to 4.979116075764935e-05.\n",
      " 43/343 [==>...........................] - ETA: 4:07 - loss: 0.5434 - acc: 0.8081 - kappa: 0.9400\n",
      "Iteration 000043: OneCycleScheduler setting learning rate to 5.0024283632831476e-05.\n",
      " 44/343 [==>...........................] - ETA: 4:08 - loss: 0.5429 - acc: 0.8068 - kappa: 0.9407\n",
      "Iteration 000044: OneCycleScheduler setting learning rate to 5.02574065080136e-05.\n",
      " 45/343 [==>...........................] - ETA: 4:09 - loss: 0.5367 - acc: 0.8111 - kappa: 0.9420\n",
      "Iteration 000045: OneCycleScheduler setting learning rate to 5.0490529383195726e-05.\n",
      " 46/343 [===>..........................] - ETA: 4:10 - loss: 0.5336 - acc: 0.8125 - kappa: 0.9431\n",
      "Iteration 000046: OneCycleScheduler setting learning rate to 5.072365225837786e-05.\n",
      " 47/343 [===>..........................] - ETA: 4:09 - loss: 0.5260 - acc: 0.8138 - kappa: 0.9441\n",
      "Iteration 000047: OneCycleScheduler setting learning rate to 5.0956775133559984e-05.\n",
      " 48/343 [===>..........................] - ETA: 4:08 - loss: 0.5209 - acc: 0.8177 - kappa: 0.9453\n",
      "Iteration 000048: OneCycleScheduler setting learning rate to 5.1189898008742116e-05.\n",
      " 49/343 [===>..........................] - ETA: 4:06 - loss: 0.5145 - acc: 0.8214 - kappa: 0.9464\n",
      "Iteration 000049: OneCycleScheduler setting learning rate to 5.142302088392424e-05.\n",
      " 50/343 [===>..........................] - ETA: 4:05 - loss: 0.5389 - acc: 0.8150 - kappa: 0.9450\n",
      "Iteration 000050: OneCycleScheduler setting learning rate to 5.1656143759106366e-05.\n",
      " 51/343 [===>..........................] - ETA: 4:04 - loss: 0.5420 - acc: 0.8113 - kappa: 0.9447\n",
      "Iteration 000051: OneCycleScheduler setting learning rate to 5.188926663428849e-05.\n",
      " 52/343 [===>..........................] - ETA: 4:04 - loss: 0.5385 - acc: 0.8125 - kappa: 0.9456\n",
      "Iteration 000052: OneCycleScheduler setting learning rate to 5.212238950947062e-05.\n",
      " 53/343 [===>..........................] - ETA: 4:04 - loss: 0.5333 - acc: 0.8137 - kappa: 0.9465\n",
      "Iteration 000053: OneCycleScheduler setting learning rate to 5.235551238465275e-05.\n",
      " 54/343 [===>..........................] - ETA: 4:05 - loss: 0.5290 - acc: 0.8148 - kappa: 0.9473\n",
      "Iteration 000054: OneCycleScheduler setting learning rate to 5.2588635259834874e-05.\n",
      " 55/343 [===>..........................] - ETA: 4:05 - loss: 0.5229 - acc: 0.8182 - kappa: 0.9483\n",
      "Iteration 000055: OneCycleScheduler setting learning rate to 5.2821758135017006e-05.\n",
      " 56/343 [===>..........................] - ETA: 4:07 - loss: 0.5177 - acc: 0.8214 - kappa: 0.9492\n",
      "Iteration 000056: OneCycleScheduler setting learning rate to 5.305488101019913e-05.\n",
      " 57/343 [===>..........................] - ETA: 4:07 - loss: 0.5155 - acc: 0.8202 - kappa: 0.9496\n",
      "Iteration 000057: OneCycleScheduler setting learning rate to 5.3288003885381256e-05.\n",
      " 58/343 [====>.........................] - ETA: 4:07 - loss: 0.5168 - acc: 0.8190 - kappa: 0.9499\n",
      "Iteration 000058: OneCycleScheduler setting learning rate to 5.352112676056338e-05.\n",
      " 59/343 [====>.........................] - ETA: 4:06 - loss: 0.5258 - acc: 0.8114 - kappa: 0.9460\n",
      "Iteration 000059: OneCycleScheduler setting learning rate to 5.3754249635745514e-05.\n",
      " 60/343 [====>.........................] - ETA: 4:04 - loss: 0.5189 - acc: 0.8146 - kappa: 0.9469\n",
      "Iteration 000060: OneCycleScheduler setting learning rate to 5.398737251092764e-05.\n",
      " 61/343 [====>.........................] - ETA: 4:05 - loss: 0.5163 - acc: 0.8156 - kappa: 0.9476\n",
      "Iteration 000061: OneCycleScheduler setting learning rate to 5.4220495386109764e-05.\n",
      " 62/343 [====>.........................] - ETA: 4:04 - loss: 0.5119 - acc: 0.8165 - kappa: 0.9480\n",
      "Iteration 000062: OneCycleScheduler setting learning rate to 5.4453618261291896e-05.\n",
      " 63/343 [====>.........................] - ETA: 4:04 - loss: 0.5089 - acc: 0.8175 - kappa: 0.9487\n",
      "Iteration 000063: OneCycleScheduler setting learning rate to 5.468674113647402e-05.\n",
      " 64/343 [====>.........................] - ETA: 4:07 - loss: 0.5187 - acc: 0.8125 - kappa: 0.9435\n",
      "Iteration 000064: OneCycleScheduler setting learning rate to 5.4919864011656146e-05.\n",
      " 65/343 [====>.........................] - ETA: 4:06 - loss: 0.5180 - acc: 0.8135 - kappa: 0.9442\n",
      "Iteration 000065: OneCycleScheduler setting learning rate to 5.515298688683827e-05.\n",
      " 66/343 [====>.........................] - ETA: 4:06 - loss: 0.5138 - acc: 0.8163 - kappa: 0.9451\n",
      "Iteration 000066: OneCycleScheduler setting learning rate to 5.5386109762020404e-05.\n",
      " 67/343 [====>.........................] - ETA: 4:04 - loss: 0.5111 - acc: 0.8172 - kappa: 0.9454\n",
      "Iteration 000067: OneCycleScheduler setting learning rate to 5.561923263720253e-05.\n",
      " 68/343 [====>.........................] - ETA: 4:03 - loss: 0.5130 - acc: 0.8143 - kappa: 0.9444\n",
      "Iteration 000068: OneCycleScheduler setting learning rate to 5.585235551238466e-05.\n",
      " 69/343 [=====>........................] - ETA: 4:02 - loss: 0.5176 - acc: 0.8098 - kappa: 0.9424\n",
      "Iteration 000069: OneCycleScheduler setting learning rate to 5.6085478387566786e-05.\n",
      " 70/343 [=====>........................] - ETA: 4:02 - loss: 0.5177 - acc: 0.8089 - kappa: 0.9427\n",
      "Iteration 000070: OneCycleScheduler setting learning rate to 5.631860126274891e-05.\n",
      " 71/343 [=====>........................] - ETA: 4:02 - loss: 0.5151 - acc: 0.8081 - kappa: 0.9431\n",
      "Iteration 000071: OneCycleScheduler setting learning rate to 5.6551724137931037e-05.\n",
      " 72/343 [=====>........................] - ETA: 4:01 - loss: 0.5108 - acc: 0.8090 - kappa: 0.9438\n",
      "Iteration 000072: OneCycleScheduler setting learning rate to 5.678484701311316e-05.\n",
      " 73/343 [=====>........................] - ETA: 4:01 - loss: 0.5115 - acc: 0.8082 - kappa: 0.9441\n",
      "Iteration 000073: OneCycleScheduler setting learning rate to 5.7017969888295294e-05.\n",
      " 74/343 [=====>........................] - ETA: 4:01 - loss: 0.5114 - acc: 0.8091 - kappa: 0.9448\n",
      "Iteration 000074: OneCycleScheduler setting learning rate to 5.7251092763477426e-05.\n",
      " 75/343 [=====>........................] - ETA: 4:00 - loss: 0.5121 - acc: 0.8100 - kappa: 0.9454\n",
      "Iteration 000075: OneCycleScheduler setting learning rate to 5.748421563865955e-05.\n",
      " 76/343 [=====>........................] - ETA: 4:00 - loss: 0.5090 - acc: 0.8125 - kappa: 0.9461\n",
      "Iteration 000076: OneCycleScheduler setting learning rate to 5.7717338513841676e-05.\n",
      " 77/343 [=====>........................] - ETA: 4:00 - loss: 0.5054 - acc: 0.8149 - kappa: 0.9468\n",
      "Iteration 000077: OneCycleScheduler setting learning rate to 5.79504613890238e-05.\n",
      " 78/343 [=====>........................] - ETA: 4:00 - loss: 0.5057 - acc: 0.8141 - kappa: 0.9459\n",
      "Iteration 000078: OneCycleScheduler setting learning rate to 5.818358426420593e-05.\n",
      " 79/343 [=====>........................] - ETA: 3:58 - loss: 0.5049 - acc: 0.8133 - kappa: 0.9462\n",
      "Iteration 000079: OneCycleScheduler setting learning rate to 5.841670713938806e-05.\n",
      " 80/343 [=====>........................] - ETA: 3:58 - loss: 0.5053 - acc: 0.8141 - kappa: 0.9465\n",
      "Iteration 000080: OneCycleScheduler setting learning rate to 5.8649830014570184e-05.\n",
      " 81/343 [======>.......................] - ETA: 3:58 - loss: 0.5070 - acc: 0.8133 - kappa: 0.9463\n",
      "Iteration 000081: OneCycleScheduler setting learning rate to 5.8882952889752316e-05.\n",
      " 82/343 [======>.......................] - ETA: 3:58 - loss: 0.5156 - acc: 0.8095 - kappa: 0.9435\n",
      "Iteration 000082: OneCycleScheduler setting learning rate to 5.911607576493444e-05.\n",
      " 83/343 [======>.......................] - ETA: 3:57 - loss: 0.5121 - acc: 0.8102 - kappa: 0.9441\n",
      "Iteration 000083: OneCycleScheduler setting learning rate to 5.9349198640116566e-05.\n",
      " 84/343 [======>.......................] - ETA: 3:56 - loss: 0.5090 - acc: 0.8125 - kappa: 0.9448\n",
      "Iteration 000084: OneCycleScheduler setting learning rate to 5.958232151529869e-05.\n",
      " 85/343 [======>.......................] - ETA: 3:56 - loss: 0.5146 - acc: 0.8059 - kappa: 0.9395\n",
      "Iteration 000085: OneCycleScheduler setting learning rate to 5.981544439048082e-05.\n",
      " 86/343 [======>.......................] - ETA: 3:55 - loss: 0.5176 - acc: 0.8038 - kappa: 0.9394\n",
      "Iteration 000086: OneCycleScheduler setting learning rate to 6.004856726566295e-05.\n",
      " 87/343 [======>.......................] - ETA: 3:53 - loss: 0.5166 - acc: 0.8032 - kappa: 0.9393\n",
      "Iteration 000087: OneCycleScheduler setting learning rate to 6.0281690140845074e-05.\n",
      " 88/343 [======>.......................] - ETA: 3:52 - loss: 0.5137 - acc: 0.8040 - kappa: 0.9399\n",
      "Iteration 000088: OneCycleScheduler setting learning rate to 6.0514813016027206e-05.\n",
      " 89/343 [======>.......................] - ETA: 3:51 - loss: 0.5126 - acc: 0.8034 - kappa: 0.9402\n",
      "Iteration 000089: OneCycleScheduler setting learning rate to 6.074793589120933e-05.\n",
      " 90/343 [======>.......................] - ETA: 3:52 - loss: 0.5207 - acc: 0.8028 - kappa: 0.9395\n",
      "Iteration 000090: OneCycleScheduler setting learning rate to 6.0981058766391456e-05.\n",
      " 91/343 [======>.......................] - ETA: 3:51 - loss: 0.5195 - acc: 0.8022 - kappa: 0.9398\n",
      "Iteration 000091: OneCycleScheduler setting learning rate to 6.121418164157358e-05.\n",
      " 92/343 [=======>......................] - ETA: 3:50 - loss: 0.5192 - acc: 0.8016 - kappa: 0.9397\n",
      "Iteration 000092: OneCycleScheduler setting learning rate to 6.144730451675571e-05.\n",
      " 93/343 [=======>......................] - ETA: 3:49 - loss: 0.5155 - acc: 0.8038 - kappa: 0.9404\n",
      "Iteration 000093: OneCycleScheduler setting learning rate to 6.168042739193783e-05.\n",
      " 94/343 [=======>......................] - ETA: 3:48 - loss: 0.5152 - acc: 0.8045 - kappa: 0.9409\n",
      "Iteration 000094: OneCycleScheduler setting learning rate to 6.191355026711997e-05.\n",
      " 95/343 [=======>......................] - ETA: 3:47 - loss: 0.5140 - acc: 0.8053 - kappa: 0.9412\n",
      "Iteration 000095: OneCycleScheduler setting learning rate to 6.21466731423021e-05.\n",
      " 96/343 [=======>......................] - ETA: 3:47 - loss: 0.5190 - acc: 0.8021 - kappa: 0.9398\n",
      "Iteration 000096: OneCycleScheduler setting learning rate to 6.237979601748422e-05.\n",
      " 97/343 [=======>......................] - ETA: 3:45 - loss: 0.5198 - acc: 0.8015 - kappa: 0.9397\n",
      "Iteration 000097: OneCycleScheduler setting learning rate to 6.261291889266635e-05.\n",
      " 98/343 [=======>......................] - ETA: 3:45 - loss: 0.5234 - acc: 0.7997 - kappa: 0.9383\n",
      "Iteration 000098: OneCycleScheduler setting learning rate to 6.284604176784847e-05.\n",
      " 99/343 [=======>......................] - ETA: 3:45 - loss: 0.5226 - acc: 0.8005 - kappa: 0.9388\n",
      "Iteration 000099: OneCycleScheduler setting learning rate to 6.307916464303061e-05.\n",
      "100/343 [=======>......................] - ETA: 3:44 - loss: 0.5216 - acc: 0.8013 - kappa: 0.9394\n",
      "Iteration 000100: OneCycleScheduler setting learning rate to 6.331228751821274e-05.\n",
      "101/343 [=======>......................] - ETA: 3:44 - loss: 0.5205 - acc: 0.8007 - kappa: 0.9397\n",
      "Iteration 000101: OneCycleScheduler setting learning rate to 6.354541039339486e-05.\n",
      "102/343 [=======>......................] - ETA: 3:43 - loss: 0.5178 - acc: 0.8027 - kappa: 0.9403\n",
      "Iteration 000102: OneCycleScheduler setting learning rate to 6.377853326857699e-05.\n",
      "103/343 [========>.....................] - ETA: 3:42 - loss: 0.5152 - acc: 0.8034 - kappa: 0.9408\n",
      "Iteration 000103: OneCycleScheduler setting learning rate to 6.401165614375911e-05.\n",
      "104/343 [========>.....................] - ETA: 3:41 - loss: 0.5176 - acc: 0.8029 - kappa: 0.9410\n",
      "Iteration 000104: OneCycleScheduler setting learning rate to 6.424477901894124e-05.\n",
      "105/343 [========>.....................] - ETA: 3:40 - loss: 0.5160 - acc: 0.8024 - kappa: 0.9409\n",
      "Iteration 000105: OneCycleScheduler setting learning rate to 6.447790189412336e-05.\n",
      "106/343 [========>.....................] - ETA: 3:40 - loss: 0.5172 - acc: 0.8007 - kappa: 0.9408\n",
      "Iteration 000106: OneCycleScheduler setting learning rate to 6.471102476930549e-05.\n",
      "107/343 [========>.....................] - ETA: 3:39 - loss: 0.5187 - acc: 0.8014 - kappa: 0.9411\n",
      "Iteration 000107: OneCycleScheduler setting learning rate to 6.494414764448761e-05.\n",
      "108/343 [========>.....................] - ETA: 3:39 - loss: 0.5190 - acc: 0.8009 - kappa: 0.9413\n",
      "Iteration 000108: OneCycleScheduler setting learning rate to 6.517727051966975e-05.\n",
      "109/343 [========>.....................] - ETA: 3:38 - loss: 0.5150 - acc: 0.8028 - kappa: 0.9419\n",
      "Iteration 000109: OneCycleScheduler setting learning rate to 6.541039339485188e-05.\n",
      "110/343 [========>.....................] - ETA: 3:37 - loss: 0.5140 - acc: 0.8023 - kappa: 0.9421\n",
      "Iteration 000110: OneCycleScheduler setting learning rate to 6.5643516270034e-05.\n",
      "111/343 [========>.....................] - ETA: 3:35 - loss: 0.5138 - acc: 0.8018 - kappa: 0.9424\n",
      "Iteration 000111: OneCycleScheduler setting learning rate to 6.587663914521613e-05.\n",
      "112/343 [========>.....................] - ETA: 3:35 - loss: 0.5171 - acc: 0.7991 - kappa: 0.9418\n",
      "Iteration 000112: OneCycleScheduler setting learning rate to 6.610976202039825e-05.\n",
      "113/343 [========>.....................] - ETA: 3:34 - loss: 0.5142 - acc: 0.8009 - kappa: 0.9423\n",
      "Iteration 000113: OneCycleScheduler setting learning rate to 6.634288489558039e-05.\n",
      "114/343 [========>.....................] - ETA: 3:33 - loss: 0.5130 - acc: 0.8015 - kappa: 0.9427\n",
      "Iteration 000114: OneCycleScheduler setting learning rate to 6.657600777076252e-05.\n",
      "115/343 [=========>....................] - ETA: 3:32 - loss: 0.5136 - acc: 0.8011 - kappa: 0.9426\n",
      "Iteration 000115: OneCycleScheduler setting learning rate to 6.680913064594464e-05.\n",
      "116/343 [=========>....................] - ETA: 3:31 - loss: 0.5106 - acc: 0.8028 - kappa: 0.9431\n",
      "Iteration 000116: OneCycleScheduler setting learning rate to 6.704225352112677e-05.\n",
      "117/343 [=========>....................] - ETA: 3:30 - loss: 0.5095 - acc: 0.8024 - kappa: 0.9433\n",
      "Iteration 000117: OneCycleScheduler setting learning rate to 6.727537639630889e-05.\n",
      "118/343 [=========>....................] - ETA: 3:29 - loss: 0.5065 - acc: 0.8040 - kappa: 0.9438\n",
      "Iteration 000118: OneCycleScheduler setting learning rate to 6.750849927149102e-05.\n",
      "119/343 [=========>....................] - ETA: 3:28 - loss: 0.5051 - acc: 0.8046 - kappa: 0.9442\n",
      "Iteration 000119: OneCycleScheduler setting learning rate to 6.774162214667314e-05.\n",
      "120/343 [=========>....................] - ETA: 3:28 - loss: 0.5035 - acc: 0.8052 - kappa: 0.9446\n",
      "Iteration 000120: OneCycleScheduler setting learning rate to 6.797474502185527e-05.\n",
      "121/343 [=========>....................] - ETA: 3:28 - loss: 0.5048 - acc: 0.8048 - kappa: 0.9445\n",
      "Iteration 000121: OneCycleScheduler setting learning rate to 6.82078678970374e-05.\n",
      "122/343 [=========>....................] - ETA: 3:27 - loss: 0.5029 - acc: 0.8053 - kappa: 0.9449\n",
      "Iteration 000122: OneCycleScheduler setting learning rate to 6.844099077221953e-05.\n",
      "123/343 [=========>....................] - ETA: 3:26 - loss: 0.5021 - acc: 0.8059 - kappa: 0.9451\n",
      "Iteration 000123: OneCycleScheduler setting learning rate to 6.867411364740166e-05.\n",
      "124/343 [=========>....................] - ETA: 3:25 - loss: 0.5019 - acc: 0.8054 - kappa: 0.9452\n",
      "Iteration 000124: OneCycleScheduler setting learning rate to 6.890723652258378e-05.\n",
      "125/343 [=========>....................] - ETA: 3:24 - loss: 0.5004 - acc: 0.8060 - kappa: 0.9456\n",
      "Iteration 000125: OneCycleScheduler setting learning rate to 6.914035939776591e-05.\n",
      "126/343 [==========>...................] - ETA: 3:23 - loss: 0.4970 - acc: 0.8075 - kappa: 0.9461\n",
      "Iteration 000126: OneCycleScheduler setting learning rate to 6.937348227294805e-05.\n",
      "127/343 [==========>...................] - ETA: 3:22 - loss: 0.4978 - acc: 0.8061 - kappa: 0.9455\n",
      "Iteration 000127: OneCycleScheduler setting learning rate to 6.960660514813017e-05.\n",
      "128/343 [==========>...................] - ETA: 3:21 - loss: 0.5024 - acc: 0.8047 - kappa: 0.9449\n",
      "Iteration 000128: OneCycleScheduler setting learning rate to 6.98397280233123e-05.\n",
      "129/343 [==========>...................] - ETA: 3:21 - loss: 0.4993 - acc: 0.8062 - kappa: 0.9454\n",
      "Iteration 000129: OneCycleScheduler setting learning rate to 7.007285089849442e-05.\n",
      "130/343 [==========>...................] - ETA: 3:20 - loss: 0.5040 - acc: 0.8058 - kappa: 0.9456\n",
      "Iteration 000130: OneCycleScheduler setting learning rate to 7.030597377367655e-05.\n",
      "131/343 [==========>...................] - ETA: 3:19 - loss: 0.5008 - acc: 0.8073 - kappa: 0.9460\n",
      "Iteration 000131: OneCycleScheduler setting learning rate to 7.053909664885867e-05.\n",
      "132/343 [==========>...................] - ETA: 3:18 - loss: 0.4992 - acc: 0.8078 - kappa: 0.9461\n",
      "Iteration 000132: OneCycleScheduler setting learning rate to 7.07722195240408e-05.\n",
      "133/343 [==========>...................] - ETA: 3:16 - loss: 0.4984 - acc: 0.8083 - kappa: 0.9465\n",
      "Iteration 000133: OneCycleScheduler setting learning rate to 7.100534239922292e-05.\n",
      "134/343 [==========>...................] - ETA: 3:15 - loss: 0.4969 - acc: 0.8097 - kappa: 0.9469\n",
      "Iteration 000134: OneCycleScheduler setting learning rate to 7.123846527440505e-05.\n",
      "135/343 [==========>...................] - ETA: 3:14 - loss: 0.4939 - acc: 0.8111 - kappa: 0.9473\n",
      "Iteration 000135: OneCycleScheduler setting learning rate to 7.147158814958719e-05.\n",
      "136/343 [==========>...................] - ETA: 3:13 - loss: 0.4924 - acc: 0.8107 - kappa: 0.9474\n",
      "Iteration 000136: OneCycleScheduler setting learning rate to 7.170471102476931e-05.\n",
      "137/343 [==========>...................] - ETA: 3:12 - loss: 0.4925 - acc: 0.8102 - kappa: 0.9476\n",
      "Iteration 000137: OneCycleScheduler setting learning rate to 7.193783389995144e-05.\n",
      "138/343 [===========>..................] - ETA: 3:11 - loss: 0.4981 - acc: 0.8089 - kappa: 0.9475\n",
      "Iteration 000138: OneCycleScheduler setting learning rate to 7.217095677513358e-05.\n",
      "139/343 [===========>..................] - ETA: 3:10 - loss: 0.4992 - acc: 0.8076 - kappa: 0.9469\n",
      "Iteration 000139: OneCycleScheduler setting learning rate to 7.24040796503157e-05.\n",
      "140/343 [===========>..................] - ETA: 3:09 - loss: 0.4995 - acc: 0.8071 - kappa: 0.9471\n",
      "Iteration 000140: OneCycleScheduler setting learning rate to 7.263720252549783e-05.\n",
      "141/343 [===========>..................] - ETA: 3:09 - loss: 0.4988 - acc: 0.8067 - kappa: 0.9473\n",
      "Iteration 000141: OneCycleScheduler setting learning rate to 7.287032540067995e-05.\n",
      "142/343 [===========>..................] - ETA: 3:08 - loss: 0.4981 - acc: 0.8072 - kappa: 0.9474\n",
      "Iteration 000142: OneCycleScheduler setting learning rate to 7.310344827586208e-05.\n",
      "143/343 [===========>..................] - ETA: 3:06 - loss: 0.4990 - acc: 0.8077 - kappa: 0.9477\n",
      "Iteration 000143: OneCycleScheduler setting learning rate to 7.33365711510442e-05.\n",
      "144/343 [===========>..................] - ETA: 3:06 - loss: 0.4987 - acc: 0.8073 - kappa: 0.9479\n",
      "Iteration 000144: OneCycleScheduler setting learning rate to 7.356969402622633e-05.\n",
      "145/343 [===========>..................] - ETA: 3:05 - loss: 0.4999 - acc: 0.8078 - kappa: 0.9482\n",
      "Iteration 000145: OneCycleScheduler setting learning rate to 7.380281690140845e-05.\n",
      "146/343 [===========>..................] - ETA: 3:05 - loss: 0.4991 - acc: 0.8082 - kappa: 0.9485\n",
      "Iteration 000146: OneCycleScheduler setting learning rate to 7.403593977659058e-05.\n",
      "147/343 [===========>..................] - ETA: 3:04 - loss: 0.4986 - acc: 0.8087 - kappa: 0.9488\n",
      "Iteration 000147: OneCycleScheduler setting learning rate to 7.42690626517727e-05.\n",
      "148/343 [===========>..................] - ETA: 3:03 - loss: 0.4964 - acc: 0.8100 - kappa: 0.9491\n",
      "Iteration 000148: OneCycleScheduler setting learning rate to 7.450218552695484e-05.\n",
      "149/343 [============>.................] - ETA: 3:02 - loss: 0.4938 - acc: 0.8112 - kappa: 0.9495\n",
      "Iteration 000149: OneCycleScheduler setting learning rate to 7.473530840213697e-05.\n",
      "150/343 [============>.................] - ETA: 3:01 - loss: 0.4915 - acc: 0.8125 - kappa: 0.9498\n",
      "Iteration 000150: OneCycleScheduler setting learning rate to 7.496843127731909e-05.\n",
      "151/343 [============>.................] - ETA: 3:01 - loss: 0.4916 - acc: 0.8113 - kappa: 0.9493\n",
      "Iteration 000151: OneCycleScheduler setting learning rate to 7.520155415250122e-05.\n",
      "152/343 [============>.................] - ETA: 3:00 - loss: 0.4913 - acc: 0.8117 - kappa: 0.9494\n",
      "Iteration 000152: OneCycleScheduler setting learning rate to 7.543467702768336e-05.\n",
      "153/343 [============>.................] - ETA: 2:59 - loss: 0.4953 - acc: 0.8113 - kappa: 0.9496\n",
      "Iteration 000153: OneCycleScheduler setting learning rate to 7.566779990286548e-05.\n",
      "154/343 [============>.................] - ETA: 2:58 - loss: 0.4973 - acc: 0.8109 - kappa: 0.9491\n",
      "Iteration 000154: OneCycleScheduler setting learning rate to 7.59009227780476e-05.\n",
      "155/343 [============>.................] - ETA: 2:57 - loss: 0.4957 - acc: 0.8113 - kappa: 0.9493\n",
      "Iteration 000155: OneCycleScheduler setting learning rate to 7.613404565322973e-05.\n",
      "156/343 [============>.................] - ETA: 2:56 - loss: 0.4975 - acc: 0.8109 - kappa: 0.9495\n",
      "Iteration 000156: OneCycleScheduler setting learning rate to 7.636716852841186e-05.\n",
      "157/343 [============>.................] - ETA: 2:55 - loss: 0.4977 - acc: 0.8105 - kappa: 0.9493\n",
      "Iteration 000157: OneCycleScheduler setting learning rate to 7.660029140359398e-05.\n",
      "158/343 [============>.................] - ETA: 2:54 - loss: 0.4952 - acc: 0.8117 - kappa: 0.9497\n",
      "Iteration 000158: OneCycleScheduler setting learning rate to 7.683341427877611e-05.\n",
      "159/343 [============>.................] - ETA: 2:53 - loss: 0.4943 - acc: 0.8121 - kappa: 0.9498\n",
      "Iteration 000159: OneCycleScheduler setting learning rate to 7.706653715395823e-05.\n",
      "160/343 [============>.................] - ETA: 2:52 - loss: 0.4943 - acc: 0.8125 - kappa: 0.9500\n",
      "Iteration 000160: OneCycleScheduler setting learning rate to 7.729966002914036e-05.\n",
      "161/343 [=============>................] - ETA: 2:52 - loss: 0.4949 - acc: 0.8121 - kappa: 0.9502\n",
      "Iteration 000161: OneCycleScheduler setting learning rate to 7.753278290432248e-05.\n",
      "162/343 [=============>................] - ETA: 2:51 - loss: 0.4952 - acc: 0.8125 - kappa: 0.9503\n",
      "Iteration 000162: OneCycleScheduler setting learning rate to 7.776590577950462e-05.\n",
      "163/343 [=============>................] - ETA: 2:50 - loss: 0.4951 - acc: 0.8121 - kappa: 0.9504\n",
      "Iteration 000163: OneCycleScheduler setting learning rate to 7.799902865468675e-05.\n",
      "164/343 [=============>................] - ETA: 2:49 - loss: 0.4936 - acc: 0.8125 - kappa: 0.9506\n",
      "Iteration 000164: OneCycleScheduler setting learning rate to 7.823215152986887e-05.\n",
      "165/343 [=============>................] - ETA: 2:48 - loss: 0.4930 - acc: 0.8129 - kappa: 0.9509\n",
      "Iteration 000165: OneCycleScheduler setting learning rate to 7.846527440505101e-05.\n",
      "166/343 [=============>................] - ETA: 2:48 - loss: 0.4922 - acc: 0.8133 - kappa: 0.9510\n",
      "Iteration 000166: OneCycleScheduler setting learning rate to 7.869839728023314e-05.\n",
      "167/343 [=============>................] - ETA: 2:46 - loss: 0.4927 - acc: 0.8129 - kappa: 0.9509\n",
      "Iteration 000167: OneCycleScheduler setting learning rate to 7.893152015541526e-05.\n",
      "168/343 [=============>................] - ETA: 2:45 - loss: 0.4924 - acc: 0.8132 - kappa: 0.9510\n",
      "Iteration 000168: OneCycleScheduler setting learning rate to 7.916464303059739e-05.\n",
      "169/343 [=============>................] - ETA: 2:45 - loss: 0.4921 - acc: 0.8129 - kappa: 0.9509\n",
      "Iteration 000169: OneCycleScheduler setting learning rate to 7.939776590577951e-05.\n",
      "170/343 [=============>................] - ETA: 2:44 - loss: 0.4910 - acc: 0.8125 - kappa: 0.9507\n",
      "Iteration 000170: OneCycleScheduler setting learning rate to 7.963088878096164e-05.\n",
      "171/343 [=============>................] - ETA: 2:42 - loss: 0.4909 - acc: 0.8129 - kappa: 0.9510\n",
      "Iteration 000171: OneCycleScheduler setting learning rate to 7.986401165614376e-05.\n",
      "172/343 [==============>...............] - ETA: 2:41 - loss: 0.4893 - acc: 0.8132 - kappa: 0.9512\n",
      "Iteration 000172: OneCycleScheduler setting learning rate to 8.009713453132589e-05.\n",
      "173/343 [==============>...............] - ETA: 2:41 - loss: 0.4915 - acc: 0.8121 - kappa: 0.9508\n",
      "Iteration 000173: OneCycleScheduler setting learning rate to 8.033025740650801e-05.\n",
      "174/343 [==============>...............] - ETA: 2:40 - loss: 0.4912 - acc: 0.8118 - kappa: 0.9507\n",
      "Iteration 000174: OneCycleScheduler setting learning rate to 8.056338028169014e-05.\n",
      "175/343 [==============>...............] - ETA: 2:39 - loss: 0.4898 - acc: 0.8121 - kappa: 0.9509\n",
      "Iteration 000175: OneCycleScheduler setting learning rate to 8.079650315687228e-05.\n",
      "176/343 [==============>...............] - ETA: 2:38 - loss: 0.4895 - acc: 0.8125 - kappa: 0.9511\n",
      "Iteration 000176: OneCycleScheduler setting learning rate to 8.10296260320544e-05.\n",
      "177/343 [==============>...............] - ETA: 2:37 - loss: 0.4905 - acc: 0.8114 - kappa: 0.9507\n",
      "Iteration 000177: OneCycleScheduler setting learning rate to 8.126274890723653e-05.\n",
      "178/343 [==============>...............] - ETA: 2:36 - loss: 0.4919 - acc: 0.8111 - kappa: 0.9506\n",
      "Iteration 000178: OneCycleScheduler setting learning rate to 8.149587178241867e-05.\n",
      "179/343 [==============>...............] - ETA: 2:35 - loss: 0.4909 - acc: 0.8108 - kappa: 0.9505\n",
      "Iteration 000179: OneCycleScheduler setting learning rate to 8.172899465760079e-05.\n",
      "180/343 [==============>...............] - ETA: 2:34 - loss: 0.4902 - acc: 0.8104 - kappa: 0.9506\n",
      "Iteration 000180: OneCycleScheduler setting learning rate to 8.196211753278292e-05.\n",
      "181/343 [==============>...............] - ETA: 2:33 - loss: 0.4905 - acc: 0.8108 - kappa: 0.9507\n",
      "Iteration 000181: OneCycleScheduler setting learning rate to 8.219524040796504e-05.\n",
      "182/343 [==============>...............] - ETA: 2:32 - loss: 0.4919 - acc: 0.8104 - kappa: 0.9505\n",
      "Iteration 000182: OneCycleScheduler setting learning rate to 8.242836328314717e-05.\n",
      "183/343 [===============>..............] - ETA: 2:31 - loss: 0.4923 - acc: 0.8101 - kappa: 0.9506\n",
      "Iteration 000183: OneCycleScheduler setting learning rate to 8.266148615832929e-05.\n",
      "184/343 [===============>..............] - ETA: 2:30 - loss: 0.4909 - acc: 0.8111 - kappa: 0.9509\n",
      "Iteration 000184: OneCycleScheduler setting learning rate to 8.289460903351142e-05.\n",
      "185/343 [===============>..............] - ETA: 2:29 - loss: 0.4895 - acc: 0.8122 - kappa: 0.9512\n",
      "Iteration 000185: OneCycleScheduler setting learning rate to 8.312773190869354e-05.\n",
      "186/343 [===============>..............] - ETA: 2:28 - loss: 0.4913 - acc: 0.8112 - kappa: 0.9508\n",
      "Iteration 000186: OneCycleScheduler setting learning rate to 8.336085478387567e-05.\n",
      "187/343 [===============>..............] - ETA: 2:28 - loss: 0.4905 - acc: 0.8115 - kappa: 0.9509\n",
      "Iteration 000187: OneCycleScheduler setting learning rate to 8.359397765905779e-05.\n",
      "188/343 [===============>..............] - ETA: 2:27 - loss: 0.4884 - acc: 0.8125 - kappa: 0.9511\n",
      "Iteration 000188: OneCycleScheduler setting learning rate to 8.382710053423993e-05.\n",
      "189/343 [===============>..............] - ETA: 2:26 - loss: 0.4888 - acc: 0.8122 - kappa: 0.9510\n",
      "Iteration 000189: OneCycleScheduler setting learning rate to 8.406022340942206e-05.\n",
      "190/343 [===============>..............] - ETA: 2:25 - loss: 0.4884 - acc: 0.8118 - kappa: 0.9509\n",
      "Iteration 000190: OneCycleScheduler setting learning rate to 8.429334628460418e-05.\n",
      "191/343 [===============>..............] - ETA: 2:24 - loss: 0.4875 - acc: 0.8122 - kappa: 0.9511\n",
      "Iteration 000191: OneCycleScheduler setting learning rate to 8.452646915978631e-05.\n",
      "192/343 [===============>..............] - ETA: 2:23 - loss: 0.4859 - acc: 0.8132 - kappa: 0.9514\n",
      "Iteration 000192: OneCycleScheduler setting learning rate to 8.475959203496845e-05.\n",
      "193/343 [===============>..............] - ETA: 2:22 - loss: 0.4871 - acc: 0.8115 - kappa: 0.9510\n",
      "Iteration 000193: OneCycleScheduler setting learning rate to 8.499271491015057e-05.\n",
      "194/343 [===============>..............] - ETA: 2:21 - loss: 0.4863 - acc: 0.8112 - kappa: 0.9511\n",
      "Iteration 000194: OneCycleScheduler setting learning rate to 8.52258377853327e-05.\n",
      "195/343 [================>.............] - ETA: 2:20 - loss: 0.4866 - acc: 0.8096 - kappa: 0.9503\n",
      "Iteration 000195: OneCycleScheduler setting learning rate to 8.545896066051482e-05.\n",
      "196/343 [================>.............] - ETA: 2:19 - loss: 0.4852 - acc: 0.8106 - kappa: 0.9506\n",
      "Iteration 000196: OneCycleScheduler setting learning rate to 8.569208353569695e-05.\n",
      "197/343 [================>.............] - ETA: 2:18 - loss: 0.4866 - acc: 0.8109 - kappa: 0.9507\n",
      "Iteration 000197: OneCycleScheduler setting learning rate to 8.592520641087907e-05.\n",
      "198/343 [================>.............] - ETA: 2:17 - loss: 0.4870 - acc: 0.8112 - kappa: 0.9508\n",
      "Iteration 000198: OneCycleScheduler setting learning rate to 8.61583292860612e-05.\n",
      "199/343 [================>.............] - ETA: 2:16 - loss: 0.4873 - acc: 0.8103 - kappa: 0.9500\n",
      "Iteration 000199: OneCycleScheduler setting learning rate to 8.639145216124332e-05.\n",
      "200/343 [================>.............] - ETA: 2:15 - loss: 0.4876 - acc: 0.8100 - kappa: 0.9501\n",
      "Iteration 000200: OneCycleScheduler setting learning rate to 8.662457503642545e-05.\n",
      "201/343 [================>.............] - ETA: 2:14 - loss: 0.4859 - acc: 0.8109 - kappa: 0.9504\n",
      "Iteration 000201: OneCycleScheduler setting learning rate to 8.685769791160757e-05.\n",
      "202/343 [================>.............] - ETA: 2:13 - loss: 0.4854 - acc: 0.8113 - kappa: 0.9506\n",
      "Iteration 000202: OneCycleScheduler setting learning rate to 8.709082078678971e-05.\n",
      "203/343 [================>.............] - ETA: 2:12 - loss: 0.4853 - acc: 0.8116 - kappa: 0.9508\n",
      "Iteration 000203: OneCycleScheduler setting learning rate to 8.732394366197184e-05.\n",
      "204/343 [================>.............] - ETA: 2:11 - loss: 0.4838 - acc: 0.8119 - kappa: 0.9509\n",
      "Iteration 000204: OneCycleScheduler setting learning rate to 8.755706653715396e-05.\n",
      "205/343 [================>.............] - ETA: 2:10 - loss: 0.4819 - acc: 0.8128 - kappa: 0.9511\n",
      "Iteration 000205: OneCycleScheduler setting learning rate to 8.77901894123361e-05.\n",
      "206/343 [=================>............] - ETA: 2:09 - loss: 0.4817 - acc: 0.8125 - kappa: 0.9510\n",
      "Iteration 000206: OneCycleScheduler setting learning rate to 8.802331228751823e-05.\n",
      "207/343 [=================>............] - ETA: 2:08 - loss: 0.4829 - acc: 0.8122 - kappa: 0.9511\n",
      "Iteration 000207: OneCycleScheduler setting learning rate to 8.825643516270035e-05.\n",
      "208/343 [=================>............] - ETA: 2:07 - loss: 0.4819 - acc: 0.8119 - kappa: 0.9512\n",
      "Iteration 000208: OneCycleScheduler setting learning rate to 8.848955803788248e-05.\n",
      "209/343 [=================>............] - ETA: 2:06 - loss: 0.4807 - acc: 0.8122 - kappa: 0.9514\n",
      "Iteration 000209: OneCycleScheduler setting learning rate to 8.87226809130646e-05.\n",
      "210/343 [=================>............] - ETA: 2:05 - loss: 0.4794 - acc: 0.8125 - kappa: 0.9516\n",
      "Iteration 000210: OneCycleScheduler setting learning rate to 8.895580378824673e-05.\n",
      "211/343 [=================>............] - ETA: 2:05 - loss: 0.4786 - acc: 0.8134 - kappa: 0.9518\n",
      "Iteration 000211: OneCycleScheduler setting learning rate to 8.918892666342885e-05.\n",
      "212/343 [=================>............] - ETA: 2:04 - loss: 0.4777 - acc: 0.8137 - kappa: 0.9520\n",
      "Iteration 000212: OneCycleScheduler setting learning rate to 8.942204953861098e-05.\n",
      "213/343 [=================>............] - ETA: 2:03 - loss: 0.4777 - acc: 0.8140 - kappa: 0.9522\n",
      "Iteration 000213: OneCycleScheduler setting learning rate to 8.96551724137931e-05.\n",
      "214/343 [=================>............] - ETA: 2:02 - loss: 0.4791 - acc: 0.8143 - kappa: 0.9521\n",
      "Iteration 000214: OneCycleScheduler setting learning rate to 8.988829528897523e-05.\n",
      "215/343 [=================>............] - ETA: 2:01 - loss: 0.4805 - acc: 0.8140 - kappa: 0.9517\n",
      "Iteration 000215: OneCycleScheduler setting learning rate to 9.012141816415737e-05.\n",
      "216/343 [=================>............] - ETA: 2:00 - loss: 0.4803 - acc: 0.8137 - kappa: 0.9518\n",
      "Iteration 000216: OneCycleScheduler setting learning rate to 9.035454103933949e-05.\n",
      "217/343 [=================>............] - ETA: 1:59 - loss: 0.4825 - acc: 0.8128 - kappa: 0.9514\n",
      "Iteration 000217: OneCycleScheduler setting learning rate to 9.058766391452162e-05.\n",
      "218/343 [==================>...........] - ETA: 1:58 - loss: 0.4831 - acc: 0.8125 - kappa: 0.9511\n",
      "Iteration 000218: OneCycleScheduler setting learning rate to 9.082078678970376e-05.\n",
      "219/343 [==================>...........] - ETA: 1:57 - loss: 0.4827 - acc: 0.8128 - kappa: 0.9513\n",
      "Iteration 000219: OneCycleScheduler setting learning rate to 9.105390966488588e-05.\n",
      "220/343 [==================>...........] - ETA: 1:56 - loss: 0.4821 - acc: 0.8131 - kappa: 0.9515\n",
      "Iteration 000220: OneCycleScheduler setting learning rate to 9.1287032540068e-05.\n",
      "221/343 [==================>...........] - ETA: 1:56 - loss: 0.4833 - acc: 0.8128 - kappa: 0.9515\n",
      "Iteration 000221: OneCycleScheduler setting learning rate to 9.152015541525013e-05.\n",
      "222/343 [==================>...........] - ETA: 1:54 - loss: 0.4824 - acc: 0.8125 - kappa: 0.9516\n",
      "Iteration 000222: OneCycleScheduler setting learning rate to 9.175327829043226e-05.\n",
      "223/343 [==================>...........] - ETA: 1:54 - loss: 0.4837 - acc: 0.8117 - kappa: 0.9515\n",
      "Iteration 000223: OneCycleScheduler setting learning rate to 9.198640116561438e-05.\n",
      "224/343 [==================>...........] - ETA: 1:53 - loss: 0.4829 - acc: 0.8125 - kappa: 0.9517\n",
      "Iteration 000224: OneCycleScheduler setting learning rate to 9.221952404079651e-05.\n",
      "225/343 [==================>...........] - ETA: 1:52 - loss: 0.4820 - acc: 0.8128 - kappa: 0.9519\n",
      "Iteration 000225: OneCycleScheduler setting learning rate to 9.245264691597863e-05.\n",
      "226/343 [==================>...........] - ETA: 1:51 - loss: 0.4814 - acc: 0.8131 - kappa: 0.9521\n",
      "Iteration 000226: OneCycleScheduler setting learning rate to 9.268576979116076e-05.\n",
      "227/343 [==================>...........] - ETA: 1:50 - loss: 0.4797 - acc: 0.8139 - kappa: 0.9523\n",
      "Iteration 000227: OneCycleScheduler setting learning rate to 9.291889266634288e-05.\n",
      "228/343 [==================>...........] - ETA: 1:49 - loss: 0.4839 - acc: 0.8125 - kappa: 0.9517\n",
      "Iteration 000228: OneCycleScheduler setting learning rate to 9.315201554152502e-05.\n",
      "229/343 [===================>..........] - ETA: 1:48 - loss: 0.4844 - acc: 0.8128 - kappa: 0.9518\n",
      "Iteration 000229: OneCycleScheduler setting learning rate to 9.338513841670715e-05.\n",
      "230/343 [===================>..........] - ETA: 1:47 - loss: 0.4842 - acc: 0.8130 - kappa: 0.9520\n",
      "Iteration 000230: OneCycleScheduler setting learning rate to 9.361826129188927e-05.\n",
      "231/343 [===================>..........] - ETA: 1:46 - loss: 0.4833 - acc: 0.8133 - kappa: 0.9522\n",
      "Iteration 000231: OneCycleScheduler setting learning rate to 9.38513841670714e-05.\n",
      "232/343 [===================>..........] - ETA: 1:45 - loss: 0.4833 - acc: 0.8136 - kappa: 0.9522\n",
      "Iteration 000232: OneCycleScheduler setting learning rate to 9.408450704225354e-05.\n",
      "233/343 [===================>..........] - ETA: 1:44 - loss: 0.4835 - acc: 0.8138 - kappa: 0.9523\n",
      "Iteration 000233: OneCycleScheduler setting learning rate to 9.431762991743566e-05.\n",
      "234/343 [===================>..........] - ETA: 1:43 - loss: 0.4833 - acc: 0.8141 - kappa: 0.9525\n",
      "Iteration 000234: OneCycleScheduler setting learning rate to 9.455075279261779e-05.\n",
      "235/343 [===================>..........] - ETA: 1:42 - loss: 0.4818 - acc: 0.8149 - kappa: 0.9527\n",
      "Iteration 000235: OneCycleScheduler setting learning rate to 9.478387566779991e-05.\n",
      "236/343 [===================>..........] - ETA: 1:41 - loss: 0.4812 - acc: 0.8151 - kappa: 0.9529\n",
      "Iteration 000236: OneCycleScheduler setting learning rate to 9.501699854298204e-05.\n",
      "237/343 [===================>..........] - ETA: 1:40 - loss: 0.4804 - acc: 0.8154 - kappa: 0.9530\n",
      "Iteration 000237: OneCycleScheduler setting learning rate to 9.525012141816416e-05.\n",
      "238/343 [===================>..........] - ETA: 1:39 - loss: 0.4788 - acc: 0.8162 - kappa: 0.9532\n",
      "Iteration 000238: OneCycleScheduler setting learning rate to 9.548324429334629e-05.\n",
      "239/343 [===================>..........] - ETA: 1:38 - loss: 0.4791 - acc: 0.8154 - kappa: 0.9531\n",
      "Iteration 000239: OneCycleScheduler setting learning rate to 9.571636716852841e-05.\n",
      "240/343 [===================>..........] - ETA: 1:37 - loss: 0.4778 - acc: 0.8161 - kappa: 0.9533\n",
      "Iteration 000240: OneCycleScheduler setting learning rate to 9.594949004371054e-05.\n",
      "241/343 [====================>.........] - ETA: 1:36 - loss: 0.4764 - acc: 0.8169 - kappa: 0.9535\n",
      "Iteration 000241: OneCycleScheduler setting learning rate to 9.618261291889266e-05.\n",
      "242/343 [====================>.........] - ETA: 1:35 - loss: 0.4750 - acc: 0.8177 - kappa: 0.9537\n",
      "Iteration 000242: OneCycleScheduler setting learning rate to 9.64157357940748e-05.\n",
      "243/343 [====================>.........] - ETA: 1:34 - loss: 0.4753 - acc: 0.8169 - kappa: 0.9531\n",
      "Iteration 000243: OneCycleScheduler setting learning rate to 9.664885866925693e-05.\n",
      "244/343 [====================>.........] - ETA: 1:33 - loss: 0.4747 - acc: 0.8166 - kappa: 0.9532\n",
      "Iteration 000244: OneCycleScheduler setting learning rate to 9.688198154443905e-05.\n",
      "245/343 [====================>.........] - ETA: 1:32 - loss: 0.4735 - acc: 0.8173 - kappa: 0.9533\n",
      "Iteration 000245: OneCycleScheduler setting learning rate to 9.711510441962119e-05.\n",
      "246/343 [====================>.........] - ETA: 1:32 - loss: 0.4731 - acc: 0.8176 - kappa: 0.9535\n",
      "Iteration 000246: OneCycleScheduler setting learning rate to 9.734822729480332e-05.\n",
      "247/343 [====================>.........] - ETA: 1:31 - loss: 0.4715 - acc: 0.8183 - kappa: 0.9537\n",
      "Iteration 000247: OneCycleScheduler setting learning rate to 9.758135016998544e-05.\n",
      "248/343 [====================>.........] - ETA: 1:30 - loss: 0.4710 - acc: 0.8185 - kappa: 0.9538\n",
      "Iteration 000248: OneCycleScheduler setting learning rate to 9.781447304516757e-05.\n",
      "249/343 [====================>.........] - ETA: 1:29 - loss: 0.4713 - acc: 0.8183 - kappa: 0.9539\n",
      "Iteration 000249: OneCycleScheduler setting learning rate to 9.804759592034969e-05.\n",
      "250/343 [====================>.........] - ETA: 1:28 - loss: 0.4724 - acc: 0.8175 - kappa: 0.9538\n",
      "Iteration 000250: OneCycleScheduler setting learning rate to 9.828071879553182e-05.\n",
      "251/343 [====================>.........] - ETA: 1:27 - loss: 0.4715 - acc: 0.8182 - kappa: 0.9540\n",
      "Iteration 000251: OneCycleScheduler setting learning rate to 9.851384167071394e-05.\n",
      "252/343 [=====================>........] - ETA: 1:26 - loss: 0.4832 - acc: 0.8165 - kappa: 0.9511\n",
      "Iteration 000252: OneCycleScheduler setting learning rate to 9.874696454589607e-05.\n",
      "253/343 [=====================>........] - ETA: 1:25 - loss: 0.4836 - acc: 0.8162 - kappa: 0.9505\n",
      "Iteration 000253: OneCycleScheduler setting learning rate to 9.89800874210782e-05.\n",
      "254/343 [=====================>........] - ETA: 1:24 - loss: 0.4821 - acc: 0.8169 - kappa: 0.9507\n",
      "Iteration 000254: OneCycleScheduler setting learning rate to 9.921321029626032e-05.\n",
      "255/343 [=====================>........] - ETA: 1:23 - loss: 0.4824 - acc: 0.8172 - kappa: 0.9509\n",
      "Iteration 000255: OneCycleScheduler setting learning rate to 9.944633317144246e-05.\n",
      "256/343 [=====================>........] - ETA: 1:22 - loss: 0.4824 - acc: 0.8169 - kappa: 0.9509\n",
      "Iteration 000256: OneCycleScheduler setting learning rate to 9.967945604662458e-05.\n",
      "257/343 [=====================>........] - ETA: 1:21 - loss: 0.4814 - acc: 0.8176 - kappa: 0.9511\n",
      "Iteration 000257: OneCycleScheduler setting learning rate to 9.991257892180671e-05.\n",
      "258/343 [=====================>........] - ETA: 1:20 - loss: 0.4803 - acc: 0.8178 - kappa: 0.9513\n",
      "Iteration 000258: OneCycleScheduler setting learning rate to 0.00010014570179698885.\n",
      "259/343 [=====================>........] - ETA: 1:19 - loss: 0.4809 - acc: 0.8181 - kappa: 0.9513\n",
      "Iteration 000259: OneCycleScheduler setting learning rate to 0.00010037882467217097.\n",
      "260/343 [=====================>........] - ETA: 1:19 - loss: 0.4819 - acc: 0.8173 - kappa: 0.9511\n",
      "Iteration 000260: OneCycleScheduler setting learning rate to 0.0001006119475473531.\n",
      "261/343 [=====================>........] - ETA: 1:18 - loss: 0.4824 - acc: 0.8170 - kappa: 0.9510\n",
      "Iteration 000261: OneCycleScheduler setting learning rate to 0.00010084507042253522.\n",
      "262/343 [=====================>........] - ETA: 1:17 - loss: 0.4835 - acc: 0.8168 - kappa: 0.9510\n",
      "Iteration 000262: OneCycleScheduler setting learning rate to 0.00010107819329771735.\n",
      "263/343 [======================>.......] - ETA: 1:16 - loss: 0.4866 - acc: 0.8165 - kappa: 0.9507\n",
      "Iteration 000263: OneCycleScheduler setting learning rate to 0.00010131131617289947.\n",
      "264/343 [======================>.......] - ETA: 1:15 - loss: 0.4849 - acc: 0.8172 - kappa: 0.9509\n",
      "Iteration 000264: OneCycleScheduler setting learning rate to 0.0001015444390480816.\n",
      "265/343 [======================>.......] - ETA: 1:14 - loss: 0.4849 - acc: 0.8175 - kappa: 0.9510\n",
      "Iteration 000265: OneCycleScheduler setting learning rate to 0.00010177756192326372.\n",
      "266/343 [======================>.......] - ETA: 1:13 - loss: 0.4866 - acc: 0.8167 - kappa: 0.9507\n",
      "Iteration 000266: OneCycleScheduler setting learning rate to 0.00010201068479844585.\n",
      "267/343 [======================>.......] - ETA: 1:12 - loss: 0.4897 - acc: 0.8160 - kappa: 0.9498\n",
      "Iteration 000267: OneCycleScheduler setting learning rate to 0.00010224380767362797.\n",
      "268/343 [======================>.......] - ETA: 1:11 - loss: 0.4934 - acc: 0.8153 - kappa: 0.9490\n",
      "Iteration 000268: OneCycleScheduler setting learning rate to 0.0001024769305488101.\n",
      "269/343 [======================>.......] - ETA: 1:10 - loss: 0.4925 - acc: 0.8160 - kappa: 0.9492\n",
      "Iteration 000269: OneCycleScheduler setting learning rate to 0.00010271005342399222.\n",
      "270/343 [======================>.......] - ETA: 1:09 - loss: 0.4927 - acc: 0.8157 - kappa: 0.9492\n",
      "Iteration 000270: OneCycleScheduler setting learning rate to 0.00010294317629917438.\n",
      "271/343 [======================>.......] - ETA: 1:08 - loss: 0.4930 - acc: 0.8155 - kappa: 0.9493\n",
      "Iteration 000271: OneCycleScheduler setting learning rate to 0.0001031762991743565.\n",
      "272/343 [======================>.......] - ETA: 1:07 - loss: 0.4925 - acc: 0.8157 - kappa: 0.9494\n",
      "Iteration 000272: OneCycleScheduler setting learning rate to 0.00010340942204953863.\n",
      "273/343 [======================>.......] - ETA: 1:06 - loss: 0.4916 - acc: 0.8159 - kappa: 0.9495\n",
      "Iteration 000273: OneCycleScheduler setting learning rate to 0.00010364254492472075.\n",
      "274/343 [======================>.......] - ETA: 1:05 - loss: 0.4909 - acc: 0.8166 - kappa: 0.9497\n",
      "Iteration 000274: OneCycleScheduler setting learning rate to 0.00010387566779990288.\n",
      "275/343 [=======================>......] - ETA: 1:04 - loss: 0.4910 - acc: 0.8164 - kappa: 0.9497\n",
      "Iteration 000275: OneCycleScheduler setting learning rate to 0.000104108790675085.\n",
      "276/343 [=======================>......] - ETA: 1:03 - loss: 0.4921 - acc: 0.8161 - kappa: 0.9497\n",
      "Iteration 000276: OneCycleScheduler setting learning rate to 0.00010434191355026713.\n",
      "277/343 [=======================>......] - ETA: 1:02 - loss: 0.4915 - acc: 0.8159 - kappa: 0.9498\n",
      "Iteration 000277: OneCycleScheduler setting learning rate to 0.00010457503642544925.\n",
      "278/343 [=======================>......] - ETA: 1:01 - loss: 0.4933 - acc: 0.8156 - kappa: 0.9497\n",
      "Iteration 000278: OneCycleScheduler setting learning rate to 0.00010480815930063138.\n",
      "279/343 [=======================>......] - ETA: 1:00 - loss: 0.4923 - acc: 0.8163 - kappa: 0.9499\n",
      "Iteration 000279: OneCycleScheduler setting learning rate to 0.0001050412821758135.\n",
      "280/343 [=======================>......] - ETA: 1:00 - loss: 0.4925 - acc: 0.8165 - kappa: 0.9501\n",
      "Iteration 000280: OneCycleScheduler setting learning rate to 0.00010527440505099563.\n",
      "281/343 [=======================>......] - ETA: 59s - loss: 0.4923 - acc: 0.8163 - kappa: 0.9500 \n",
      "Iteration 000281: OneCycleScheduler setting learning rate to 0.00010550752792617775.\n",
      "282/343 [=======================>......] - ETA: 58s - loss: 0.4918 - acc: 0.8165 - kappa: 0.9501\n",
      "Iteration 000282: OneCycleScheduler setting learning rate to 0.00010574065080135988.\n",
      "283/343 [=======================>......] - ETA: 57s - loss: 0.4920 - acc: 0.8163 - kappa: 0.9502\n",
      "Iteration 000283: OneCycleScheduler setting learning rate to 0.00010597377367654203.\n",
      "284/343 [=======================>......] - ETA: 56s - loss: 0.4914 - acc: 0.8160 - kappa: 0.9499\n",
      "Iteration 000284: OneCycleScheduler setting learning rate to 0.00010620689655172416.\n",
      "285/343 [=======================>......] - ETA: 55s - loss: 0.4922 - acc: 0.8149 - kappa: 0.9491\n",
      "Iteration 000285: OneCycleScheduler setting learning rate to 0.00010644001942690628.\n",
      "286/343 [========================>.....] - ETA: 54s - loss: 0.4960 - acc: 0.8138 - kappa: 0.9483\n",
      "Iteration 000286: OneCycleScheduler setting learning rate to 0.00010667314230208841.\n",
      "287/343 [========================>.....] - ETA: 53s - loss: 0.4957 - acc: 0.8140 - kappa: 0.9484\n",
      "Iteration 000287: OneCycleScheduler setting learning rate to 0.00010690626517727053.\n",
      "288/343 [========================>.....] - ETA: 52s - loss: 0.4961 - acc: 0.8138 - kappa: 0.9483\n",
      "Iteration 000288: OneCycleScheduler setting learning rate to 0.00010713938805245266.\n",
      "289/343 [========================>.....] - ETA: 51s - loss: 0.4946 - acc: 0.8144 - kappa: 0.9485\n",
      "Iteration 000289: OneCycleScheduler setting learning rate to 0.00010737251092763478.\n",
      "290/343 [========================>.....] - ETA: 50s - loss: 0.4942 - acc: 0.8147 - kappa: 0.9486\n",
      "Iteration 000290: OneCycleScheduler setting learning rate to 0.00010760563380281691.\n",
      "291/343 [========================>.....] - ETA: 49s - loss: 0.4932 - acc: 0.8153 - kappa: 0.9487\n",
      "Iteration 000291: OneCycleScheduler setting learning rate to 0.00010783875667799903.\n",
      "292/343 [========================>.....] - ETA: 48s - loss: 0.4935 - acc: 0.8146 - kappa: 0.9485\n",
      "Iteration 000292: OneCycleScheduler setting learning rate to 0.00010807187955318116.\n",
      "293/343 [========================>.....] - ETA: 47s - loss: 0.4927 - acc: 0.8153 - kappa: 0.9487\n",
      "Iteration 000293: OneCycleScheduler setting learning rate to 0.00010830500242836328.\n",
      "294/343 [========================>.....] - ETA: 46s - loss: 0.4934 - acc: 0.8151 - kappa: 0.9487\n",
      "Iteration 000294: OneCycleScheduler setting learning rate to 0.00010853812530354541.\n",
      "295/343 [========================>.....] - ETA: 45s - loss: 0.4927 - acc: 0.8153 - kappa: 0.9489\n",
      "Iteration 000295: OneCycleScheduler setting learning rate to 0.00010877124817872753.\n",
      "296/343 [========================>.....] - ETA: 44s - loss: 0.4920 - acc: 0.8155 - kappa: 0.9490\n",
      "Iteration 000296: OneCycleScheduler setting learning rate to 0.00010900437105390969.\n",
      "297/343 [========================>.....] - ETA: 43s - loss: 0.4910 - acc: 0.8157 - kappa: 0.9492\n",
      "Iteration 000297: OneCycleScheduler setting learning rate to 0.00010923749392909181.\n",
      "298/343 [=========================>....] - ETA: 42s - loss: 0.4911 - acc: 0.8159 - kappa: 0.9492\n",
      "Iteration 000298: OneCycleScheduler setting learning rate to 0.00010947061680427394.\n",
      "299/343 [=========================>....] - ETA: 42s - loss: 0.4913 - acc: 0.8156 - kappa: 0.9493\n",
      "Iteration 000299: OneCycleScheduler setting learning rate to 0.00010970373967945606.\n",
      "300/343 [=========================>....] - ETA: 41s - loss: 0.4910 - acc: 0.8154 - kappa: 0.9492\n",
      "Iteration 000300: OneCycleScheduler setting learning rate to 0.00010993686255463819.\n",
      "301/343 [=========================>....] - ETA: 40s - loss: 0.4931 - acc: 0.8144 - kappa: 0.9490\n",
      "Iteration 000301: OneCycleScheduler setting learning rate to 0.00011016998542982031.\n",
      "302/343 [=========================>....] - ETA: 39s - loss: 0.4930 - acc: 0.8146 - kappa: 0.9491\n",
      "Iteration 000302: OneCycleScheduler setting learning rate to 0.00011040310830500244.\n",
      "303/343 [=========================>....] - ETA: 38s - loss: 0.4919 - acc: 0.8152 - kappa: 0.9493\n",
      "Iteration 000303: OneCycleScheduler setting learning rate to 0.00011063623118018456.\n",
      "304/343 [=========================>....] - ETA: 37s - loss: 0.4912 - acc: 0.8154 - kappa: 0.9495\n",
      "Iteration 000304: OneCycleScheduler setting learning rate to 0.00011086935405536669.\n",
      "305/343 [=========================>....] - ETA: 36s - loss: 0.4909 - acc: 0.8156 - kappa: 0.9496\n",
      "Iteration 000305: OneCycleScheduler setting learning rate to 0.00011110247693054881.\n",
      "306/343 [=========================>....] - ETA: 35s - loss: 0.4902 - acc: 0.8158 - kappa: 0.9497\n",
      "Iteration 000306: OneCycleScheduler setting learning rate to 0.00011133559980573094.\n",
      "307/343 [=========================>....] - ETA: 34s - loss: 0.4905 - acc: 0.8156 - kappa: 0.9496\n",
      "Iteration 000307: OneCycleScheduler setting learning rate to 0.00011156872268091306.\n",
      "308/343 [=========================>....] - ETA: 33s - loss: 0.4907 - acc: 0.8157 - kappa: 0.9497\n",
      "Iteration 000308: OneCycleScheduler setting learning rate to 0.00011180184555609519.\n",
      "309/343 [==========================>...] - ETA: 32s - loss: 0.4909 - acc: 0.8155 - kappa: 0.9495\n",
      "Iteration 000309: OneCycleScheduler setting learning rate to 0.00011203496843127731.\n",
      "310/343 [==========================>...] - ETA: 31s - loss: 0.4916 - acc: 0.8153 - kappa: 0.9495\n",
      "Iteration 000310: OneCycleScheduler setting learning rate to 0.00011226809130645947.\n",
      "311/343 [==========================>...] - ETA: 30s - loss: 0.4910 - acc: 0.8159 - kappa: 0.9497\n",
      "Iteration 000311: OneCycleScheduler setting learning rate to 0.00011250121418164159.\n",
      "312/343 [==========================>...] - ETA: 29s - loss: 0.4897 - acc: 0.8165 - kappa: 0.9499\n",
      "Iteration 000312: OneCycleScheduler setting learning rate to 0.00011273433705682372.\n",
      "313/343 [==========================>...] - ETA: 28s - loss: 0.4904 - acc: 0.8159 - kappa: 0.9498\n",
      "Iteration 000313: OneCycleScheduler setting learning rate to 0.00011296745993200584.\n",
      "314/343 [==========================>...] - ETA: 27s - loss: 0.4895 - acc: 0.8165 - kappa: 0.9500\n",
      "Iteration 000314: OneCycleScheduler setting learning rate to 0.00011320058280718797.\n",
      "315/343 [==========================>...] - ETA: 26s - loss: 0.4905 - acc: 0.8163 - kappa: 0.9500\n",
      "Iteration 000315: OneCycleScheduler setting learning rate to 0.00011343370568237009.\n",
      "316/343 [==========================>...] - ETA: 25s - loss: 0.4898 - acc: 0.8169 - kappa: 0.9502\n",
      "Iteration 000316: OneCycleScheduler setting learning rate to 0.00011366682855755222.\n",
      "317/343 [==========================>...] - ETA: 24s - loss: 0.4885 - acc: 0.8174 - kappa: 0.9503\n",
      "Iteration 000317: OneCycleScheduler setting learning rate to 0.00011389995143273434.\n",
      "318/343 [==========================>...] - ETA: 23s - loss: 0.4879 - acc: 0.8176 - kappa: 0.9504\n",
      "Iteration 000318: OneCycleScheduler setting learning rate to 0.00011413307430791647.\n",
      "319/343 [==========================>...] - ETA: 22s - loss: 0.4865 - acc: 0.8182 - kappa: 0.9506\n",
      "Iteration 000319: OneCycleScheduler setting learning rate to 0.0001143661971830986.\n",
      "320/343 [==========================>...] - ETA: 21s - loss: 0.4880 - acc: 0.8176 - kappa: 0.9503\n",
      "Iteration 000320: OneCycleScheduler setting learning rate to 0.00011459932005828072.\n",
      "321/343 [===========================>..] - ETA: 20s - loss: 0.4886 - acc: 0.8170 - kappa: 0.9503\n",
      "Iteration 000321: OneCycleScheduler setting learning rate to 0.00011483244293346284.\n",
      "322/343 [===========================>..] - ETA: 20s - loss: 0.4893 - acc: 0.8164 - kappa: 0.9502\n",
      "Iteration 000322: OneCycleScheduler setting learning rate to 0.00011506556580864497.\n",
      "323/343 [===========================>..] - ETA: 19s - loss: 0.4881 - acc: 0.8170 - kappa: 0.9503\n",
      "Iteration 000323: OneCycleScheduler setting learning rate to 0.00011529868868382712.\n",
      "324/343 [===========================>..] - ETA: 18s - loss: 0.4885 - acc: 0.8167 - kappa: 0.9499\n",
      "Iteration 000324: OneCycleScheduler setting learning rate to 0.00011553181155900925.\n",
      "325/343 [===========================>..] - ETA: 17s - loss: 0.4883 - acc: 0.8165 - kappa: 0.9498\n",
      "Iteration 000325: OneCycleScheduler setting learning rate to 0.00011576493443419137.\n",
      "326/343 [===========================>..] - ETA: 16s - loss: 0.4886 - acc: 0.8160 - kappa: 0.9496\n",
      "Iteration 000326: OneCycleScheduler setting learning rate to 0.0001159980573093735.\n",
      "327/343 [===========================>..] - ETA: 15s - loss: 0.4884 - acc: 0.8157 - kappa: 0.9497\n",
      "Iteration 000327: OneCycleScheduler setting learning rate to 0.00011623118018455562.\n",
      "328/343 [===========================>..] - ETA: 14s - loss: 0.4884 - acc: 0.8159 - kappa: 0.9498\n",
      "Iteration 000328: OneCycleScheduler setting learning rate to 0.00011646430305973775.\n",
      "329/343 [===========================>..] - ETA: 13s - loss: 0.4883 - acc: 0.8161 - kappa: 0.9499\n",
      "Iteration 000329: OneCycleScheduler setting learning rate to 0.00011669742593491987.\n",
      "330/343 [===========================>..] - ETA: 12s - loss: 0.4871 - acc: 0.8167 - kappa: 0.9501\n",
      "Iteration 000330: OneCycleScheduler setting learning rate to 0.000116930548810102.\n",
      "331/343 [===========================>..] - ETA: 11s - loss: 0.4861 - acc: 0.8168 - kappa: 0.9502\n",
      "Iteration 000331: OneCycleScheduler setting learning rate to 0.00011716367168528412.\n",
      "332/343 [============================>.] - ETA: 10s - loss: 0.4855 - acc: 0.8166 - kappa: 0.9503\n",
      "Iteration 000332: OneCycleScheduler setting learning rate to 0.00011739679456046625.\n",
      "333/343 [============================>.] - ETA: 9s - loss: 0.4851 - acc: 0.8168 - kappa: 0.9503 \n",
      "Iteration 000333: OneCycleScheduler setting learning rate to 0.00011762991743564837.\n",
      "334/343 [============================>.] - ETA: 8s - loss: 0.4847 - acc: 0.8170 - kappa: 0.9504\n",
      "Iteration 000334: OneCycleScheduler setting learning rate to 0.0001178630403108305.\n",
      "335/343 [============================>.] - ETA: 7s - loss: 0.4846 - acc: 0.8168 - kappa: 0.9503\n",
      "Iteration 000335: OneCycleScheduler setting learning rate to 0.00011809616318601262.\n",
      "336/343 [============================>.] - ETA: 6s - loss: 0.4846 - acc: 0.8170 - kappa: 0.9504\n",
      "Iteration 000336: OneCycleScheduler setting learning rate to 0.00011832928606119478.\n",
      "337/343 [============================>.] - ETA: 5s - loss: 0.4853 - acc: 0.8164 - kappa: 0.9499\n",
      "Iteration 000337: OneCycleScheduler setting learning rate to 0.0001185624089363769.\n",
      "338/343 [============================>.] - ETA: 4s - loss: 0.4849 - acc: 0.8166 - kappa: 0.9501\n",
      "Iteration 000338: OneCycleScheduler setting learning rate to 0.00011879553181155903.\n",
      "339/343 [============================>.] - ETA: 3s - loss: 0.4858 - acc: 0.8164 - kappa: 0.9500\n",
      "Iteration 000339: OneCycleScheduler setting learning rate to 0.00011902865468674115.\n",
      "340/343 [============================>.] - ETA: 2s - loss: 0.4862 - acc: 0.8162 - kappa: 0.9500\n",
      "Iteration 000340: OneCycleScheduler setting learning rate to 0.00011926177756192328.\n",
      "341/343 [============================>.] - ETA: 1s - loss: 0.4865 - acc: 0.8152 - kappa: 0.9501\n",
      "Iteration 000341: OneCycleScheduler setting learning rate to 0.0001194949004371054.\n",
      "342/343 [============================>.] - ETA: 0s - loss: 0.4870 - acc: 0.8151 - kappa: 0.9502\n",
      "Iteration 000342: OneCycleScheduler setting learning rate to 0.00011972802331228753.\n",
      "343/343 [==============================] - 421s 1s/step - loss: 0.4868 - acc: 0.8149 - kappa: 0.9502 - val_loss: 0.7174 - val_acc: 0.7610 - val_kappa: 0.9151\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00007: early stopping\n"
     ]
    }
   ],
   "source": [
    "history_finetunning = model.fit_generator(generator=train_generator,\n",
    "                                          steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                                          validation_data=valid_generator,\n",
    "                                          validation_steps=STEP_SIZE_VALID,\n",
    "                                          epochs=EPOCHS,\n",
    "                                          callbacks=callback_list,\n",
    "                                          class_weight=class_weights,\n",
    "                                          verbose=1).history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model loss graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1296 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = {'loss': history_warmup['loss'] + history_finetunning['loss'], \n",
    "           'val_loss': history_warmup['val_loss'] + history_finetunning['val_loss'], \n",
    "           'acc': history_warmup['acc'] + history_finetunning['acc'], \n",
    "           'val_acc': history_warmup['val_acc'] + history_finetunning['val_acc'], \n",
    "           'kappa': history_warmup['kappa'] + history_finetunning['kappa'], \n",
    "           'val_kappa': history_warmup['val_kappa'] + history_finetunning['val_kappa']}\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, sharex='col', figsize=(20, 18))\n",
    "\n",
    "ax1.plot(history['loss'], label='Train loss')\n",
    "ax1.plot(history['val_loss'], label='Validation loss')\n",
    "ax1.legend(loc='best')\n",
    "ax1.set_title('Loss')\n",
    "\n",
    "ax2.plot(history['acc'], label='Train accuracy')\n",
    "ax2.plot(history['val_acc'], label='Validation accuracy')\n",
    "ax2.legend(loc='best')\n",
    "ax2.set_title('Accuracy')\n",
    "\n",
    "ax3.plot(history['kappa'], label='Train kappa')\n",
    "ax3.plot(history['val_kappa'], label='Validation kappa')\n",
    "ax3.legend(loc='best')\n",
    "ax3.set_title('Kappa')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# Create empty arays to keep the predictions and labels\n",
    "lastFullTrainPred = np.empty((0, N_CLASSES))\n",
    "lastFullTrainLabels = np.empty((0, N_CLASSES))\n",
    "lastFullValPred = np.empty((0, N_CLASSES))\n",
    "lastFullValLabels = np.empty((0, N_CLASSES))\n",
    "\n",
    "# Add train predictions and labels\n",
    "for i in range(STEP_SIZE_TRAIN+1):\n",
    "    im, lbl = next(train_generator)\n",
    "    scores = model.predict(im, batch_size=train_generator.batch_size)\n",
    "    lastFullTrainPred = np.append(lastFullTrainPred, scores, axis=0)\n",
    "    lastFullTrainLabels = np.append(lastFullTrainLabels, lbl, axis=0)\n",
    "\n",
    "# Add validation predictions and labels\n",
    "for i in range(STEP_SIZE_VALID+1):\n",
    "    im, lbl = next(valid_generator)\n",
    "    scores = model.predict(im, batch_size=valid_generator.batch_size)\n",
    "    lastFullValPred = np.append(lastFullValPred, scores, axis=0)\n",
    "    lastFullValLabels = np.append(lastFullValLabels, lbl, axis=0)\n",
    "\n",
    "lastFullComPred = np.concatenate((lastFullTrainPred, lastFullValPred))\n",
    "lastFullComLabels = np.concatenate((lastFullTrainLabels, lastFullValLabels))\n",
    "\n",
    "train_preds = [np.argmax(pred) for pred in lastFullTrainPred]\n",
    "train_labels = [np.argmax(label) for label in lastFullTrainLabels]\n",
    "validation_preds = [np.argmax(pred) for pred in lastFullValPred]\n",
    "validation_labels = [np.argmax(label) for label in lastFullValLabels]\n",
    "complete_labels = [np.argmax(label) for label in lastFullComLabels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Threshold optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thr=0.340 F2=0.670\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thr=0.410 F2=0.668\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thr=0.200 F2=0.712\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thr=0.350 F2=0.669\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def find_best_fixed_threshold(preds, targs, do_plot=True):\n",
    "    best_thr_list = [0 for i in range(preds.shape[1])]\n",
    "    for index in reversed(range(1, preds.shape[1])):\n",
    "        score = []\n",
    "        thrs = np.arange(0, 1, 0.01)\n",
    "        for thr in thrs:\n",
    "            preds_thr = [index if x[index] > thr else np.argmax(x) for x in preds]\n",
    "            score.append(cohen_kappa_score(targs, preds_thr))\n",
    "        score = np.array(score)\n",
    "        pm = score.argmax()\n",
    "        best_thr, best_score = thrs[pm], score[pm].item()\n",
    "        best_thr_list[index] = best_thr\n",
    "        print(f'thr={best_thr:.3f}', f'F2={best_score:.3f}')\n",
    "        if do_plot:\n",
    "            plt.plot(thrs, score)\n",
    "            plt.vlines(x=best_thr, ymin=score.min(), ymax=score.max())\n",
    "            plt.text(best_thr+0.03, best_score-0.01, ('Kappa[%s]=%.3f'%(index, best_score)), fontsize=14);\n",
    "            plt.show()\n",
    "            \n",
    "    return best_thr_list\n",
    "\n",
    "threshold_list = find_best_fixed_threshold(lastFullValPred, validation_labels, do_plot=True)\n",
    "threshold_list[0] = 0 # In last instance assign label 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# Apply optimized thresholds to the train predictions\n",
    "train_preds_opt = [0 for i in range(lastFullTrainPred.shape[0])]\n",
    "for idx, thr in enumerate(threshold_list):\n",
    "    for idx2, pred in enumerate(lastFullTrainPred):\n",
    "        if pred[idx] > thr:\n",
    "            train_preds_opt[idx2] = idx\n",
    "\n",
    "# Apply optimized thresholds to the validation predictions\n",
    "validation_preds_opt = [0 for i in range(lastFullValPred.shape[0])]\n",
    "for idx, thr in enumerate(threshold_list):\n",
    "    for idx2, pred in enumerate(lastFullValPred):\n",
    "        if pred[idx] > thr:\n",
    "            validation_preds_opt[idx2] = idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1728x504 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Original thresholds\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, sharex='col', figsize=(24, 7))\n",
    "labels = ['0 - No DR', '1 - Mild', '2 - Moderate', '3 - Severe', '4 - Proliferative DR']\n",
    "train_cnf_matrix = confusion_matrix(train_labels, train_preds)\n",
    "validation_cnf_matrix = confusion_matrix(validation_labels, validation_preds)\n",
    "\n",
    "train_cnf_matrix_norm = train_cnf_matrix.astype('float') / train_cnf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "validation_cnf_matrix_norm = validation_cnf_matrix.astype('float') / validation_cnf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "train_df_cm = pd.DataFrame(train_cnf_matrix_norm, index=labels, columns=labels)\n",
    "validation_df_cm = pd.DataFrame(validation_cnf_matrix_norm, index=labels, columns=labels)\n",
    "\n",
    "sns.heatmap(train_df_cm, annot=True, fmt='.2f', cmap=\"Blues\",ax=ax1).set_title('Train')\n",
    "sns.heatmap(validation_df_cm, annot=True, fmt='.2f', cmap=\"Blues\",ax=ax2).set_title('Validation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1728x504 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Optimized thresholds\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, sharex='col', figsize=(24, 7))\n",
    "train_cnf_matrix = confusion_matrix(train_labels, train_preds_opt)\n",
    "validation_cnf_matrix = confusion_matrix(validation_labels, validation_preds_opt)\n",
    "\n",
    "train_cnf_matrix_norm = train_cnf_matrix.astype('float') / train_cnf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "validation_cnf_matrix_norm = validation_cnf_matrix.astype('float') / validation_cnf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "train_df_cm = pd.DataFrame(train_cnf_matrix_norm, index=labels, columns=labels)\n",
    "validation_df_cm = pd.DataFrame(validation_cnf_matrix_norm, index=labels, columns=labels)\n",
    "\n",
    "sns.heatmap(train_df_cm, annot=True, fmt='.2f', cmap=\"Blues\",ax=ax1).set_title('Train optimized')\n",
    "sns.heatmap(validation_df_cm, annot=True, fmt='.2f', cmap=\"Blues\",ax=ax2).set_title('Validation optimized')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quadratic Weighted Kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --- Original thresholds --- \n",
      "Train Cohen Kappa score: 0.864\n",
      "Validation Cohen Kappa score: 0.852\n",
      "Complete set Cohen Kappa score: 0.861\n",
      " --- Optimized thresholds --- \n",
      "Train Cohen Kappa score: 0.853\n",
      "Validation Cohen Kappa score: 0.857\n",
      "Complete set Cohen Kappa score: 0.854\n"
     ]
    }
   ],
   "source": [
    "print(\" --- Original thresholds --- \")\n",
    "print(\"Train Cohen Kappa score: %.3f\" % cohen_kappa_score(train_preds, train_labels, weights='quadratic'))\n",
    "print(\"Validation Cohen Kappa score: %.3f\" % cohen_kappa_score(validation_preds, validation_labels, weights='quadratic'))\n",
    "print(\"Complete set Cohen Kappa score: %.3f\" % cohen_kappa_score(train_preds+validation_preds, train_labels+validation_labels, weights='quadratic'))\n",
    "print(\" --- Optimized thresholds --- \")\n",
    "print(\"Train Cohen Kappa score: %.3f\" % cohen_kappa_score(train_preds_opt, train_labels, weights='quadratic'))\n",
    "print(\"Validation Cohen Kappa score: %.3f\" % cohen_kappa_score(validation_preds_opt, validation_labels, weights='quadratic'))\n",
    "print(\"Complete set Cohen Kappa score: %.3f\" % cohen_kappa_score(train_preds_opt+validation_preds_opt, train_labels+validation_labels, weights='quadratic'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply model to test set and output predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "test_generator.reset()\n",
    "STEP_SIZE_TEST = test_generator.n//test_generator.batch_size\n",
    "preds = model.predict_generator(test_generator, steps=STEP_SIZE_TEST)\n",
    "predictions = [np.argmax(pred) for pred in preds]\n",
    "\n",
    "predictions_opt = [0 for i in range(preds.shape[0])]\n",
    "for idx, thr in enumerate(threshold_list):\n",
    "    for idx2, pred in enumerate(preds):\n",
    "        if pred[idx] > thr:\n",
    "            predictions_opt[idx2] = idx\n",
    "\n",
    "filenames = test_generator.filenames\n",
    "results = pd.DataFrame({'id_code':filenames, 'diagnosis':predictions})\n",
    "results['id_code'] = results['id_code'].map(lambda x: str(x)[:-4])\n",
    "\n",
    "results_opt = pd.DataFrame({'id_code':filenames, 'diagnosis':predictions_opt})\n",
    "results_opt['id_code'] = results_opt['id_code'].map(lambda x: str(x)[:-4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1728x626.4 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, sharex='col', figsize=(24, 8.7))\n",
    "sns.countplot(x=\"diagnosis\", data=results, palette=\"GnBu_d\", ax=ax1).set_title('Test')\n",
    "sns.countplot(x=\"diagnosis\", data=results_opt, palette=\"GnBu_d\", ax=ax2).set_title('Test optimized')\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0005cfc8afb6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>003f0afdcd15</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>006efc72b638</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00836aaacf06</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>009245722fa4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>009c019a7309</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>010d915e229a</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0111b949947e</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>01499815e469</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0167076e7089</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_code  diagnosis\n",
       "0  0005cfc8afb6          2\n",
       "1  003f0afdcd15          3\n",
       "2  006efc72b638          3\n",
       "3  00836aaacf06          2\n",
       "4  009245722fa4          4\n",
       "5  009c019a7309          3\n",
       "6  010d915e229a          4\n",
       "7  0111b949947e          1\n",
       "8  01499815e469          3\n",
       "9  0167076e7089          2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_kappa =  cohen_kappa_score(validation_preds, validation_labels, weights='quadratic')\n",
    "val_opt_kappa = cohen_kappa_score(validation_preds_opt, validation_labels, weights='quadratic')\n",
    "if val_kappa > val_opt_kappa:\n",
    "    results_name = 'submission.csv'\n",
    "    results_opt_name = 'submission_opt.csv'\n",
    "else:\n",
    "    results_name = 'submission_norm.csv'\n",
    "    results_opt_name = 'submission.csv'\n",
    "\n",
    "results.to_csv(results_name, index=False)\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0005cfc8afb6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>003f0afdcd15</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>006efc72b638</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00836aaacf06</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>009245722fa4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>009c019a7309</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>010d915e229a</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0111b949947e</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>01499815e469</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0167076e7089</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_code  diagnosis\n",
       "0  0005cfc8afb6          2\n",
       "1  003f0afdcd15          3\n",
       "2  006efc72b638          2\n",
       "3  00836aaacf06          2\n",
       "4  009245722fa4          4\n",
       "5  009c019a7309          2\n",
       "6  010d915e229a          4\n",
       "7  0111b949947e          2\n",
       "8  01499815e469          3\n",
       "9  0167076e7089          2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_opt.to_csv(results_opt_name, index=False)\n",
    "results_opt.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
